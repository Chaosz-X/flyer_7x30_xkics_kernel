From 41b38d3377db532db18212fcb646b7ae07472bcc Mon Sep 17 00:00:00 2001
From: Carter Cooper <ccooper@codeaurora.org>
Date: Tue, 27 Dec 2011 15:19:39 +0100
Subject: [PATCH] msm: kgsl: Rename files to represent correct modules

Rename 3d specific files to adreno_*, consolidate 2d files
into z180.[ch].  Keeps modules from cross contamination.

Change-Id: I4d654e039fed4981e532a16873edb8ea3bce0780
Signed-off-by: Carter Cooper <ccooper@codeaurora.org>
---
 drivers/video/msm/gpu/kgsl_adreno205_hc/Makefile   |   30 +-
 drivers/video/msm/gpu/kgsl_adreno205_hc/a200_reg.h |  452 +++++
 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.c   | 1370 ++++++++++++++++
 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.h   |   75 +
 .../msm/gpu/kgsl_adreno205_hc/adreno_debugfs.c     |  450 +++++
 .../msm/gpu/kgsl_adreno205_hc/adreno_debugfs.h     |   56 +
 .../msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.c    | 1676 +++++++++++++++++++
 .../msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.h    |  113 ++
 .../msm/gpu/kgsl_adreno205_hc/adreno_pm4types.h    |  193 +++
 .../msm/gpu/kgsl_adreno205_hc/adreno_postmortem.c  |  869 ++++++++++
 .../msm/gpu/kgsl_adreno205_hc/adreno_postmortem.h  |   37 +
 .../msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.c  |  938 +++++++++++
 .../msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.h  |  204 +++
 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.c     |   97 +-
 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.h     |   15 +-
 .../msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.c     |   54 -
 .../msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.h     |   70 -
 .../video/msm/gpu/kgsl_adreno205_hc/kgsl_device.h  |   49 +-
 .../msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.c      | 1726 --------------------
 .../msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.h      |  116 --
 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_g12.h |   63 -
 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_log.h |    6 +-
 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_mmu.c |   24 +-
 .../msm/gpu/kgsl_adreno205_hc/kgsl_pm4types.h      |  193 ---
 .../msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.c    |  880 ----------
 .../msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.h    |   37 -
 .../video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.c |    6 -
 .../video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.h |   12 +-
 .../msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.c    |  945 -----------
 .../msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.h    |  211 ---
 .../msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.c     |    9 +-
 .../msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.h     |   12 +-
 .../video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.c  | 1326 ---------------
 .../video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.h  |   65 -
 .../gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.c    |  452 -----
 .../gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.h    |   41 -
 .../video/msm/gpu/kgsl_adreno205_hc/yamato_reg.h   |  452 -----
 drivers/video/msm/gpu/kgsl_adreno205_hc/z180.h     |   63 +
 38 files changed, 6563 insertions(+), 6824 deletions(-)
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/a200_reg.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.c
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.c
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.c
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_pm4types.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.c
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.c
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_g12.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pm4types.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.c
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.h
 delete mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/yamato_reg.h
 create mode 100644 drivers/video/msm/gpu/kgsl_adreno205_hc/z180.h

diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/Makefile b/drivers/video/msm/gpu/kgsl_adreno205_hc/Makefile
index e8a73d5..6ae89b9 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/Makefile
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/Makefile
@@ -2,33 +2,31 @@ ccflags-y := -Iinclude/drm
 
 msm_kgsl_core-$(CONFIG_GPU_MSM_KGSL) = \
 	kgsl.o \
-	kgsl_mmu.o \
 	kgsl_sharedmem.o \
-	kgsl_pwrctrl.o \
-	kgsl_postmortem.o
+	kgsl_pwrctrl.o
 
 msm_kgsl_core-$(CONFIG_DEBUG_FS) += kgsl_debugfs.o
+msm_kgsl_core-$(CONFIG_MSM_KGSL_MMU) += kgsl_mmu.o
+msm_kgsl_core-$(CONFIG_MSM_KGSL_CFF_DUMP) += kgsl_cffdump.o
+msm_kgsl_core-$(CONFIG_MSM_KGSL_DRM) += kgsl_drm.o
 
-msm_kgsl_a200-$(CONFIG_GPU_MSM_KGSL) += \
-	kgsl_ringbuffer.o \
-	kgsl_drawctxt.o \
-	kgsl_cmdstream.o \
-	kgsl_yamato.o
+msm_adreno-$(CONFIG_GPU_MSM_KGSL) += \
+	adreno_ringbuffer.o \
+	adreno_drawctxt.o \
+	adreno_postmortem.o \
+	adreno.o
 
-msm_kgsl_a200-$(CONFIG_DEBUG_FS) += kgsl_yamato_debugfs.o
+msm_adreno-$(CONFIG_DEBUG_FS) += adreno_debugfs.o
 
-msm_kgsl_z180-$(CONFIG_MSM_KGSL_2D) += \
+msm_z180-$(CONFIG_MSM_KGSL_2D) += \
 	kgsl_g12_drawctxt.o \
 	kgsl_g12_cmdstream.o \
 	kgsl_g12.o
 
-msm_kgsl_core-$(CONFIG_MSM_KGSL_CFF_DUMP) += kgsl_cffdump.o
-msm_kgsl_core-$(CONFIG_MSM_KGSL_DRM) += kgsl_drm.o
-
 msm_kgsl_core-objs = $(msm_kgsl_core-y)
-msm_kgsl_a200-objs = $(msm_kgsl_a200-y)
-msm_kgsl_z180-objs = $(msm_kgsl_z180-y)
+msm_adreno-objs = $(msm_kgsl_adreno-y)
+msm_z180-objs = $(msm_kgsl_z180-y)
 
 obj-$(CONFIG_GPU_MSM_KGSL) += \
 	msm_kgsl_core.o \
-	msm_kgsl_a200.o
+	msm_adreno.o
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/a200_reg.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/a200_reg.h
new file mode 100644
index 0000000..7fe119b
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/a200_reg.h
@@ -0,0 +1,452 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __A200_REG_H
+#define __A200_REG_H
+
+enum VGT_EVENT_TYPE {
+	VS_DEALLOC = 0,
+	PS_DEALLOC = 1,
+	VS_DONE_TS = 2,
+	PS_DONE_TS = 3,
+	CACHE_FLUSH_TS = 4,
+	CONTEXT_DONE = 5,
+	CACHE_FLUSH = 6,
+	VIZQUERY_START = 7,
+	VIZQUERY_END = 8,
+	SC_WAIT_WC = 9,
+	RST_PIX_CNT = 13,
+	RST_VTX_CNT = 14,
+	TILE_FLUSH = 15,
+	CACHE_FLUSH_AND_INV_TS_EVENT = 20,
+	ZPASS_DONE = 21,
+	CACHE_FLUSH_AND_INV_EVENT = 22,
+	PERFCOUNTER_START = 23,
+	PERFCOUNTER_STOP = 24,
+	VS_FETCH_DONE = 27,
+	FACENESS_FLUSH = 28,
+};
+
+enum COLORFORMATX {
+	COLORX_4_4_4_4 = 0,
+	COLORX_1_5_5_5 = 1,
+	COLORX_5_6_5 = 2,
+	COLORX_8 = 3,
+	COLORX_8_8 = 4,
+	COLORX_8_8_8_8 = 5,
+	COLORX_S8_8_8_8 = 6,
+	COLORX_16_FLOAT = 7,
+	COLORX_16_16_FLOAT = 8,
+	COLORX_16_16_16_16_FLOAT = 9,
+	COLORX_32_FLOAT = 10,
+	COLORX_32_32_FLOAT = 11,
+	COLORX_32_32_32_32_FLOAT = 12,
+	COLORX_2_3_3 = 13,
+	COLORX_8_8_8 = 14,
+};
+
+enum SURFACEFORMAT {
+	FMT_1_REVERSE                  = 0,
+	FMT_1                          = 1,
+	FMT_8                          = 2,
+	FMT_1_5_5_5                    = 3,
+	FMT_5_6_5                      = 4,
+	FMT_6_5_5                      = 5,
+	FMT_8_8_8_8                    = 6,
+	FMT_2_10_10_10                 = 7,
+	FMT_8_A                        = 8,
+	FMT_8_B                        = 9,
+	FMT_8_8                        = 10,
+	FMT_Cr_Y1_Cb_Y0                = 11,
+	FMT_Y1_Cr_Y0_Cb                = 12,
+	FMT_5_5_5_1                    = 13,
+	FMT_8_8_8_8_A                  = 14,
+	FMT_4_4_4_4                    = 15,
+	FMT_10_11_11                   = 16,
+	FMT_11_11_10                   = 17,
+	FMT_DXT1                       = 18,
+	FMT_DXT2_3                     = 19,
+	FMT_DXT4_5                     = 20,
+	FMT_24_8                       = 22,
+	FMT_24_8_FLOAT                 = 23,
+	FMT_16                         = 24,
+	FMT_16_16                      = 25,
+	FMT_16_16_16_16                = 26,
+	FMT_16_EXPAND                  = 27,
+	FMT_16_16_EXPAND               = 28,
+	FMT_16_16_16_16_EXPAND         = 29,
+	FMT_16_FLOAT                   = 30,
+	FMT_16_16_FLOAT                = 31,
+	FMT_16_16_16_16_FLOAT          = 32,
+	FMT_32                         = 33,
+	FMT_32_32                      = 34,
+	FMT_32_32_32_32                = 35,
+	FMT_32_FLOAT                   = 36,
+	FMT_32_32_FLOAT                = 37,
+	FMT_32_32_32_32_FLOAT          = 38,
+	FMT_32_AS_8                    = 39,
+	FMT_32_AS_8_8                  = 40,
+	FMT_16_MPEG                    = 41,
+	FMT_16_16_MPEG                 = 42,
+	FMT_8_INTERLACED               = 43,
+	FMT_32_AS_8_INTERLACED         = 44,
+	FMT_32_AS_8_8_INTERLACED       = 45,
+	FMT_16_INTERLACED              = 46,
+	FMT_16_MPEG_INTERLACED         = 47,
+	FMT_16_16_MPEG_INTERLACED      = 48,
+	FMT_DXN                        = 49,
+	FMT_8_8_8_8_AS_16_16_16_16     = 50,
+	FMT_DXT1_AS_16_16_16_16        = 51,
+	FMT_DXT2_3_AS_16_16_16_16      = 52,
+	FMT_DXT4_5_AS_16_16_16_16      = 53,
+	FMT_2_10_10_10_AS_16_16_16_16  = 54,
+	FMT_10_11_11_AS_16_16_16_16    = 55,
+	FMT_11_11_10_AS_16_16_16_16    = 56,
+	FMT_32_32_32_FLOAT             = 57,
+	FMT_DXT3A                      = 58,
+	FMT_DXT5A                      = 59,
+	FMT_CTX1                       = 60,
+	FMT_DXT3A_AS_1_1_1_1           = 61
+};
+
+#define REG_PERF_MODE_CNT	0x0
+#define REG_PERF_STATE_RESET	0x0
+#define REG_PERF_STATE_ENABLE	0x1
+#define REG_PERF_STATE_FREEZE	0x2
+
+#define RB_EDRAM_INFO_EDRAM_SIZE_SIZE                      4
+#define RB_EDRAM_INFO_EDRAM_MAPPING_MODE_SIZE              2
+#define RB_EDRAM_INFO_UNUSED0_SIZE                         8
+#define RB_EDRAM_INFO_EDRAM_RANGE_SIZE                     18
+
+struct rb_edram_info_t {
+	unsigned int edram_size:RB_EDRAM_INFO_EDRAM_SIZE_SIZE;
+	unsigned int edram_mapping_mode:RB_EDRAM_INFO_EDRAM_MAPPING_MODE_SIZE;
+	unsigned int unused0:RB_EDRAM_INFO_UNUSED0_SIZE;
+	unsigned int edram_range:RB_EDRAM_INFO_EDRAM_RANGE_SIZE;
+};
+
+union reg_rb_edram_info {
+	unsigned int val;
+	struct rb_edram_info_t f;
+};
+
+#define RBBM_READ_ERROR_UNUSED0_SIZE		2
+#define RBBM_READ_ERROR_READ_ADDRESS_SIZE	15
+#define RBBM_READ_ERROR_UNUSED1_SIZE		13
+#define RBBM_READ_ERROR_READ_REQUESTER_SIZE	1
+#define RBBM_READ_ERROR_READ_ERROR_SIZE		1
+
+struct rbbm_read_error_t {
+	unsigned int unused0:RBBM_READ_ERROR_UNUSED0_SIZE;
+	unsigned int read_address:RBBM_READ_ERROR_READ_ADDRESS_SIZE;
+	unsigned int unused1:RBBM_READ_ERROR_UNUSED1_SIZE;
+	unsigned int read_requester:RBBM_READ_ERROR_READ_REQUESTER_SIZE;
+	unsigned int read_error:RBBM_READ_ERROR_READ_ERROR_SIZE;
+};
+
+union rbbm_read_error_u {
+	unsigned int val:32;
+	struct rbbm_read_error_t f;
+};
+
+#define CP_RB_CNTL_RB_BUFSZ_SIZE                           6
+#define CP_RB_CNTL_UNUSED0_SIZE                            2
+#define CP_RB_CNTL_RB_BLKSZ_SIZE                           6
+#define CP_RB_CNTL_UNUSED1_SIZE                            2
+#define CP_RB_CNTL_BUF_SWAP_SIZE                           2
+#define CP_RB_CNTL_UNUSED2_SIZE                            2
+#define CP_RB_CNTL_RB_POLL_EN_SIZE                         1
+#define CP_RB_CNTL_UNUSED3_SIZE                            6
+#define CP_RB_CNTL_RB_NO_UPDATE_SIZE                       1
+#define CP_RB_CNTL_UNUSED4_SIZE                            3
+#define CP_RB_CNTL_RB_RPTR_WR_ENA_SIZE                     1
+
+struct cp_rb_cntl_t {
+	unsigned int rb_bufsz:CP_RB_CNTL_RB_BUFSZ_SIZE;
+	unsigned int unused0:CP_RB_CNTL_UNUSED0_SIZE;
+	unsigned int rb_blksz:CP_RB_CNTL_RB_BLKSZ_SIZE;
+	unsigned int unused1:CP_RB_CNTL_UNUSED1_SIZE;
+	unsigned int buf_swap:CP_RB_CNTL_BUF_SWAP_SIZE;
+	unsigned int unused2:CP_RB_CNTL_UNUSED2_SIZE;
+	unsigned int rb_poll_en:CP_RB_CNTL_RB_POLL_EN_SIZE;
+	unsigned int unused3:CP_RB_CNTL_UNUSED3_SIZE;
+	unsigned int rb_no_update:CP_RB_CNTL_RB_NO_UPDATE_SIZE;
+	unsigned int unused4:CP_RB_CNTL_UNUSED4_SIZE;
+	unsigned int rb_rptr_wr_ena:CP_RB_CNTL_RB_RPTR_WR_ENA_SIZE;
+};
+
+union reg_cp_rb_cntl {
+	unsigned int val:32;
+	struct cp_rb_cntl_t f;
+};
+
+#define RB_COLOR_INFO__COLOR_FORMAT_MASK                   0x0000000fL
+#define RB_COPY_DEST_INFO__COPY_DEST_FORMAT__SHIFT         0x00000004
+
+
+#define SQ_INT_CNTL__PS_WATCHDOG_MASK                      0x00000001L
+#define SQ_INT_CNTL__VS_WATCHDOG_MASK                      0x00000002L
+
+#define MH_INTERRUPT_MASK__AXI_READ_ERROR                  0x00000001L
+#define MH_INTERRUPT_MASK__AXI_WRITE_ERROR                 0x00000002L
+#define MH_INTERRUPT_MASK__MMU_PAGE_FAULT                  0x00000004L
+
+#define RBBM_INT_CNTL__RDERR_INT_MASK                      0x00000001L
+#define RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK             0x00000002L
+#define RBBM_INT_CNTL__GUI_IDLE_INT_MASK                   0x00080000L
+
+#define RBBM_STATUS__CMDFIFO_AVAIL_MASK                    0x0000001fL
+#define RBBM_STATUS__TC_BUSY_MASK                          0x00000020L
+#define RBBM_STATUS__HIRQ_PENDING_MASK                     0x00000100L
+#define RBBM_STATUS__CPRQ_PENDING_MASK                     0x00000200L
+#define RBBM_STATUS__CFRQ_PENDING_MASK                     0x00000400L
+#define RBBM_STATUS__PFRQ_PENDING_MASK                     0x00000800L
+#define RBBM_STATUS__VGT_BUSY_NO_DMA_MASK                  0x00001000L
+#define RBBM_STATUS__RBBM_WU_BUSY_MASK                     0x00004000L
+#define RBBM_STATUS__CP_NRT_BUSY_MASK                      0x00010000L
+#define RBBM_STATUS__MH_BUSY_MASK                          0x00040000L
+#define RBBM_STATUS__MH_COHERENCY_BUSY_MASK                0x00080000L
+#define RBBM_STATUS__SX_BUSY_MASK                          0x00200000L
+#define RBBM_STATUS__TPC_BUSY_MASK                         0x00400000L
+#define RBBM_STATUS__SC_CNTX_BUSY_MASK                     0x01000000L
+#define RBBM_STATUS__PA_BUSY_MASK                          0x02000000L
+#define RBBM_STATUS__VGT_BUSY_MASK                         0x04000000L
+#define RBBM_STATUS__SQ_CNTX17_BUSY_MASK                   0x08000000L
+#define RBBM_STATUS__SQ_CNTX0_BUSY_MASK                    0x10000000L
+#define RBBM_STATUS__RB_CNTX_BUSY_MASK                     0x40000000L
+#define RBBM_STATUS__GUI_ACTIVE_MASK                       0x80000000L
+
+#define CP_INT_CNTL__SW_INT_MASK                           0x00080000L
+#define CP_INT_CNTL__T0_PACKET_IN_IB_MASK                  0x00800000L
+#define CP_INT_CNTL__OPCODE_ERROR_MASK                     0x01000000L
+#define CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK             0x02000000L
+#define CP_INT_CNTL__RESERVED_BIT_ERROR_MASK               0x04000000L
+#define CP_INT_CNTL__IB_ERROR_MASK                         0x08000000L
+#define CP_INT_CNTL__IB2_INT_MASK                          0x20000000L
+#define CP_INT_CNTL__IB1_INT_MASK                          0x40000000L
+#define CP_INT_CNTL__RB_INT_MASK                           0x80000000L
+
+#define MASTER_INT_SIGNAL__MH_INT_STAT                     0x00000020L
+#define MASTER_INT_SIGNAL__SQ_INT_STAT                     0x04000000L
+#define MASTER_INT_SIGNAL__CP_INT_STAT                     0x40000000L
+#define MASTER_INT_SIGNAL__RBBM_INT_STAT                   0x80000000L
+
+#define RB_EDRAM_INFO__EDRAM_SIZE_MASK                     0x0000000fL
+#define RB_EDRAM_INFO__EDRAM_RANGE_MASK                    0xffffc000L
+
+#define MH_ARBITER_CONFIG__SAME_PAGE_GRANULARITY__SHIFT    0x00000006
+#define MH_ARBITER_CONFIG__L1_ARB_ENABLE__SHIFT            0x00000007
+#define MH_ARBITER_CONFIG__L1_ARB_HOLD_ENABLE__SHIFT       0x00000008
+#define MH_ARBITER_CONFIG__L2_ARB_CONTROL__SHIFT           0x00000009
+#define MH_ARBITER_CONFIG__PAGE_SIZE__SHIFT                0x0000000a
+#define MH_ARBITER_CONFIG__TC_REORDER_ENABLE__SHIFT        0x0000000d
+#define MH_ARBITER_CONFIG__TC_ARB_HOLD_ENABLE__SHIFT       0x0000000e
+#define MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT_ENABLE__SHIFT   0x0000000f
+#define MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT__SHIFT          0x00000010
+#define MH_ARBITER_CONFIG__CP_CLNT_ENABLE__SHIFT           0x00000016
+#define MH_ARBITER_CONFIG__VGT_CLNT_ENABLE__SHIFT          0x00000017
+#define MH_ARBITER_CONFIG__TC_CLNT_ENABLE__SHIFT           0x00000018
+#define MH_ARBITER_CONFIG__RB_CLNT_ENABLE__SHIFT           0x00000019
+#define MH_ARBITER_CONFIG__PA_CLNT_ENABLE__SHIFT           0x0000001a
+
+#define MH_MMU_CONFIG__RB_W_CLNT_BEHAVIOR__SHIFT           0x00000004
+#define MH_MMU_CONFIG__CP_W_CLNT_BEHAVIOR__SHIFT           0x00000006
+#define MH_MMU_CONFIG__CP_R0_CLNT_BEHAVIOR__SHIFT          0x00000008
+#define MH_MMU_CONFIG__CP_R1_CLNT_BEHAVIOR__SHIFT          0x0000000a
+#define MH_MMU_CONFIG__CP_R2_CLNT_BEHAVIOR__SHIFT          0x0000000c
+#define MH_MMU_CONFIG__CP_R3_CLNT_BEHAVIOR__SHIFT          0x0000000e
+#define MH_MMU_CONFIG__CP_R4_CLNT_BEHAVIOR__SHIFT          0x00000010
+#define MH_MMU_CONFIG__VGT_R0_CLNT_BEHAVIOR__SHIFT         0x00000012
+#define MH_MMU_CONFIG__VGT_R1_CLNT_BEHAVIOR__SHIFT         0x00000014
+#define MH_MMU_CONFIG__TC_R_CLNT_BEHAVIOR__SHIFT           0x00000016
+#define MH_MMU_CONFIG__PA_W_CLNT_BEHAVIOR__SHIFT           0x00000018
+
+#define CP_RB_CNTL__RB_BUFSZ__SHIFT                        0x00000000
+#define CP_RB_CNTL__RB_BLKSZ__SHIFT                        0x00000008
+#define CP_RB_CNTL__RB_POLL_EN__SHIFT                      0x00000014
+#define CP_RB_CNTL__RB_NO_UPDATE__SHIFT                    0x0000001b
+
+#define RB_COLOR_INFO__COLOR_FORMAT__SHIFT                 0x00000000
+#define RB_EDRAM_INFO__EDRAM_MAPPING_MODE__SHIFT           0x00000004
+#define RB_EDRAM_INFO__EDRAM_RANGE__SHIFT                  0x0000000e
+
+#define REG_CP_CSQ_IB1_STAT              0x01FE
+#define REG_CP_CSQ_IB2_STAT              0x01FF
+#define REG_CP_CSQ_RB_STAT               0x01FD
+#define REG_CP_DEBUG                     0x01FC
+#define REG_CP_IB1_BASE                  0x0458
+#define REG_CP_IB1_BUFSZ                 0x0459
+#define REG_CP_IB2_BASE                  0x045A
+#define REG_CP_IB2_BUFSZ                 0x045B
+#define REG_CP_INT_ACK                   0x01F4
+#define REG_CP_INT_CNTL                  0x01F2
+#define REG_CP_INT_STATUS                0x01F3
+#define REG_CP_ME_CNTL                   0x01F6
+#define REG_CP_ME_RAM_DATA               0x01FA
+#define REG_CP_ME_RAM_WADDR              0x01F8
+#define REG_CP_ME_STATUS                 0x01F7
+#define REG_CP_PFP_UCODE_ADDR            0x00C0
+#define REG_CP_PFP_UCODE_DATA            0x00C1
+#define REG_CP_QUEUE_THRESHOLDS          0x01D5
+#define REG_CP_RB_BASE                   0x01C0
+#define REG_CP_RB_CNTL                   0x01C1
+#define REG_CP_RB_RPTR                   0x01C4
+#define REG_CP_RB_RPTR_ADDR              0x01C3
+#define REG_CP_RB_RPTR_WR                0x01C7
+#define REG_CP_RB_WPTR                   0x01C5
+#define REG_CP_RB_WPTR_BASE              0x01C8
+#define REG_CP_RB_WPTR_DELAY             0x01C6
+#define REG_CP_STAT                      0x047F
+#define REG_CP_STATE_DEBUG_DATA          0x01ED
+#define REG_CP_STATE_DEBUG_INDEX         0x01EC
+#define REG_CP_ST_BASE                   0x044D
+#define REG_CP_ST_BUFSZ                  0x044E
+
+#define REG_CP_PERFMON_CNTL              0x0444
+#define REG_CP_PERFCOUNTER_SELECT        0x0445
+#define REG_CP_PERFCOUNTER_LO            0x0446
+#define REG_CP_PERFCOUNTER_HI            0x0447
+
+#define REG_RBBM_PERFCOUNTER1_SELECT     0x0395
+#define REG_RBBM_PERFCOUNTER1_HI         0x0398
+#define REG_RBBM_PERFCOUNTER1_LO         0x0397
+
+#define REG_MASTER_INT_SIGNAL            0x03B7
+
+#define REG_MH_ARBITER_CONFIG            0x0A40
+#define REG_MH_INTERRUPT_CLEAR           0x0A44
+#define REG_MH_INTERRUPT_MASK            0x0A42
+#define REG_MH_INTERRUPT_STATUS          0x0A43
+#define REG_MH_MMU_CONFIG                0x0040
+#define REG_MH_MMU_INVALIDATE            0x0045
+#define REG_MH_MMU_MPU_BASE              0x0046
+#define REG_MH_MMU_MPU_END               0x0047
+#define REG_MH_MMU_PAGE_FAULT            0x0043
+#define REG_MH_MMU_PT_BASE               0x0042
+#define REG_MH_MMU_TRAN_ERROR            0x0044
+#define REG_MH_MMU_VA_RANGE              0x0041
+#define REG_MH_CLNT_INTF_CTRL_CONFIG1    0x0A54
+#define REG_MH_CLNT_INTF_CTRL_CONFIG2    0x0A55
+
+#define REG_PA_CL_VPORT_XSCALE           0x210F
+#define REG_PA_CL_VPORT_ZOFFSET          0x2114
+#define REG_PA_CL_VPORT_ZSCALE           0x2113
+#define REG_PA_CL_CLIP_CNTL              0x2204
+#define REG_PA_CL_VTE_CNTL               0x2206
+#define REG_PA_SC_AA_MASK                0x2312
+#define REG_PA_SC_LINE_CNTL              0x2300
+#define REG_PA_SC_SCREEN_SCISSOR_BR      0x200F
+#define REG_PA_SC_SCREEN_SCISSOR_TL      0x200E
+#define REG_PA_SC_VIZ_QUERY              0x2293
+#define REG_PA_SC_VIZ_QUERY_STATUS       0x0C44
+#define REG_PA_SC_WINDOW_OFFSET          0x2080
+#define REG_PA_SC_WINDOW_SCISSOR_BR      0x2082
+#define REG_PA_SC_WINDOW_SCISSOR_TL      0x2081
+#define REG_PA_SU_FACE_DATA              0x0C86
+#define REG_PA_SU_POINT_SIZE             0x2280
+#define REG_PA_SU_LINE_CNTL              0x2282
+#define REG_PA_SU_POLY_OFFSET_BACK_OFFSET 0x2383
+#define REG_PA_SU_POLY_OFFSET_FRONT_SCALE 0x2380
+#define REG_PA_SU_SC_MODE_CNTL           0x2205
+
+#define REG_PC_INDEX_OFFSET              0x2102
+
+#define REG_RBBM_CNTL                    0x003B
+#define REG_RBBM_INT_ACK                 0x03B6
+#define REG_RBBM_INT_CNTL                0x03B4
+#define REG_RBBM_INT_STATUS              0x03B5
+#define REG_RBBM_PATCH_RELEASE           0x0001
+#define REG_RBBM_PERIPHID1               0x03F9
+#define REG_RBBM_PERIPHID2               0x03FA
+#define REG_RBBM_DEBUG                   0x039B
+#define REG_RBBM_DEBUG_OUT               0x03A0
+#define REG_RBBM_DEBUG_CNTL              0x03A1
+#define REG_RBBM_PM_OVERRIDE1            0x039C
+#define REG_RBBM_PM_OVERRIDE2            0x039D
+#define REG_RBBM_READ_ERROR              0x03B3
+#define REG_RBBM_SOFT_RESET              0x003C
+#define REG_RBBM_STATUS                  0x05D0
+
+#define REG_RB_COLORCONTROL              0x2202
+#define REG_RB_COLOR_DEST_MASK           0x2326
+#define REG_RB_COLOR_MASK                0x2104
+#define REG_RB_COPY_CONTROL              0x2318
+#define REG_RB_DEPTHCONTROL              0x2200
+#define REG_RB_EDRAM_INFO                0x0F02
+#define REG_RB_MODECONTROL               0x2208
+#define REG_RB_SURFACE_INFO              0x2000
+#define REG_RB_SAMPLE_POS                0x220a
+
+#define REG_SCRATCH_ADDR                 0x01DD
+#define REG_SCRATCH_REG0                 0x0578
+#define REG_SCRATCH_REG2                 0x057A
+#define REG_SCRATCH_UMSK                 0x01DC
+
+#define REG_SQ_CF_BOOLEANS               0x4900
+#define REG_SQ_CF_LOOP                   0x4908
+#define REG_SQ_GPR_MANAGEMENT            0x0D00
+#define REG_SQ_INST_STORE_MANAGMENT      0x0D02
+#define REG_SQ_INT_ACK                   0x0D36
+#define REG_SQ_INT_CNTL                  0x0D34
+#define REG_SQ_INT_STATUS                0x0D35
+#define REG_SQ_PROGRAM_CNTL              0x2180
+#define REG_SQ_PS_PROGRAM                0x21F6
+#define REG_SQ_VS_PROGRAM                0x21F7
+#define REG_SQ_WRAPPING_0                0x2183
+#define REG_SQ_WRAPPING_1                0x2184
+
+#define REG_VGT_ENHANCE                  0x2294
+#define REG_VGT_INDX_OFFSET              0x2102
+#define REG_VGT_MAX_VTX_INDX             0x2100
+#define REG_VGT_MIN_VTX_INDX             0x2101
+
+#define REG_TP0_CHICKEN                  0x0E1E
+#define REG_TC_CNTL_STATUS               0x0E00
+#define REG_PA_SC_AA_CONFIG              0x2301
+#define REG_VGT_VERTEX_REUSE_BLOCK_CNTL  0x2316
+#define REG_SQ_INTERPOLATOR_CNTL         0x2182
+#define REG_RB_DEPTH_INFO                0x2002
+#define REG_COHER_DEST_BASE_0            0x2006
+#define REG_RB_FOG_COLOR                 0x2109
+#define REG_RB_STENCILREFMASK_BF         0x210C
+#define REG_PA_SC_LINE_STIPPLE           0x2283
+#define REG_SQ_PS_CONST                  0x2308
+#define REG_RB_DEPTH_CLEAR               0x231D
+#define REG_RB_SAMPLE_COUNT_CTL          0x2324
+#define REG_SQ_CONSTANT_0                0x4000
+#define REG_SQ_FETCH_0                   0x4800
+
+#define REG_MH_AXI_ERROR                 0xA45
+#define REG_MH_DEBUG_CTRL                0xA4E
+#define REG_MH_DEBUG_DATA                0xA4F
+#define REG_COHER_BASE_PM4               0xA2A
+#define REG_COHER_STATUS_PM4             0xA2B
+#define REG_COHER_SIZE_PM4               0xA29
+
+#endif /* __A200_REG_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.c
new file mode 100644
index 0000000..f4de5b9
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.c
@@ -0,0 +1,1370 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301, USA.
+ *
+ */
+#include <linux/delay.h>
+#include <linux/uaccess.h>
+
+#include <linux/vmalloc.h>
+
+#include "kgsl.h"
+#include "kgsl_cffdump.h"
+#include "adreno.h"
+#include "adreno_pm4types.h"
+#include "adreno_debugfs.h"
+#include "adreno_postmortem.h"
+
+#define DRIVER_VERSION_MAJOR   3
+#define DRIVER_VERSION_MINOR   1
+
+#define GSL_RBBM_INT_MASK \
+	 (RBBM_INT_CNTL__RDERR_INT_MASK |  \
+	  RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK)
+
+#define GSL_SQ_INT_MASK \
+	(SQ_INT_CNTL__PS_WATCHDOG_MASK | \
+	 SQ_INT_CNTL__VS_WATCHDOG_MASK)
+
+/* Yamato MH arbiter config*/
+#define KGSL_CFG_YAMATO_MHARB \
+	(0x10 \
+		| (0 << MH_ARBITER_CONFIG__SAME_PAGE_GRANULARITY__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__L1_ARB_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__L1_ARB_HOLD_ENABLE__SHIFT) \
+		| (0 << MH_ARBITER_CONFIG__L2_ARB_CONTROL__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__PAGE_SIZE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__TC_REORDER_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__TC_ARB_HOLD_ENABLE__SHIFT) \
+		| (0 << MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT_ENABLE__SHIFT) \
+		| (0x8 << MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__CP_CLNT_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__VGT_CLNT_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__TC_CLNT_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__RB_CLNT_ENABLE__SHIFT) \
+		| (1 << MH_ARBITER_CONFIG__PA_CLNT_ENABLE__SHIFT))
+
+#define YAMATO_MMU_CONFIG						\
+	(0x01								\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__RB_W_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_W_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R0_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R1_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R2_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R3_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R4_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__VGT_R0_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__VGT_R1_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__TC_R_CLNT_BEHAVIOR__SHIFT)	\
+	 | (MMU_CONFIG << MH_MMU_CONFIG__PA_W_CLNT_BEHAVIOR__SHIFT))
+
+/* max msecs to wait for gpu to finish its operation(s) */
+#define MAX_WAITGPU_SECS (HZ + HZ/2)
+
+static struct kgsl_yamato_device yamato_device = {
+	.dev = {
+		.name = DEVICE_3D0_NAME,
+		.id = KGSL_DEVICE_YAMATO,
+		.ver_major = DRIVER_VERSION_MAJOR,
+		.ver_minor = DRIVER_VERSION_MINOR,
+		.mmu = {
+			.config = YAMATO_MMU_CONFIG,
+			/* turn off memory protection unit by setting
+			   acceptable physical address range to include
+			   all pages. */
+			.mpu_base = 0x00000000,
+			.mpu_range =  0xFFFFF000,
+			.reg = {
+				.config = REG_MH_MMU_CONFIG,
+				.mpu_base = REG_MH_MMU_MPU_BASE,
+				.mpu_end = REG_MH_MMU_MPU_END,
+				.va_range = REG_MH_MMU_VA_RANGE,
+				.pt_page = REG_MH_MMU_PT_BASE,
+				.page_fault = REG_MH_MMU_PAGE_FAULT,
+				.tran_error = REG_MH_MMU_TRAN_ERROR,
+				.invalidate = REG_MH_MMU_INVALIDATE,
+				.interrupt_mask = REG_MH_INTERRUPT_MASK,
+				.interrupt_status = REG_MH_INTERRUPT_STATUS,
+				.interrupt_clear = REG_MH_INTERRUPT_CLEAR,
+				.axi_error = REG_MH_AXI_ERROR,
+			},
+		},
+		.pwrctrl = {
+			.pwr_rail = PWR_RAIL_GRP_CLK,
+			.regulator_name = "fs_gfx3d",
+			.irq_name = KGSL_3D0_IRQ,
+			.src_clk_name = "grp_src_clk",
+		},
+		.mutex = __MUTEX_INITIALIZER(yamato_device.dev.mutex),
+		.state = KGSL_STATE_INIT,
+		.active_cnt = 0,
+		.iomemname = KGSL_3D0_REG_MEMORY,
+	},
+	.gmemspace = {
+		.gpu_base = 0,
+		.sizebytes = SZ_256K,
+	},
+	.pfp_fw = NULL,
+	.pm4_fw = NULL,
+};
+
+static void __devinit kgsl_yamato_getfunctable(struct kgsl_functable *ftbl);
+
+static int kgsl_yamato_gmeminit(struct kgsl_yamato_device *yamato_device)
+{
+	struct kgsl_device *device = &yamato_device->dev;
+	union reg_rb_edram_info rb_edram_info;
+	unsigned int gmem_size;
+	unsigned int edram_value = 0;
+
+	/* make sure edram range is aligned to size */
+	BUG_ON(yamato_device->gmemspace.gpu_base &
+				(yamato_device->gmemspace.sizebytes - 1));
+
+	/* get edram_size value equivalent */
+	gmem_size = (yamato_device->gmemspace.sizebytes >> 14);
+	while (gmem_size >>= 1)
+		edram_value++;
+
+	rb_edram_info.val = 0;
+
+	rb_edram_info.f.edram_size = edram_value;
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
+		rb_edram_info.f.edram_mapping_mode = 0; /* EDRAM_MAP_UPPER */
+
+	/* must be aligned to size */
+	rb_edram_info.f.edram_range = (yamato_device->gmemspace.gpu_base >> 14);
+
+	kgsl_yamato_regwrite(device, REG_RB_EDRAM_INFO, rb_edram_info.val);
+
+	return 0;
+}
+
+static int kgsl_yamato_gmemclose(struct kgsl_device *device)
+{
+	kgsl_yamato_regwrite(device, REG_RB_EDRAM_INFO, 0x00000000);
+
+	return 0;
+}
+
+static void kgsl_yamato_rbbm_intrcallback(struct kgsl_device *device)
+{
+	unsigned int status = 0;
+	unsigned int rderr = 0;
+
+	kgsl_yamato_regread_isr(device, REG_RBBM_INT_STATUS, &status);
+
+	if (status & RBBM_INT_CNTL__RDERR_INT_MASK) {
+		union rbbm_read_error_u rerr;
+		kgsl_yamato_regread_isr(device, REG_RBBM_READ_ERROR, &rderr);
+		rerr.val = rderr;
+		if (rerr.f.read_address == REG_CP_INT_STATUS &&
+			rerr.f.read_error &&
+			rerr.f.read_requester)
+			KGSL_DRV_WARN(device,
+				"rbbm read error interrupt: %08x\n", rderr);
+		else
+			KGSL_DRV_CRIT(device,
+				"rbbm read error interrupt: %08x\n", rderr);
+	} else if (status & RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK) {
+		KGSL_DRV_INFO(device, "rbbm display update interrupt\n");
+	} else if (status & RBBM_INT_CNTL__GUI_IDLE_INT_MASK) {
+		KGSL_DRV_INFO(device, "rbbm gui idle interrupt\n");
+	} else {
+		KGSL_CMD_WARN(device,
+			"bad bits in REG_CP_INT_STATUS %08x\n", status);
+	}
+
+	status &= GSL_RBBM_INT_MASK;
+	kgsl_yamato_regwrite_isr(device, REG_RBBM_INT_ACK, status);
+}
+
+static void kgsl_yamato_sq_intrcallback(struct kgsl_device *device)
+{
+	unsigned int status = 0;
+
+	kgsl_yamato_regread_isr(device, REG_SQ_INT_STATUS, &status);
+
+	if (status & SQ_INT_CNTL__PS_WATCHDOG_MASK)
+		KGSL_DRV_INFO(device, "sq ps watchdog interrupt\n");
+	else if (status & SQ_INT_CNTL__VS_WATCHDOG_MASK)
+		KGSL_DRV_INFO(device, "sq vs watchdog interrupt\n");
+	else
+		KGSL_DRV_WARN(device,
+			"bad bits in REG_SQ_INT_STATUS %08x\n", status);
+
+
+	status &= GSL_SQ_INT_MASK;
+	kgsl_yamato_regwrite_isr(device, REG_SQ_INT_ACK, status);
+}
+
+irqreturn_t kgsl_yamato_isr(int irq, void *data)
+{
+	irqreturn_t result = IRQ_NONE;
+	struct kgsl_device *device;
+	unsigned int status;
+
+	device = (struct kgsl_device *) data;
+
+	BUG_ON(device == NULL);
+	BUG_ON(device->regspace.sizebytes == 0);
+	BUG_ON(device->regspace.mmio_virt_base == 0);
+
+	kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL, &status);
+
+	if (status & MASTER_INT_SIGNAL__MH_INT_STAT) {
+		kgsl_mh_intrcallback(device);
+		result = IRQ_HANDLED;
+	}
+
+	if (status & MASTER_INT_SIGNAL__CP_INT_STAT) {
+		kgsl_cp_intrcallback(device);
+		result = IRQ_HANDLED;
+	}
+
+	if (status & MASTER_INT_SIGNAL__RBBM_INT_STAT) {
+		kgsl_yamato_rbbm_intrcallback(device);
+		result = IRQ_HANDLED;
+	}
+
+	if (status & MASTER_INT_SIGNAL__SQ_INT_STAT) {
+		kgsl_yamato_sq_intrcallback(device);
+		result = IRQ_HANDLED;
+	}
+
+	if (device->requested_state == KGSL_STATE_NONE) {
+		if (device->pwrctrl.nap_allowed == true) {
+			device->requested_state = KGSL_STATE_NAP;
+			queue_work(device->work_queue, &device->idle_check_ws);
+		} else if (device->pwrctrl.idle_pass == true) {
+			queue_work(device->work_queue, &device->idle_check_ws);
+		}
+	}
+
+	/* Reset the time-out in our idle timer */
+	mod_timer(&device->idle_timer,
+		jiffies + device->pwrctrl.interval_timeout);
+	return result;
+}
+
+static int kgsl_yamato_cleanup_pt(struct kgsl_device *device,
+			struct kgsl_pagetable *pagetable)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+
+	kgsl_mmu_unmap(pagetable, &rb->buffer_desc);
+
+	kgsl_mmu_unmap(pagetable, &rb->memptrs_desc);
+
+	kgsl_mmu_unmap(pagetable, &device->memstore);
+
+	kgsl_mmu_unmap(pagetable, &device->mmu.dummyspace);
+
+	return 0;
+}
+
+static int kgsl_yamato_setup_pt(struct kgsl_device *device,
+			struct kgsl_pagetable *pagetable)
+{
+	int result = 0;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+
+	BUG_ON(rb->buffer_desc.physaddr == 0);
+	BUG_ON(rb->memptrs_desc.physaddr == 0);
+	BUG_ON(device->memstore.physaddr == 0);
+#ifdef CONFIG_MSM_KGSL_MMU
+	BUG_ON(device->mmu.dummyspace.physaddr == 0);
+#endif
+	result = kgsl_mmu_map_global(pagetable, &rb->buffer_desc,
+				     GSL_PT_PAGE_RV);
+	if (result)
+		goto error;
+
+	result = kgsl_mmu_map_global(pagetable, &rb->memptrs_desc,
+				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
+	if (result)
+		goto unmap_buffer_desc;
+
+	result = kgsl_mmu_map_global(pagetable, &device->memstore,
+				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
+	if (result)
+		goto unmap_memptrs_desc;
+
+	result = kgsl_mmu_map_global(pagetable, &device->mmu.dummyspace,
+				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
+	if (result)
+		goto unmap_memstore_desc;
+
+	return result;
+
+unmap_memstore_desc:
+	kgsl_mmu_unmap(pagetable, &device->memstore);
+
+unmap_memptrs_desc:
+	kgsl_mmu_unmap(pagetable, &rb->memptrs_desc);
+
+unmap_buffer_desc:
+	kgsl_mmu_unmap(pagetable, &rb->buffer_desc);
+
+error:
+	return result;
+}
+
+static int kgsl_yamato_setstate(struct kgsl_device *device, uint32_t flags)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	unsigned int link[32];
+	unsigned int *cmds = &link[0];
+	int sizedwords = 0;
+	unsigned int mh_mmu_invalidate = 0x00000003; /*invalidate all and tc */
+
+#ifndef CONFIG_MSM_KGSL_MMU
+	return 0;
+#endif
+	/* if possible, set via command stream,
+	* otherwise set via direct register writes
+	*/
+	if (yamato_device->drawctxt_active) {
+		if (flags & KGSL_MMUFLAGS_PTUPDATE) {
+			/* wait for graphics pipe to be idle */
+			*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+			*cmds++ = 0x00000000;
+
+			/* set page table base */
+			*cmds++ = pm4_type0_packet(REG_MH_MMU_PT_BASE, 1);
+			*cmds++ = device->mmu.hwpagetable->base.gpuaddr;
+			sizedwords += 4;
+		}
+
+		if (flags & KGSL_MMUFLAGS_TLBFLUSH) {
+			if (!(flags & KGSL_MMUFLAGS_PTUPDATE)) {
+				*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE,
+								1);
+				*cmds++ = 0x00000000;
+				sizedwords += 2;
+			}
+			*cmds++ = pm4_type0_packet(REG_MH_MMU_INVALIDATE, 1);
+			*cmds++ = mh_mmu_invalidate;
+			sizedwords += 2;
+		}
+
+		if (flags & KGSL_MMUFLAGS_PTUPDATE &&
+			device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+			/* HW workaround: to resolve MMU page fault interrupts
+			* caused by the VGT.It prevents the CP PFP from filling
+			* the VGT DMA request fifo too early,thereby ensuring
+			* that the VGT will not fetch vertex/bin data until
+			* after the page table base register has been updated.
+			*
+			* Two null DRAW_INDX_BIN packets are inserted right
+			* after the page table base update, followed by a
+			* wait for idle. The null packets will fill up the
+			* VGT DMA request fifo and prevent any further
+			* vertex/bin updates from occurring until the wait
+			* has finished. */
+			*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+			*cmds++ = (0x4 << 16) |
+				(REG_PA_SU_SC_MODE_CNTL - 0x2000);
+			*cmds++ = 0;	  /* disable faceness generation */
+			*cmds++ = pm4_type3_packet(PM4_SET_BIN_BASE_OFFSET, 1);
+			*cmds++ = device->mmu.dummyspace.gpuaddr;
+			*cmds++ = pm4_type3_packet(PM4_DRAW_INDX_BIN, 6);
+			*cmds++ = 0;	  /* viz query info */
+			*cmds++ = 0x0003C004; /* draw indicator */
+			*cmds++ = 0;	  /* bin base */
+			*cmds++ = 3;	  /* bin size */
+			*cmds++ = device->mmu.dummyspace.gpuaddr; /* dma base */
+			*cmds++ = 6;	  /* dma size */
+			*cmds++ = pm4_type3_packet(PM4_DRAW_INDX_BIN, 6);
+			*cmds++ = 0;	  /* viz query info */
+			*cmds++ = 0x0003C004; /* draw indicator */
+			*cmds++ = 0;	  /* bin base */
+			*cmds++ = 3;	  /* bin size */
+			/* dma base */
+			*cmds++ = device->mmu.dummyspace.gpuaddr;
+			*cmds++ = 6;	  /* dma size */
+			*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+			*cmds++ = 0x00000000;
+			sizedwords += 21;
+		}
+
+		if (flags & (KGSL_MMUFLAGS_PTUPDATE | KGSL_MMUFLAGS_TLBFLUSH)) {
+			*cmds++ = pm4_type3_packet(PM4_INVALIDATE_STATE, 1);
+			*cmds++ = 0x7fff; /* invalidate all base pointers */
+			sizedwords += 2;
+		}
+
+		kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
+					&link[0], sizedwords);
+	} else {
+		if (flags & KGSL_MMUFLAGS_PTUPDATE) {
+			kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+			kgsl_yamato_regwrite(device, REG_MH_MMU_PT_BASE,
+				     device->mmu.hwpagetable->base.gpuaddr);
+		}
+
+		if (flags & KGSL_MMUFLAGS_TLBFLUSH) {
+			kgsl_yamato_regwrite(device, REG_MH_MMU_INVALIDATE,
+					   mh_mmu_invalidate);
+		}
+	}
+
+	return 0;
+}
+
+static unsigned int
+kgsl_yamato_getchipid(struct kgsl_device *device)
+{
+	unsigned int chipid;
+	unsigned int coreid, majorid, minorid, patchid, revid;
+
+	/* YDX */
+	kgsl_yamato_regread(device, REG_RBBM_PERIPHID1, &coreid);
+	coreid &= 0xF;
+
+	kgsl_yamato_regread(device, REG_RBBM_PERIPHID2, &majorid);
+	majorid = (majorid >> 4) & 0xF;
+
+	kgsl_yamato_regread(device, REG_RBBM_PATCH_RELEASE, &revid);
+	/* this is a 16bit field, but extremely unlikely it would ever get
+	* this high
+	*/
+	minorid = ((revid >> 0)  & 0xFF);
+
+
+	patchid = ((revid >> 16) & 0xFF);
+
+	chipid  = ((coreid << 24) | (majorid << 16) |
+			(minorid << 8) | (patchid << 0));
+
+	/* Hardware revision 211 (8650) returns the wrong chip ID */
+	if (chipid == KGSL_CHIPID_YAMATODX_REV21)
+		chipid = KGSL_CHIPID_YAMATODX_REV211;
+
+	/* Workaround Hardware revision issue of Z470 */
+	if (chipid == KGSL_CHIPID_LEIA_REV470_TEMP)
+		chipid = KGSL_CHIPID_LEIA_REV470;
+
+
+	return chipid;
+}
+
+static int __devinit
+kgsl_3d_probe(struct platform_device *pdev)
+{
+	struct kgsl_device *device;
+	struct kgsl_yamato_device *device_3d = NULL;
+	int status = -EINVAL;
+
+	device = (struct kgsl_device *)pdev->id_entry->driver_data;
+	device_3d = KGSL_YAMATO_DEVICE(device);
+	device->pdev = pdev;
+
+	init_completion(&device->recovery_gate);
+
+	kgsl_yamato_getfunctable(&device->ftbl);
+
+	status = kgsl_ringbuffer_init(device);
+	if (status != 0)
+		goto error;
+
+	status = kgsl_device_platform_probe(device, kgsl_yamato_isr);
+	if (status)
+		goto error_close_rb;
+
+	kgsl_yamato_debugfs_init(device);
+
+	device->flags &= ~KGSL_FLAGS_SOFT_RESET;
+	return 0;
+
+error_close_rb:
+	kgsl_ringbuffer_close(&device_3d->ringbuffer);
+error:
+	device->pdev = NULL;
+	return status;
+}
+
+static int __devexit kgsl_3d_remove(struct platform_device *pdev)
+{
+	struct kgsl_device *device = NULL;
+	struct kgsl_yamato_device *device_3d = NULL;
+
+	device = (struct kgsl_device *)pdev->id_entry->driver_data;
+	device_3d = KGSL_YAMATO_DEVICE(device);
+
+	kgsl_device_platform_remove(device);
+
+	kgsl_ringbuffer_close(&device_3d->ringbuffer);
+
+	return 0;
+}
+
+static int kgsl_yamato_start(struct kgsl_device *device, unsigned int init_ram)
+{
+	int status = -EINVAL;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	int init_reftimestamp = 0x7fffffff;
+
+	device->state = KGSL_STATE_INIT;
+	device->requested_state = KGSL_STATE_NONE;
+	/* Order pwrrail/clk sequence based upon platform. */
+	if (device->pwrctrl.pwrrail_first)
+		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_ON);
+	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_ON);
+	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_ON);
+	if (!device->pwrctrl.pwrrail_first)
+		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_ON);
+
+	if (kgsl_mmu_start(device))
+		goto error_clk_off;
+
+	/*We need to make sure all blocks are powered up and clocked before
+	*issuing a soft reset.  The overrides will then be turned off (set to 0)
+	*/
+	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE1, 0xfffffffe);
+	device->chip_id = kgsl_yamato_getchipid(device);
+
+	if (device->chip_id == CHIP_REV_251)
+		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0x000000ff);
+	else
+		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0xffffffff);
+
+	/* Only reset CP block if all blocks have previously been reset */
+	if (!(device->flags & KGSL_FLAGS_SOFT_RESET) ||
+		(device->chip_id != KGSL_CHIPID_LEIA_REV470)) {
+		kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0xFFFFFFFF);
+		device->flags |= KGSL_FLAGS_SOFT_RESET;
+	} else
+		kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0x00000001);
+
+	/* The core is in an indeterminate state until the reset completes
+	 * after 30ms.
+	 */
+	msleep(30);
+
+	kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0x00000000);
+
+	kgsl_yamato_regwrite(device, REG_RBBM_CNTL, 0x00004442);
+
+	kgsl_yamato_regwrite(device, REG_MH_ARBITER_CONFIG,
+				KGSL_CFG_YAMATO_MHARB);
+
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		kgsl_yamato_regwrite(device,
+			 REG_MH_CLNT_INTF_CTRL_CONFIG1, 0x00030f27);
+		kgsl_yamato_regwrite(device,
+			 REG_MH_CLNT_INTF_CTRL_CONFIG2, 0x00472747);
+	}
+
+	/* Remove 1k boundary check in z470 to avoid GPU hang.
+	   Notice that, this solution won't work if both EBI and SMI are used */
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
+		kgsl_yamato_regwrite(device, REG_MH_CLNT_INTF_CTRL_CONFIG1,
+				 0x00032f07);
+	}
+
+	kgsl_yamato_regwrite(device, REG_SQ_VS_PROGRAM, 0x00000000);
+	kgsl_yamato_regwrite(device, REG_SQ_PS_PROGRAM, 0x00000000);
+
+	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE1, 0);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
+		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0);
+	else
+		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0x80);
+
+	kgsl_sharedmem_writel(&device->memstore,
+			      KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
+			      init_reftimestamp);
+
+	kgsl_yamato_regwrite(device, REG_RBBM_DEBUG, 0x00080000);
+
+	kgsl_yamato_regwrite(device, REG_RBBM_INT_CNTL, GSL_RBBM_INT_MASK);
+
+	/* make sure SQ interrupts are disabled */
+	kgsl_yamato_regwrite(device, REG_SQ_INT_CNTL, 0);
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		yamato_device->gmemspace.sizebytes = SZ_512K;
+	else
+		yamato_device->gmemspace.sizebytes = SZ_256K;
+	kgsl_yamato_gmeminit(yamato_device);
+
+	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_ON);
+
+	status = kgsl_ringbuffer_start(&yamato_device->ringbuffer, init_ram);
+	if (status != 0)
+		goto error_irq_off;
+
+	mod_timer(&device->idle_timer, jiffies + FIRST_TIMEOUT);
+	return status;
+
+error_irq_off:
+	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
+error_clk_off:
+	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_OFF);
+	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_OFF);
+
+	kgsl_mmu_stop(device);
+	return status;
+}
+
+static int kgsl_yamato_stop(struct kgsl_device *device)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	del_timer(&device->idle_timer);
+	kgsl_yamato_regwrite(device, REG_RBBM_INT_CNTL, 0);
+
+	kgsl_yamato_regwrite(device, REG_SQ_INT_CNTL, 0);
+
+	yamato_device->drawctxt_active = NULL;
+
+	kgsl_ringbuffer_stop(&yamato_device->ringbuffer);
+
+	kgsl_yamato_gmemclose(device);
+
+	kgsl_mmu_stop(device);
+
+	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
+	if (!device->pwrctrl.pwrrail_first)
+		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_OFF);
+	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_OFF);
+	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_OFF);
+	if (device->pwrctrl.pwrrail_first)
+		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_OFF);
+
+	return 0;
+}
+
+static int
+kgsl_yamato_recover_hang(struct kgsl_device *device)
+{
+	int ret;
+	unsigned int *rb_buffer;
+	struct kgsl_yamato_device *yamato_device =
+			(struct kgsl_yamato_device *)device;
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+	unsigned int timestamp;
+	unsigned int num_rb_contents;
+	unsigned int bad_context;
+	unsigned int reftimestamp;
+	unsigned int enable_ts;
+	unsigned int soptimestamp;
+	unsigned int eoptimestamp;
+	struct kgsl_yamato_context *drawctxt;
+
+	KGSL_DRV_ERR(device, "Starting recovery from 3D GPU hang....\n");
+	rb_buffer = vmalloc(rb->buffer_desc.size);
+	if (!rb_buffer) {
+		KGSL_MEM_ERR(device,
+			"Failed to allocate memory for recovery: %x\n",
+			rb->buffer_desc.size);
+		return -ENOMEM;
+	}
+	/* Extract valid contents from rb which can stil be executed after
+	 * hang */
+	ret = kgsl_ringbuffer_extract(rb, rb_buffer, &num_rb_contents);
+	if (ret)
+		goto done;
+	timestamp = rb->timestamp;
+	KGSL_DRV_ERR(device, "Last issued timestamp: %x\n", timestamp);
+	kgsl_sharedmem_readl(&device->memstore, &bad_context,
+				KGSL_DEVICE_MEMSTORE_OFFSET(current_context));
+	kgsl_sharedmem_readl(&device->memstore, &reftimestamp,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts));
+	kgsl_sharedmem_readl(&device->memstore, &enable_ts,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable));
+	kgsl_sharedmem_readl(&device->memstore, &soptimestamp,
+				KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp));
+	kgsl_sharedmem_readl(&device->memstore, &eoptimestamp,
+				KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp));
+	rmb();
+	KGSL_CTXT_ERR(device,
+		"Context that caused a GPU hang: %x\n", bad_context);
+	/* restart device */
+	ret = kgsl_yamato_stop(device);
+	if (ret)
+		goto done;
+	ret = kgsl_yamato_start(device, true);
+	if (ret)
+		goto done;
+	KGSL_DRV_ERR(device, "Device has been restarted after hang\n");
+	/* Restore timestamp states */
+	kgsl_sharedmem_writel(&device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp),
+			soptimestamp);
+	kgsl_sharedmem_writel(&device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp),
+			eoptimestamp);
+	kgsl_sharedmem_writel(&device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp),
+			soptimestamp);
+	if (num_rb_contents) {
+		kgsl_sharedmem_writel(&device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
+			reftimestamp);
+		kgsl_sharedmem_writel(&device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
+			enable_ts);
+	}
+	wmb();
+	/* Mark the invalid context so no more commands are accepted from
+	 * that context */
+
+	drawctxt = (struct kgsl_yamato_context *) bad_context;
+
+	KGSL_CTXT_ERR(device,
+		"Context that caused a GPU hang: %x\n", bad_context);
+
+	drawctxt->flags |= CTXT_FLAGS_GPU_HANG;
+
+	/* Restore valid commands in ringbuffer */
+	kgsl_ringbuffer_restore(rb, rb_buffer, num_rb_contents);
+	rb->timestamp = timestamp;
+done:
+	vfree(rb_buffer);
+	return ret;
+}
+
+static int
+kgsl_yamato_dump_and_recover(struct kgsl_device *device)
+{
+	static int recovery;
+	int result = -ETIMEDOUT;
+
+	if (device->state == KGSL_STATE_HUNG)
+		goto done;
+	if (device->state == KGSL_STATE_DUMP_AND_RECOVER && !recovery) {
+		mutex_unlock(&device->mutex);
+		wait_for_completion(&device->recovery_gate);
+		mutex_lock(&device->mutex);
+		if (!(device->state & KGSL_STATE_HUNG))
+			/* recovery success */
+			result = 0;
+	} else {
+		INIT_COMPLETION(device->recovery_gate);
+		/* Detected a hang - trigger an automatic dump */
+		kgsl_postmortem_dump(device, 0);
+		if (!recovery) {
+			recovery = 1;
+			result = kgsl_yamato_recover_hang(device);
+			if (result)
+				device->state = KGSL_STATE_HUNG;
+			recovery = 0;
+			complete_all(&device->recovery_gate);
+		} else
+			KGSL_DRV_ERR(device,
+				"Cannot recover from another hang while "
+				"recovering from a hang\n");
+	}
+done:
+	return result;
+}
+
+static int kgsl_yamato_getproperty(struct kgsl_device *device,
+				enum kgsl_property_type type,
+				void *value,
+				unsigned int sizebytes)
+{
+	int status = -EINVAL;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+
+	switch (type) {
+	case KGSL_PROP_DEVICE_INFO:
+		{
+			struct kgsl_devinfo devinfo;
+
+			if (sizebytes != sizeof(devinfo)) {
+				status = -EINVAL;
+				break;
+			}
+
+			memset(&devinfo, 0, sizeof(devinfo));
+			devinfo.device_id = device->id+1;
+			devinfo.chip_id = device->chip_id;
+			devinfo.mmu_enabled = kgsl_mmu_isenabled(&device->mmu);
+//			devinfo.gpu_id = adreno_get_rev(adreno_dev);
+			devinfo.gpu_id = 205;
+			devinfo.gmem_gpubaseaddr = yamato_device->gmemspace.
+					gpu_base;
+			devinfo.gmem_sizebytes = yamato_device->gmemspace.
+					sizebytes;
+
+			if (copy_to_user(value, &devinfo, sizeof(devinfo)) !=
+					0) {
+				status = -EFAULT;
+				break;
+			}
+			status = 0;
+		}
+		break;
+	case KGSL_PROP_DEVICE_SHADOW:
+		{
+			struct kgsl_shadowprop shadowprop;
+
+			if (sizebytes != sizeof(shadowprop)) {
+				status = -EINVAL;
+				break;
+			}
+			memset(&shadowprop, 0, sizeof(shadowprop));
+			if (device->memstore.hostptr) {
+				/*NOTE: with mmu enabled, gpuaddr doesn't mean
+				 * anything to mmap().
+				 */
+				shadowprop.gpuaddr = device->memstore.physaddr;
+				shadowprop.size = device->memstore.size;
+				/* GSL needs this to be set, even if it
+				   appears to be meaningless */
+				shadowprop.flags = KGSL_FLAGS_INITIALIZED;
+			}
+			if (copy_to_user(value, &shadowprop,
+				sizeof(shadowprop))) {
+				status = -EFAULT;
+				break;
+			}
+			status = 0;
+		}
+		break;
+	case KGSL_PROP_MMU_ENABLE:
+		{
+#ifdef CONFIG_MSM_KGSL_MMU
+			int mmuProp = 1;
+#else
+			int mmuProp = 0;
+#endif
+			if (sizebytes != sizeof(int)) {
+				status = -EINVAL;
+				break;
+			}
+			if (copy_to_user(value, &mmuProp, sizeof(mmuProp))) {
+				status = -EFAULT;
+				break;
+			}
+			status = 0;
+		}
+		break;
+	case KGSL_PROP_INTERRUPT_WAITS:
+		{
+			int int_waits = 1;
+			if (sizebytes != sizeof(int)) {
+				status = -EINVAL;
+				break;
+			}
+			if (copy_to_user(value, &int_waits, sizeof(int))) {
+				status = -EFAULT;
+				break;
+			}
+			status = 0;
+		}
+		break;
+	default:
+		status = -EINVAL;
+	}
+
+	return status;
+}
+
+/* Caller must hold the device mutex. */
+int kgsl_yamato_idle(struct kgsl_device *device, unsigned int timeout)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+	unsigned int rbbm_status;
+	unsigned long wait_time = jiffies + MAX_WAITGPU_SECS;
+
+	kgsl_cffdump_regpoll(device->id, REG_RBBM_STATUS << 2,
+		0x00000000, 0x80000000);
+	/* first, wait until the CP has consumed all the commands in
+	 * the ring buffer
+	 */
+retry:
+	if (rb->flags & KGSL_FLAGS_STARTED) {
+		do {
+			GSL_RB_GET_READPTR(rb, &rb->rptr);
+			if (time_after(jiffies, wait_time)) {
+				KGSL_DRV_ERR(device, "rptr: %x, wptr: %x\n",
+					rb->rptr, rb->wptr);
+				goto err;
+			}
+		} while (rb->rptr != rb->wptr);
+	}
+
+	/* now, wait for the GPU to finish its operations */
+	wait_time = jiffies + MAX_WAITGPU_SECS;
+	while (time_before(jiffies, wait_time)) {
+		kgsl_yamato_regread(device, REG_RBBM_STATUS, &rbbm_status);
+		if (rbbm_status == 0x110)
+			return 0;
+	}
+
+err:
+	KGSL_DRV_ERR(device, "spun too long waiting for RB to idle\n");
+	if (!kgsl_yamato_dump_and_recover(device)) {
+		wait_time = jiffies + MAX_WAITGPU_SECS;
+		goto retry;
+	}
+	return -ETIMEDOUT;
+}
+
+static unsigned int kgsl_yamato_isidle(struct kgsl_device *device)
+{
+	int status = false;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+	unsigned int rbbm_status;
+
+	if (rb->flags & KGSL_FLAGS_STARTED) {
+		/* Is the ring buffer is empty? */
+		GSL_RB_GET_READPTR(rb, &rb->rptr);
+		if (!device->active_cnt && (rb->rptr == rb->wptr)) {
+			/* Is the core idle? */
+			kgsl_yamato_regread(device, REG_RBBM_STATUS,
+					    &rbbm_status);
+			if (rbbm_status == 0x110)
+				status = true;
+		}
+	} else {
+		KGSL_DRV_ERR(device, "ringbuffer not started\n");
+		BUG();
+	}
+	return status;
+}
+
+
+/******************************************************************/
+/* Caller must hold the driver mutex. */
+static int kgsl_yamato_resume_context(struct kgsl_device *device)
+{
+	int status = 0;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+
+	if (device->pwrctrl.suspended_ctxt != NULL) {
+		kgsl_drawctxt_switch(yamato_device,
+				     device->pwrctrl.suspended_ctxt, 0);
+		status = kgsl_yamato_idle(device, 0);
+
+	}
+
+	return status;
+}
+
+/******************************************************************/
+/* Caller must hold the device mutex. */
+static int kgsl_yamato_suspend_context(struct kgsl_device *device)
+{
+	int status = 0;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+
+	/* save ctxt ptr and switch to NULL ctxt */
+	device->pwrctrl.suspended_ctxt = yamato_device->drawctxt_active;
+	if (device->pwrctrl.suspended_ctxt != NULL) {
+		kgsl_drawctxt_switch(yamato_device, NULL, 0);
+		status = kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+	}
+
+	return status;
+}
+
+uint8_t *kgsl_sharedmem_convertaddr(struct kgsl_device *device,
+	unsigned int pt_base, unsigned int gpuaddr, unsigned int *size)
+{
+	uint8_t *result = NULL;
+	struct kgsl_mem_entry *entry;
+	struct kgsl_process_private *priv;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *ringbuffer = &yamato_device->ringbuffer;
+
+	if (kgsl_gpuaddr_in_memdesc(&ringbuffer->buffer_desc, gpuaddr)) {
+		return kgsl_gpuaddr_to_vaddr(&ringbuffer->buffer_desc,
+					gpuaddr, size);
+	}
+
+	if (kgsl_gpuaddr_in_memdesc(&ringbuffer->memptrs_desc, gpuaddr)) {
+		return kgsl_gpuaddr_to_vaddr(&ringbuffer->memptrs_desc,
+					gpuaddr, size);
+	}
+
+	if (kgsl_gpuaddr_in_memdesc(&device->memstore, gpuaddr)) {
+		return kgsl_gpuaddr_to_vaddr(&device->memstore,
+					gpuaddr, size);
+	}
+
+	mutex_lock(&kgsl_driver.process_mutex);
+	list_for_each_entry(priv, &kgsl_driver.process_list, list) {
+		if (pt_base != 0
+			&& priv->pagetable
+			&& priv->pagetable->base.gpuaddr != pt_base) {
+			continue;
+		}
+
+		spin_lock(&priv->mem_lock);
+		entry = kgsl_sharedmem_find_region(priv, gpuaddr,
+						sizeof(unsigned int));
+		if (entry) {
+			result = kgsl_gpuaddr_to_vaddr(&entry->memdesc,
+							gpuaddr, size);
+			spin_unlock(&priv->mem_lock);
+			mutex_unlock(&kgsl_driver.process_mutex);
+			return result;
+		}
+		spin_unlock(&priv->mem_lock);
+	}
+	mutex_unlock(&kgsl_driver.process_mutex);
+
+	BUG_ON(!mutex_is_locked(&device->mutex));
+	list_for_each_entry(entry, &device->memqueue, list) {
+		if (kgsl_gpuaddr_in_memdesc(&entry->memdesc, gpuaddr)) {
+			result = kgsl_gpuaddr_to_vaddr(&entry->memdesc,
+							gpuaddr, size);
+			break;
+		}
+
+	}
+	return result;
+}
+
+static void _yamato_regread(struct kgsl_device *device,
+			    unsigned int offsetwords,
+			    unsigned int *value)
+{
+	unsigned int *reg;
+	BUG_ON(offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes);
+	reg = (unsigned int *)(device->regspace.mmio_virt_base
+				+ (offsetwords << 2));
+	*value = readl(reg);
+}
+
+void kgsl_yamato_regread(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int *value)
+{
+	kgsl_pre_hwaccess(device);
+	_yamato_regread(device, offsetwords, value);
+}
+
+void kgsl_yamato_regread_isr(struct kgsl_device *device,
+			     unsigned int offsetwords,
+			     unsigned int *value)
+{
+	_yamato_regread(device, offsetwords, value);
+}
+
+static void _yamato_regwrite(struct kgsl_device *device,
+			     unsigned int offsetwords,
+			     unsigned int value)
+{
+	unsigned int *reg;
+
+	BUG_ON(offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes);
+
+	kgsl_cffdump_regwrite(device->id, offsetwords << 2, value);
+	reg = (unsigned int *)(device->regspace.mmio_virt_base
+				+ (offsetwords << 2));
+
+	writel(value, reg);
+
+}
+
+void kgsl_yamato_regwrite(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int value)
+{
+	kgsl_pre_hwaccess(device);
+	_yamato_regwrite(device, offsetwords, value);
+}
+
+void kgsl_yamato_regwrite_isr(struct kgsl_device *device,
+			      unsigned int offsetwords,
+			      unsigned int value)
+{
+	_yamato_regwrite(device, offsetwords, value);
+}
+
+static int kgsl_check_interrupt_timestamp(struct kgsl_device *device,
+					unsigned int timestamp)
+{
+	int status;
+	unsigned int ref_ts, enableflag;
+
+	status = kgsl_check_timestamp(device, timestamp);
+	if (!status) {
+		mutex_lock(&device->mutex);
+		kgsl_sharedmem_readl(&device->memstore, &enableflag,
+			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable));
+		rmb();
+
+		if (enableflag) {
+			kgsl_sharedmem_readl(&device->memstore, &ref_ts,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts));
+			rmb();
+			if (timestamp_cmp(ref_ts, timestamp)) {
+				kgsl_sharedmem_writel(&device->memstore,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
+				timestamp);
+				wmb();
+			}
+		} else {
+			unsigned int cmds[2];
+			kgsl_sharedmem_writel(&device->memstore,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
+				timestamp);
+			enableflag = 1;
+			kgsl_sharedmem_writel(&device->memstore,
+				KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
+				enableflag);
+			wmb();
+			/* submit a dummy packet so that even if all
+			* commands upto timestamp get executed we will still
+			* get an interrupt */
+			cmds[0] = pm4_type3_packet(PM4_NOP, 1);
+			cmds[1] = 0;
+			kgsl_ringbuffer_issuecmds(device, 0, &cmds[0], 2);
+		}
+		mutex_unlock(&device->mutex);
+	}
+
+	return status;
+}
+
+/*
+ wait_io_event_interruptible_timeout checks for the exit condition before
+ placing a process in wait q. For conditional interrupts we expect the
+ process to already be in its wait q when its exit condition checking
+ function is called.
+*/
+#define kgsl_wait_io_event_interruptible_timeout(wq, condition, timeout)\
+({									\
+	long __ret = timeout;						\
+	__wait_io_event_interruptible_timeout(wq, condition, __ret);	\
+	__ret;								\
+})
+
+/* MUST be called with the device mutex held */
+static int kgsl_yamato_waittimestamp(struct kgsl_device *device,
+				unsigned int timestamp,
+				unsigned int msecs)
+{
+	long status = 0;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+
+	if (timestamp != yamato_device->ringbuffer.timestamp &&
+		timestamp_cmp(timestamp,
+		yamato_device->ringbuffer.timestamp)) {
+		KGSL_DRV_ERR(device, "Cannot wait for invalid ts: %x, "
+			"rb->timestamp: %x\n",
+			timestamp, yamato_device->ringbuffer.timestamp);
+		status = -EINVAL;
+		goto done;
+	}
+	if (!kgsl_check_timestamp(device, timestamp)) {
+		mutex_unlock(&device->mutex);
+		/* We need to make sure that the process is placed in wait-q
+		 * before its condition is called */
+		status = kgsl_wait_io_event_interruptible_timeout(
+				device->wait_queue,
+				kgsl_check_interrupt_timestamp(device,
+					timestamp), msecs_to_jiffies(msecs));
+		mutex_lock(&device->mutex);
+
+		if (status > 0)
+			status = 0;
+		else if (status == 0) {
+			if (!kgsl_check_timestamp(device, timestamp)) {
+				status = -ETIMEDOUT;
+				KGSL_DRV_ERR(device,
+					"Device hang detected while waiting "
+					"for timestamp: %x, last "
+					"submitted(rb->timestamp): %x, wptr: "
+					"%x\n", timestamp,
+					yamato_device->ringbuffer.timestamp,
+					yamato_device->ringbuffer.wptr);
+				if (!kgsl_yamato_dump_and_recover(device)) {
+					/* wait for idle after recovery as the
+					 * timestamp that this process wanted
+					 * to wait on may be invalid */
+					if (!kgsl_yamato_idle(device,
+						KGSL_TIMEOUT_DEFAULT))
+						status = 0;
+				}
+			}
+		}
+	}
+
+done:
+	return (int)status;
+}
+
+static unsigned int kgsl_yamato_readtimestamp(struct kgsl_device *device,
+			     enum kgsl_timestamp_type type)
+{
+	unsigned int timestamp = 0;
+
+	if (type == KGSL_TIMESTAMP_CONSUMED)
+		kgsl_yamato_regread(device, REG_CP_TIMESTAMP, &timestamp);
+	else if (type == KGSL_TIMESTAMP_RETIRED)
+		kgsl_sharedmem_readl(&device->memstore, &timestamp,
+				 KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp));
+	rmb();
+
+	return timestamp;
+}
+
+static long kgsl_yamato_ioctl(struct kgsl_device_private *dev_priv,
+			      unsigned int cmd, void *data)
+{
+	int result = 0;
+	struct kgsl_drawctxt_set_bin_base_offset *binbase;
+	struct kgsl_context *context;
+
+	switch (cmd) {
+	case IOCTL_KGSL_DRAWCTXT_SET_BIN_BASE_OFFSET:
+		binbase = data;
+
+		context = kgsl_find_context(dev_priv, binbase->drawctxt_id);
+		if (context) {
+			result = kgsl_drawctxt_set_bin_base_offset(
+					dev_priv->device,
+					context,
+					binbase->offset);
+		} else {
+			result = -EINVAL;
+			KGSL_DRV_ERR(dev_priv->device,
+				"invalid drawctxt drawctxt_id %d "
+				"device_id=%d\n",
+				binbase->drawctxt_id, dev_priv->device->id);
+		}
+		break;
+
+	default:
+		KGSL_DRV_INFO(dev_priv->device,
+			"invalid ioctl code %08x\n", cmd);
+		result = -EINVAL;
+		break;
+	}
+	return result;
+
+}
+
+static inline s64 kgsl_yamato_ticks_to_us(u32 ticks, u32 gpu_freq)
+{
+	gpu_freq /= 1000000;
+	return ticks / gpu_freq;
+}
+
+static void kgsl_yamato_power_stats(struct kgsl_device *device,
+				struct kgsl_power_stats *stats)
+{
+	unsigned int reg;
+	struct kgsl_pwrctrl *pwr = &device->pwrctrl;
+
+	/* In order to calculate idle you have to have run the algorithm *
+	 * at least once to get a start time. */
+	if (pwr->time != 0) {
+		s64 tmp;
+		/* Stop the performance moniter and read the current *
+		 * busy cycles. */
+		kgsl_yamato_regwrite(device,
+					REG_CP_PERFMON_CNTL,
+					REG_PERF_MODE_CNT |
+					REG_PERF_STATE_FREEZE);
+		kgsl_yamato_regread(device, REG_RBBM_PERFCOUNTER1_LO, &reg);
+		tmp = ktime_to_us(ktime_get());
+		stats->total_time = tmp - pwr->time;
+		pwr->time = tmp;
+		stats->busy_time  = kgsl_yamato_ticks_to_us(reg,
+				device->pwrctrl.
+				pwrlevels[device->pwrctrl.active_pwrlevel].
+				gpu_freq);
+		kgsl_yamato_regwrite(device,
+					REG_CP_PERFMON_CNTL,
+					REG_PERF_MODE_CNT |
+					REG_PERF_STATE_RESET);
+	} else {
+		stats->total_time = 0;
+		stats->busy_time = 0;
+		pwr->time = ktime_to_us(ktime_get());
+	}
+
+	/* re-enable the performance moniters */
+	kgsl_yamato_regread(device, REG_RBBM_PM_OVERRIDE2, &reg);
+	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, (reg | 0x40));
+	kgsl_yamato_regwrite(device, REG_RBBM_PERFCOUNTER1_SELECT, 0x1);
+	kgsl_yamato_regwrite(device,
+				REG_CP_PERFMON_CNTL,
+				REG_PERF_MODE_CNT | REG_PERF_STATE_ENABLE);
+}
+
+static void __devinit kgsl_yamato_getfunctable(struct kgsl_functable *ftbl)
+{
+	if (ftbl == NULL)
+		return;
+	ftbl->device_regread = kgsl_yamato_regread;
+	ftbl->device_regwrite = kgsl_yamato_regwrite;
+	ftbl->device_regread_isr = kgsl_yamato_regread_isr;
+	ftbl->device_regwrite_isr = kgsl_yamato_regwrite_isr;
+	ftbl->device_setstate = kgsl_yamato_setstate;
+	ftbl->device_idle = kgsl_yamato_idle;
+	ftbl->device_isidle = kgsl_yamato_isidle;
+	ftbl->device_suspend_context = kgsl_yamato_suspend_context;
+	ftbl->device_resume_context = kgsl_yamato_resume_context;
+	ftbl->device_start = kgsl_yamato_start;
+	ftbl->device_stop = kgsl_yamato_stop;
+	ftbl->device_getproperty = kgsl_yamato_getproperty;
+	ftbl->device_waittimestamp = kgsl_yamato_waittimestamp;
+	ftbl->device_readtimestamp = kgsl_yamato_readtimestamp;
+	ftbl->device_issueibcmds = kgsl_ringbuffer_issueibcmds;
+	ftbl->device_drawctxt_create = kgsl_drawctxt_create;
+	ftbl->device_drawctxt_destroy = kgsl_drawctxt_destroy;
+	ftbl->device_ioctl = kgsl_yamato_ioctl;
+	ftbl->device_setup_pt = kgsl_yamato_setup_pt;
+	ftbl->device_cleanup_pt = kgsl_yamato_cleanup_pt;
+	ftbl->device_power_stats = kgsl_yamato_power_stats;
+}
+
+static struct platform_device_id kgsl_3d_id_table[] = {
+	{ DEVICE_3D0_NAME, (kernel_ulong_t)&yamato_device.dev, },
+	{ },
+};
+MODULE_DEVICE_TABLE(platform, kgsl_3d_id_table);
+
+static struct platform_driver kgsl_3d_platform_driver = {
+	.probe = kgsl_3d_probe,
+	.remove = __devexit_p(kgsl_3d_remove),
+	.suspend = kgsl_suspend_driver,
+	.resume = kgsl_resume_driver,
+	.id_table = kgsl_3d_id_table,
+	.driver = {
+		.owner = THIS_MODULE,
+		.name = DEVICE_3D_NAME,
+		.pm = &kgsl_pm_ops,
+	}
+};
+
+static int __init kgsl_3d_init(void)
+{
+	return platform_driver_register(&kgsl_3d_platform_driver);
+}
+
+static void __exit kgsl_3d_exit(void)
+{
+	platform_driver_unregister(&kgsl_3d_platform_driver);
+}
+
+module_init(kgsl_3d_init);
+module_exit(kgsl_3d_exit);
+
+MODULE_DESCRIPTION("3D Graphics driver");
+MODULE_VERSION("1.2");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:kgsl_3d");
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.h
new file mode 100644
index 0000000..ab6ce3b
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno.h
@@ -0,0 +1,75 @@
+/* Copyright (c) 2008-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __ADRENO_H
+#define __ADRENO_H
+
+#include "adreno_drawctxt.h"
+#include "adreno_ringbuffer.h"
+
+#define DEVICE_3D_NAME "kgsl-3d"
+#define DEVICE_3D0_NAME "kgsl-3d0"
+
+/* Flags to control command packet settings */
+#define KGSL_CMD_FLAGS_PMODE           0x00000001
+#define KGSL_CMD_FLAGS_NO_TS_CMP       0x00000002
+#define KGSL_CMD_FLAGS_NOT_KERNEL_CMD  0x00000004
+
+/* Command identifiers */
+#define KGSL_CONTEXT_TO_MEM_IDENTIFIER 0xDEADBEEF
+#define KGSL_CMD_IDENTIFIER            0xFEEDFACE
+
+struct kgsl_yamato_device {
+	struct kgsl_device dev;    /* Must be first field in this struct */
+	struct kgsl_memregion gmemspace;
+	struct kgsl_yamato_context *drawctxt_active;
+	wait_queue_head_t ib1_wq;
+	unsigned int *pfp_fw;
+	size_t pfp_fw_size;
+	unsigned int *pm4_fw;
+	size_t pm4_fw_size;
+	struct kgsl_ringbuffer ringbuffer;
+};
+
+
+int kgsl_yamato_idle(struct kgsl_device *device, unsigned int timeout);
+void kgsl_yamato_regread(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int *value);
+void kgsl_yamato_regwrite(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int value);
+void kgsl_yamato_regread_isr(struct kgsl_device *device,
+			     unsigned int offsetwords,
+			     unsigned int *value);
+void kgsl_yamato_regwrite_isr(struct kgsl_device *device,
+			      unsigned int offsetwords,
+			      unsigned int value);
+
+uint8_t *kgsl_sharedmem_convertaddr(struct kgsl_device *device,
+	unsigned int pt_base, unsigned int gpuaddr, unsigned int *size);
+
+#endif /* __ADRENO_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.c
new file mode 100644
index 0000000..53cbd57
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.c
@@ -0,0 +1,450 @@
+/* Copyright (c) 2002,2008-2011, Code Aurora Forum. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+
+#include "kgsl.h"
+#include "adreno_postmortem.h"
+#include "adreno.h"
+
+#include "a200_reg.h"
+
+unsigned int kgsl_cff_dump_enable;
+int kgsl_pm_regs_enabled;
+
+static uint32_t kgsl_ib_base;
+static uint32_t kgsl_ib_size;
+
+static struct dentry *pm_d_debugfs;
+
+static int pm_dump_set(void *data, u64 val)
+{
+	struct kgsl_device *device = data;
+
+	if (val) {
+		mutex_lock(&device->mutex);
+		kgsl_postmortem_dump(device, 1);
+		mutex_unlock(&device->mutex);
+	}
+
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(pm_dump_fops,
+			NULL,
+			pm_dump_set, "%llu\n");
+
+static int pm_regs_enabled_set(void *data, u64 val)
+{
+	kgsl_pm_regs_enabled = val ? 1 : 0;
+	return 0;
+}
+
+static int pm_regs_enabled_get(void *data, u64 *val)
+{
+	*val = kgsl_pm_regs_enabled;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(pm_regs_enabled_fops,
+			pm_regs_enabled_get,
+			pm_regs_enabled_set, "%llu\n");
+
+
+static int kgsl_cff_dump_enable_set(void *data, u64 val)
+{
+#ifdef CONFIG_MSM_KGSL_CFF_DUMP
+	kgsl_cff_dump_enable = (val != 0);
+	return 0;
+#else
+	return -EINVAL;
+#endif
+}
+
+static int kgsl_cff_dump_enable_get(void *data, u64 *val)
+{
+	*val = kgsl_cff_dump_enable;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(kgsl_cff_dump_enable_fops, kgsl_cff_dump_enable_get,
+			kgsl_cff_dump_enable_set, "%llu\n");
+
+static int kgsl_dbgfs_open(struct inode *inode, struct file *file)
+{
+	file->f_mode &= ~(FMODE_PREAD | FMODE_PWRITE);
+	file->private_data = inode->i_private;
+	return 0;
+}
+
+static int kgsl_dbgfs_release(struct inode *inode, struct file *file)
+{
+	return 0;
+}
+
+static int kgsl_hex_dump(const char *prefix, int c, uint8_t *data,
+	int rowc, int linec, char __user *buff)
+{
+	int ss;
+	/* Prefix of 20 chars max, 32 bytes per row, in groups of four - that's
+	 * 8 groups at 8 chars per group plus a space, plus new-line, plus
+	 * ending character */
+	char linebuf[20 + 64 + 1 + 1];
+
+	ss = snprintf(linebuf, sizeof(linebuf), prefix, c);
+	hex_dump_to_buffer(data, linec, rowc, 4, linebuf+ss,
+		sizeof(linebuf)-ss, 0);
+	strncat(linebuf, "\n", sizeof(linebuf));
+	linebuf[sizeof(linebuf)-1] = 0;
+	ss = strlen(linebuf);
+	if (copy_to_user(buff, linebuf, ss+1))
+		return -EFAULT;
+	return ss;
+}
+
+static ssize_t kgsl_ib_dump_read(
+	struct file *file,
+	char __user *buff,
+	size_t buff_count,
+	loff_t *ppos)
+{
+	int i, count = kgsl_ib_size, remaining, pos = 0, tot = 0, ss;
+	struct kgsl_device *device = file->private_data;
+	const int rowc = 32;
+	unsigned int pt_base, ib_memsize;
+	uint8_t *base_addr;
+	char linebuf[80];
+
+	if (!ppos || !device || !kgsl_ib_base)
+		return 0;
+
+	kgsl_regread(device, REG_MH_MMU_PT_BASE, &pt_base);
+	base_addr = kgsl_sharedmem_convertaddr(device, pt_base, kgsl_ib_base,
+		&ib_memsize);
+
+	if (!base_addr)
+		return 0;
+
+	pr_info("%s ppos=%ld, buff_count=%d, count=%d\n", __func__, (long)*ppos,
+		buff_count, count);
+	ss = snprintf(linebuf, sizeof(linebuf), "IB: base=%08x(%08x"
+		"), size=%d, memsize=%d\n", kgsl_ib_base,
+		(uint32_t)base_addr, kgsl_ib_size, ib_memsize);
+	if (*ppos == 0) {
+		if (copy_to_user(buff, linebuf, ss+1))
+			return -EFAULT;
+		tot += ss;
+		buff += ss;
+		*ppos += ss;
+	}
+	pos += ss;
+	remaining = count;
+	for (i = 0; i < count; i += rowc) {
+		int linec = min(remaining, rowc);
+
+		remaining -= rowc;
+		ss = kgsl_hex_dump("IB: %05x: ", i, base_addr, rowc, linec,
+			buff);
+		if (ss < 0)
+			return ss;
+
+		if (pos >= *ppos) {
+			if (tot+ss >= buff_count) {
+				ss = copy_to_user(buff, "", 1);
+				return tot;
+			}
+			tot += ss;
+			buff += ss;
+			*ppos += ss;
+		}
+		pos += ss;
+		base_addr += linec;
+	}
+
+	return tot;
+}
+
+static ssize_t kgsl_ib_dump_write(
+	struct file *file,
+	const char __user *buff,
+	size_t count,
+	loff_t *ppos)
+{
+	char local_buff[64];
+
+	if (count >= sizeof(local_buff))
+		return -EFAULT;
+
+	if (copy_from_user(local_buff, buff, count))
+		return -EFAULT;
+
+	local_buff[count] = 0;	/* end of string */
+	sscanf(local_buff, "%x %d", &kgsl_ib_base, &kgsl_ib_size);
+
+	pr_info("%s: base=%08X size=%d\n", __func__, kgsl_ib_base,
+		kgsl_ib_size);
+
+	return count;
+}
+
+static const struct file_operations kgsl_ib_dump_fops = {
+	.open = kgsl_dbgfs_open,
+	.release = kgsl_dbgfs_release,
+	.read = kgsl_ib_dump_read,
+	.write = kgsl_ib_dump_write,
+};
+
+static int kgsl_regread_nolock(struct kgsl_device *device,
+	unsigned int offsetwords, unsigned int *value)
+{
+	unsigned int *reg;
+
+	if (offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes) {
+		KGSL_DRV_ERR(device, "invalid offset %d\n", offsetwords);
+		return -ERANGE;
+	}
+
+	reg = (unsigned int *)(device->regspace.mmio_virt_base
+				+ (offsetwords << 2));
+	*value = readl(reg);
+	return 0;
+}
+
+#define KGSL_ISTORE_START 0x5000
+#define KGSL_ISTORE_LENGTH 0x600
+static ssize_t kgsl_istore_read(
+	struct file *file,
+	char __user *buff,
+	size_t buff_count,
+	loff_t *ppos)
+{
+	int i, count = KGSL_ISTORE_LENGTH, remaining, pos = 0, tot = 0;
+	struct kgsl_device *device = file->private_data;
+	const int rowc = 8;
+
+	if (!ppos || !device)
+		return 0;
+
+	remaining = count;
+	for (i = 0; i < count; i += rowc) {
+		unsigned int vals[rowc];
+		int j, ss;
+		int linec = min(remaining, rowc);
+		remaining -= rowc;
+
+		if (pos >= *ppos) {
+			for (j = 0; j < linec; ++j)
+				kgsl_regread_nolock(device,
+					KGSL_ISTORE_START+i+j, vals+j);
+		} else
+			memset(vals, 0, sizeof(vals));
+
+		ss = kgsl_hex_dump("IS: %04x: ", i, (uint8_t *)vals, rowc*4,
+			linec*4, buff);
+		if (ss < 0)
+			return ss;
+
+		if (pos >= *ppos) {
+			if (tot+ss >= buff_count)
+				return tot;
+			tot += ss;
+			buff += ss;
+			*ppos += ss;
+		}
+		pos += ss;
+	}
+
+	return tot;
+}
+
+static const struct file_operations kgsl_istore_fops = {
+	.open = kgsl_dbgfs_open,
+	.release = kgsl_dbgfs_release,
+	.read = kgsl_istore_read,
+	.llseek = default_llseek,
+};
+
+typedef void (*reg_read_init_t)(struct kgsl_device *device);
+typedef void (*reg_read_fill_t)(struct kgsl_device *device, int i,
+	unsigned int *vals, int linec);
+static ssize_t kgsl_reg_read(struct kgsl_device *device, int count,
+	reg_read_init_t reg_read_init,
+	reg_read_fill_t reg_read_fill, const char *prefix, char __user *buff,
+	loff_t *ppos)
+{
+	int i, remaining;
+	const int rowc = 8;
+
+	if (!ppos || *ppos || !device)
+		return 0;
+
+	mutex_lock(&device->mutex);
+	reg_read_init(device);
+	remaining = count;
+	for (i = 0; i < count; i += rowc) {
+		unsigned int vals[rowc];
+		int ss;
+		int linec = min(remaining, rowc);
+		remaining -= rowc;
+
+		reg_read_fill(device, i, vals, linec);
+		ss = kgsl_hex_dump(prefix, i, (uint8_t *)vals, rowc*4, linec*4,
+			buff);
+		if (ss < 0) {
+			mutex_unlock(&device->mutex);
+			return ss;
+		}
+		buff += ss;
+		*ppos += ss;
+	}
+	mutex_unlock(&device->mutex);
+
+	return *ppos;
+}
+
+
+static void kgsl_sx_reg_read_init(struct kgsl_device *device)
+{
+	kgsl_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0xFF);
+	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
+}
+
+static void kgsl_sx_reg_read_fill(struct kgsl_device *device, int i,
+	unsigned int *vals, int linec)
+{
+	int j;
+
+	for (j = 0; j < linec; ++j) {
+		kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0x1B00 | i);
+		kgsl_regread(device, REG_RBBM_DEBUG_OUT, vals+j);
+	}
+}
+
+static ssize_t kgsl_sx_debug_read(
+	struct file *file,
+	char __user *buff,
+	size_t buff_count,
+	loff_t *ppos)
+{
+	struct kgsl_device *device = file->private_data;
+	return kgsl_reg_read(device, 0x1B, kgsl_sx_reg_read_init,
+			     kgsl_sx_reg_read_fill, "SX: %02x: ", buff, ppos);
+}
+
+static const struct file_operations kgsl_sx_debug_fops = {
+	.open = kgsl_dbgfs_open,
+	.release = kgsl_dbgfs_release,
+	.read = kgsl_sx_debug_read,
+};
+
+static void kgsl_cp_reg_read_init(struct kgsl_device *device)
+{
+	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
+}
+
+static void kgsl_cp_reg_read_fill(struct kgsl_device *device, int i,
+	unsigned int *vals, int linec)
+{
+	int j;
+
+	for (j = 0; j < linec; ++j) {
+		kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0x1628);
+		kgsl_regread(device, REG_RBBM_DEBUG_OUT, vals+j);
+		msleep(100);
+	}
+}
+
+static ssize_t kgsl_cp_debug_read(
+	struct file *file,
+	char __user *buff,
+	size_t buff_count,
+	loff_t *ppos)
+{
+	struct kgsl_device *device = file->private_data;
+	return kgsl_reg_read(device, 20, kgsl_cp_reg_read_init,
+		kgsl_cp_reg_read_fill,
+		"CP: %02x: ", buff, ppos);
+}
+
+static const struct file_operations kgsl_cp_debug_fops = {
+	.open = kgsl_dbgfs_open,
+	.release = kgsl_dbgfs_release,
+	.read = kgsl_cp_debug_read,
+};
+
+static void kgsl_mh_reg_read_init(struct kgsl_device *device)
+{
+	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
+}
+
+static void kgsl_mh_reg_read_fill(struct kgsl_device *device, int i,
+	unsigned int *vals, int linec)
+{
+	int j;
+
+	for (j = 0; j < linec; ++j) {
+		kgsl_regwrite(device, REG_MH_DEBUG_CTRL, i+j);
+		kgsl_regread(device, REG_MH_DEBUG_DATA, vals+j);
+	}
+}
+
+static ssize_t kgsl_mh_debug_read(
+	struct file *file,
+	char __user *buff,
+	size_t buff_count,
+	loff_t *ppos)
+{
+	struct kgsl_device *device = file->private_data;
+	return kgsl_reg_read(device, 0x40, kgsl_mh_reg_read_init,
+		kgsl_mh_reg_read_fill,
+		"MH: %02x: ", buff, ppos);
+}
+
+static const struct file_operations kgsl_mh_debug_fops = {
+	.open = kgsl_dbgfs_open,
+	.release = kgsl_dbgfs_release,
+	.read = kgsl_mh_debug_read,
+};
+
+void kgsl_yamato_debugfs_init(struct kgsl_device *device)
+{
+	if (!device->d_debugfs || IS_ERR(device->d_debugfs))
+		return;
+
+	debugfs_create_file("ib_dump",  0600, device->d_debugfs, device,
+			    &kgsl_ib_dump_fops);
+	debugfs_create_file("istore",   0400, device->d_debugfs, device,
+			    &kgsl_istore_fops);
+	debugfs_create_file("sx_debug", 0400, device->d_debugfs, device,
+			    &kgsl_sx_debug_fops);
+	debugfs_create_file("cp_debug", 0400, device->d_debugfs, device,
+			    &kgsl_cp_debug_fops);
+	debugfs_create_file("mh_debug", 0400, device->d_debugfs, device,
+			    &kgsl_mh_debug_fops);
+	debugfs_create_file("cff_dump", 0644, device->d_debugfs, device,
+			    &kgsl_cff_dump_enable_fops);
+
+	/* Create post mortem control files */
+
+	pm_d_debugfs = debugfs_create_dir("postmortem", device->d_debugfs);
+
+	if (IS_ERR(pm_d_debugfs))
+		return;
+
+	debugfs_create_file("dump",  0600, pm_d_debugfs, device,
+			    &pm_dump_fops);
+	debugfs_create_file("regs_enabled", 0644, pm_d_debugfs, device,
+			    &pm_regs_enabled_fops);
+}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.h
new file mode 100644
index 0000000..1eed862
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_debugfs.h
@@ -0,0 +1,56 @@
+/* Copyright (c) 2002,2008-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __ADRENO_DEBUGFS_H
+#define __ADRENO_DEBUGFS_H
+
+#ifdef CONFIG_DEBUG_FS
+
+int kgsl_yamato_debugfs_init(struct kgsl_device *device);
+
+extern int kgsl_pm_regs_enabled;
+
+static inline int kgsl_pmregs_enabled(void)
+{
+	return kgsl_pm_regs_enabled;
+}
+
+#else
+static inline int kgsl_yamato_debugfs_init(struct kgsl_device *device)
+{
+	return 0;
+}
+
+static inline int kgsl_pmregs_enabled(void)
+{
+	/* If debugfs is turned off, then always print registers */
+	return 1;
+}
+#endif
+
+#endif /* __ADRENO_DEBUGFS_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.c
new file mode 100644
index 0000000..c3dd3d5
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.c
@@ -0,0 +1,1676 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+#include <linux/slab.h>
+
+#include "kgsl.h"
+
+#include "adreno.h"
+#include "adreno_pm4types.h"
+#include "adreno_drawctxt.h"
+
+/*
+ *
+ *  Memory Map for Register, Constant & Instruction Shadow, and Command Buffers
+ *  (34.5KB)
+ *
+ *  +---------------------+------------+-------------+---+---------------------+
+ *  | ALU Constant Shadow | Reg Shadow | C&V Buffers |Tex| Shader Instr Shadow |
+ *  +---------------------+------------+-------------+---+---------------------+
+ *    ________________________________/               \____________________
+ *   /                                                                     |
+ *  +--------------+-----------+------+-----------+------------------------+
+ *  | Restore Regs | Save Regs | Quad | Gmem Save | Gmem Restore | unused  |
+ *  +--------------+-----------+------+-----------+------------------------+
+ *
+ *              8K - ALU Constant Shadow (8K aligned)
+ *              4K - H/W Register Shadow (8K aligned)
+ *              4K - Command and Vertex Buffers
+ *                         - Indirect command buffer : Const/Reg restore
+ *                               - includes Loop & Bool const shadows
+ *                         - Indirect command buffer : Const/Reg save
+ *                         - Quad vertices & texture coordinates
+ *                         - Indirect command buffer : Gmem save
+ *                         - Indirect command buffer : Gmem restore
+ *                         - Unused (padding to 8KB boundary)
+ *             <1K - Texture Constant Shadow (768 bytes) (8K aligned)
+ *       18K - Shader Instruction Shadow
+ *               - 6K vertex (32 byte aligned)
+ *               - 6K pixel  (32 byte aligned)
+ *               - 6K shared (32 byte aligned)
+ *
+ *  Note: Reading constants into a shadow, one at a time using REG_TO_MEM, takes
+ *  3 DWORDS per DWORD transfered, plus 1 DWORD for the shadow, for a total of
+ *  16 bytes per constant.  If the texture constants were transfered this way,
+ *  the Command & Vertex Buffers section would extend past the 16K boundary.
+ *  By moving the texture constant shadow area to start at 16KB boundary, we
+ *  only require approximately 40 bytes more memory, but are able to use the
+ *  LOAD_CONSTANT_CONTEXT shadowing feature for the textures, speeding up
+ *  context switching.
+ *
+ *  [Using LOAD_CONSTANT_CONTEXT shadowing feature for the Loop and/or Bool
+ *  constants would require an additional 8KB each, for alignment.]
+ *
+ */
+
+/* Constants */
+
+#define ALU_CONSTANTS	2048	/* DWORDS */
+#define NUM_REGISTERS	1024	/* DWORDS */
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+#define CMD_BUFFER_LEN	9216	/* DWORDS */
+#else
+#define CMD_BUFFER_LEN	3072	/* DWORDS */
+#endif
+#define TEX_CONSTANTS		(32*6)	/* DWORDS */
+#define BOOL_CONSTANTS		8	/* DWORDS */
+#define LOOP_CONSTANTS		56	/* DWORDS */
+#define SHADER_INSTRUCT_LOG2	9U	/* 2^n == SHADER_INSTRUCTIONS */
+
+#if defined(PM4_IM_STORE)
+/* 96-bit instructions */
+#define SHADER_INSTRUCT		(1<<SHADER_INSTRUCT_LOG2)
+#else
+#define SHADER_INSTRUCT		0
+#endif
+
+/* LOAD_CONSTANT_CONTEXT shadow size */
+#define LCC_SHADOW_SIZE		0x2000	/* 8KB */
+
+#define ALU_SHADOW_SIZE		LCC_SHADOW_SIZE	/* 8KB */
+#define REG_SHADOW_SIZE		0x1000	/* 4KB */
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+#define CMD_BUFFER_SIZE		0x9000	/* 36KB */
+#else
+#define CMD_BUFFER_SIZE		0x3000	/* 12KB */
+#endif
+#define TEX_SHADOW_SIZE		(TEX_CONSTANTS*4)	/* 768 bytes */
+#define SHADER_SHADOW_SIZE	(SHADER_INSTRUCT*12)	/* 6KB */
+
+#define REG_OFFSET		LCC_SHADOW_SIZE
+#define CMD_OFFSET		(REG_OFFSET + REG_SHADOW_SIZE)
+#define TEX_OFFSET		(CMD_OFFSET + CMD_BUFFER_SIZE)
+#define SHADER_OFFSET		((TEX_OFFSET + TEX_SHADOW_SIZE + 32) & ~31)
+
+#define CONTEXT_SIZE		(SHADER_OFFSET + 3 * SHADER_SHADOW_SIZE)
+
+/* temporary work structure */
+struct tmp_ctx {
+	unsigned int *start;	/* Command & Vertex buffer start */
+	unsigned int *cmd;	/* Next available dword in C&V buffer */
+
+	/* address of buffers, needed when creating IB1 command buffers. */
+	uint32_t bool_shadow;	/* bool constants */
+	uint32_t loop_shadow;	/* loop constants */
+
+#if defined(PM4_IM_STORE)
+	uint32_t shader_shared;	/* shared shader instruction shadow */
+	uint32_t shader_vertex;	/* vertex shader instruction shadow */
+	uint32_t shader_pixel;	/* pixel shader instruction shadow */
+#endif
+
+	/* Addresses in command buffer where separately handled registers
+	 * are saved
+	 */
+	uint32_t reg_values[33];
+	uint32_t chicken_restore;
+
+	uint32_t gmem_base;	/* Base gpu address of GMEM */
+
+};
+
+/* Helper function to calculate IEEE754 single precision float values
+*  without FPU
+*/
+unsigned int uint2float(unsigned int uintval)
+{
+	unsigned int exp = 0;
+	unsigned int frac = 0;
+	unsigned int u = uintval;
+
+	/* Handle zero separately */
+	if (uintval == 0)
+		return 0;
+	/* Find log2 of u */
+	if (u >= 0x10000) {
+		exp += 16;
+		u >>= 16;
+	}
+	if (u >= 0x100) {
+		exp += 8;
+		u >>= 8;
+	}
+	if (u >= 0x10) {
+		exp += 4;
+		u >>= 4;
+	}
+	if (u >= 0x4) {
+		exp += 2;
+		u >>= 2;
+	}
+	if (u >= 0x2) {
+		exp += 1;
+		u >>= 1;
+	}
+
+	/* Calculate fraction */
+	if (23 > exp)
+		frac = (uintval & (~(1 << exp))) << (23 - exp);
+
+	/* Exp is biased by 127 and shifted 23 bits */
+	exp = (exp + 127) << 23;
+
+	return exp | frac;
+}
+
+/* context save (gmem -> sys) */
+
+/* pre-compiled vertex shader program
+*
+*  attribute vec4  P;
+*  void main(void)
+*  {
+*    gl_Position = P;
+*  }
+*/
+#define GMEM2SYS_VTX_PGM_LEN	0x12
+
+static unsigned int gmem2sys_vtx_pgm[GMEM2SYS_VTX_PGM_LEN] = {
+	0x00011003, 0x00001000, 0xc2000000,
+	0x00001004, 0x00001000, 0xc4000000,
+	0x00001005, 0x00002000, 0x00000000,
+	0x1cb81000, 0x00398a88, 0x00000003,
+	0x140f803e, 0x00000000, 0xe2010100,
+	0x14000000, 0x00000000, 0xe2000000
+};
+
+/* pre-compiled fragment shader program
+*
+*  precision highp float;
+*  uniform   vec4  clear_color;
+*  void main(void)
+*  {
+*     gl_FragColor = clear_color;
+*  }
+*/
+
+#define GMEM2SYS_FRAG_PGM_LEN	0x0c
+
+static unsigned int gmem2sys_frag_pgm[GMEM2SYS_FRAG_PGM_LEN] = {
+	0x00000000, 0x1002c400, 0x10000000,
+	0x00001003, 0x00002000, 0x00000000,
+	0x140f8000, 0x00000000, 0x22000000,
+	0x14000000, 0x00000000, 0xe2000000
+};
+
+/* context restore (sys -> gmem) */
+/* pre-compiled vertex shader program
+*
+*  attribute vec4 position;
+*  attribute vec4 texcoord;
+*  varying   vec4 texcoord0;
+*  void main()
+*  {
+*     gl_Position = position;
+*     texcoord0 = texcoord;
+*  }
+*/
+
+#define SYS2GMEM_VTX_PGM_LEN	0x18
+
+static unsigned int sys2gmem_vtx_pgm[SYS2GMEM_VTX_PGM_LEN] = {
+	0x00052003, 0x00001000, 0xc2000000, 0x00001005,
+	0x00001000, 0xc4000000, 0x00001006, 0x10071000,
+	0x20000000, 0x18981000, 0x0039ba88, 0x00000003,
+	0x12982000, 0x40257b08, 0x00000002, 0x140f803e,
+	0x00000000, 0xe2010100, 0x140f8000, 0x00000000,
+	0xe2020200, 0x14000000, 0x00000000, 0xe2000000
+};
+
+/* pre-compiled fragment shader program
+*
+*  precision mediump   float;
+*  uniform   sampler2D tex0;
+*  varying   vec4      texcoord0;
+*  void main()
+*  {
+*     gl_FragColor = texture2D(tex0, texcoord0.xy);
+*  }
+*/
+
+#define SYS2GMEM_FRAG_PGM_LEN	0x0f
+
+static unsigned int sys2gmem_frag_pgm[SYS2GMEM_FRAG_PGM_LEN] = {
+	0x00011002, 0x00001000, 0xc4000000, 0x00001003,
+	0x10041000, 0x20000000, 0x10000001, 0x1ffff688,
+	0x00000002, 0x140f8000, 0x00000000, 0xe2000000,
+	0x14000000, 0x00000000, 0xe2000000
+};
+
+/* shader texture constants (sysmem -> gmem)  */
+#define SYS2GMEM_TEX_CONST_LEN	6
+
+static unsigned int sys2gmem_tex_const[SYS2GMEM_TEX_CONST_LEN] = {
+	/* Texture, FormatXYZW=Unsigned, ClampXYZ=Wrap/Repeat,
+	 * RFMode=ZeroClamp-1, Dim=1:2d
+	 */
+	0x00000002,		/* Pitch = TBD */
+
+	/* Format=6:8888_WZYX, EndianSwap=0:None, ReqSize=0:256bit, DimHi=0,
+	 * NearestClamp=1:OGL Mode
+	 */
+	0x00000800,		/* Address[31:12] = TBD */
+
+	/* Width, Height, EndianSwap=0:None */
+	0,			/* Width & Height = TBD */
+
+	/* NumFormat=0:RF, DstSelXYZW=XYZW, ExpAdj=0, MagFilt=MinFilt=0:Point,
+	 * Mip=2:BaseMap
+	 */
+	0 << 1 | 1 << 4 | 2 << 7 | 3 << 10 | 2 << 23,
+
+	/* VolMag=VolMin=0:Point, MinMipLvl=0, MaxMipLvl=1, LodBiasH=V=0,
+	 * Dim3d=0
+	 */
+	0,
+
+	/* BorderColor=0:ABGRBlack, ForceBC=0:diable, TriJuice=0, Aniso=0,
+	 * Dim=1:2d, MipPacking=0
+	 */
+	1 << 9			/* Mip Address[31:12] = TBD */
+};
+
+/* quad for copying GMEM to context shadow */
+#define QUAD_LEN				12
+
+static unsigned int gmem_copy_quad[QUAD_LEN] = {
+	0x00000000, 0x00000000, 0x3f800000,
+	0x00000000, 0x00000000, 0x3f800000,
+	0x00000000, 0x00000000, 0x3f800000,
+	0x00000000, 0x00000000, 0x3f800000
+};
+
+#define TEXCOORD_LEN			8
+
+static unsigned int gmem_copy_texcoord[TEXCOORD_LEN] = {
+	0x00000000, 0x3f800000,
+	0x3f800000, 0x3f800000,
+	0x00000000, 0x00000000,
+	0x3f800000, 0x00000000
+};
+
+#define NUM_COLOR_FORMATS   13
+
+static enum SURFACEFORMAT surface_format_table[NUM_COLOR_FORMATS] = {
+	FMT_4_4_4_4,		/* COLORX_4_4_4_4 */
+	FMT_1_5_5_5,		/* COLORX_1_5_5_5 */
+	FMT_5_6_5,		/* COLORX_5_6_5 */
+	FMT_8,			/* COLORX_8 */
+	FMT_8_8,		/* COLORX_8_8 */
+	FMT_8_8_8_8,		/* COLORX_8_8_8_8 */
+	FMT_8_8_8_8,		/* COLORX_S8_8_8_8 */
+	FMT_16_FLOAT,		/* COLORX_16_FLOAT */
+	FMT_16_16_FLOAT,	/* COLORX_16_16_FLOAT */
+	FMT_16_16_16_16_FLOAT,	/* COLORX_16_16_16_16_FLOAT */
+	FMT_32_FLOAT,		/* COLORX_32_FLOAT */
+	FMT_32_32_FLOAT,	/* COLORX_32_32_FLOAT */
+	FMT_32_32_32_32_FLOAT,	/* COLORX_32_32_32_32_FLOAT */
+};
+
+static unsigned int format2bytesperpixel[NUM_COLOR_FORMATS] = {
+	2,			/* COLORX_4_4_4_4 */
+	2,			/* COLORX_1_5_5_5 */
+	2,			/* COLORX_5_6_5 */
+	1,			/* COLORX_8 */
+	2,			/* COLORX_8_8 8*/
+	4,			/* COLORX_8_8_8_8 */
+	4,			/* COLORX_S8_8_8_8 */
+	2,			/* COLORX_16_FLOAT */
+	4,			/* COLORX_16_16_FLOAT */
+	8,			/* COLORX_16_16_16_16_FLOAT */
+	4,			/* COLORX_32_FLOAT */
+	8,			/* COLORX_32_32_FLOAT */
+	16,			/* COLORX_32_32_32_32_FLOAT */
+};
+
+/* shader linkage info */
+#define SHADER_CONST_ADDR	(11 * 6 + 3)
+
+/* gmem command buffer length */
+#define PM4_REG(reg)		((0x4 << 16) | (GSL_HAL_SUBBLOCK_OFFSET(reg)))
+
+/* functions */
+static void config_gmemsize(struct gmem_shadow_t *shadow, int gmem_size)
+{
+	int w = 64, h = 64;	/* 16KB surface, minimum */
+
+	shadow->format = COLORX_8_8_8_8;
+	/* convert from bytes to 32-bit words */
+	gmem_size = (gmem_size + 3) / 4;
+
+	/* find the right surface size, close to a square. */
+	while (w * h < gmem_size)
+		if (w < h)
+			w *= 2;
+		else
+			h *= 2;
+
+	shadow->width = w;
+	shadow->pitch = w;
+	shadow->height = h;
+	shadow->gmem_pitch = shadow->pitch;
+
+	shadow->size = shadow->pitch * shadow->height * 4;
+}
+
+static unsigned int gpuaddr(unsigned int *cmd, struct kgsl_memdesc *memdesc)
+{
+	return memdesc->gpuaddr + ((char *)cmd - (char *)memdesc->hostptr);
+}
+
+static void
+create_ib1(struct kgsl_yamato_context *drawctxt, unsigned int *cmd,
+	   unsigned int *start, unsigned int *end)
+{
+	cmd[0] = PM4_HDR_INDIRECT_BUFFER_PFD;
+	cmd[1] = gpuaddr(start, &drawctxt->gpustate);
+	cmd[2] = end - start;
+}
+
+static unsigned int *program_shader(unsigned int *cmds, int vtxfrag,
+				    unsigned int *shader_pgm, int dwords)
+{
+	/* load the patched vertex shader stream */
+	*cmds++ = pm4_type3_packet(PM4_IM_LOAD_IMMEDIATE, 2 + dwords);
+	/* 0=vertex shader, 1=fragment shader */
+	*cmds++ = vtxfrag;
+	/* instruction start & size (in 32-bit words) */
+	*cmds++ = ((0 << 16) | dwords);
+
+	memcpy(cmds, shader_pgm, dwords << 2);
+	cmds += dwords;
+
+	return cmds;
+}
+
+static unsigned int *reg_to_mem(unsigned int *cmds, uint32_t dst,
+				uint32_t src, int dwords)
+{
+	while (dwords-- > 0) {
+		*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+		*cmds++ = src++;
+		*cmds++ = dst;
+		dst += 4;
+	}
+
+	return cmds;
+}
+
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+
+static void build_reg_to_mem_range(unsigned int start, unsigned int end,
+				   unsigned int **cmd,
+				   struct kgsl_yamato_context *drawctxt)
+{
+	unsigned int i = start;
+
+	for (i = start; i <= end; i++) {
+		*(*cmd)++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+		*(*cmd)++ = i;
+		*(*cmd)++ =
+		    ((drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000) +
+		    (i - 0x2000) * 4;
+	}
+}
+
+#endif
+
+/* chicken restore */
+static unsigned int *build_chicken_restore_cmds(
+					struct kgsl_yamato_context *drawctxt,
+					struct tmp_ctx *ctx)
+{
+	unsigned int *start = ctx->cmd;
+	unsigned int *cmds = start;
+
+	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmds++ = 0;
+
+	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
+	ctx->chicken_restore = gpuaddr(cmds, &drawctxt->gpustate);
+	*cmds++ = 0x00000000;
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->chicken_restore, start, cmds);
+
+	return cmds;
+}
+
+/* save h/w regs, alu constants, texture contants, etc. ...
+*  requires: bool_shadow_gpuaddr, loop_shadow_gpuaddr
+*/
+static void build_regsave_cmds(struct kgsl_device *device,
+			       struct kgsl_yamato_context *drawctxt,
+			       struct tmp_ctx *ctx)
+{
+	unsigned int *start = ctx->cmd;
+	unsigned int *cmd = start;
+
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	/* Make sure the HW context has the correct register values
+	 * before reading them. */
+	*cmd++ = pm4_type3_packet(PM4_CONTEXT_UPDATE, 1);
+	*cmd++ = 0;
+#endif
+
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	/* Write HW registers into shadow */
+	build_reg_to_mem_range(REG_RB_SURFACE_INFO, REG_RB_DEPTH_INFO,
+				&cmd, drawctxt);
+	build_reg_to_mem_range(REG_COHER_DEST_BASE_0,
+				REG_PA_SC_SCREEN_SCISSOR_BR,
+				&cmd, drawctxt);
+	build_reg_to_mem_range(REG_PA_SC_WINDOW_OFFSET,
+				REG_PA_SC_WINDOW_SCISSOR_BR,
+				&cmd, drawctxt);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		build_reg_to_mem_range(REG_VGT_MAX_VTX_INDX, REG_RB_FOG_COLOR,
+				&cmd, drawctxt);
+	} else {
+		build_reg_to_mem_range(REG_LEIA_PC_MAX_VTX_INDX,
+				REG_LEIA_PC_INDX_OFFSET,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_RB_COLOR_MASK,
+				REG_RB_FOG_COLOR,
+				&cmd, drawctxt);
+	}
+	build_reg_to_mem_range(REG_RB_STENCILREFMASK_BF,
+				REG_PA_CL_VPORT_ZOFFSET,
+				&cmd, drawctxt);
+	build_reg_to_mem_range(REG_SQ_PROGRAM_CNTL, REG_SQ_WRAPPING_1,
+				&cmd, drawctxt);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		build_reg_to_mem_range(REG_RB_DEPTHCONTROL, REG_RB_MODECONTROL,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_PA_SU_POINT_SIZE,
+				REG_PA_SC_LINE_STIPPLE,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_PA_SC_VIZ_QUERY, REG_PA_SC_VIZ_QUERY,
+				&cmd, drawctxt);
+	} else {
+		build_reg_to_mem_range(REG_RB_DEPTHCONTROL,
+				REG_RB_COLORCONTROL,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_PA_CL_CLIP_CNTL,
+				REG_PA_CL_VTE_CNTL,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_RB_MODECONTROL,
+				REG_LEIA_GRAS_CONTROL,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_PA_SU_POINT_SIZE,
+				REG_PA_SU_LINE_CNTL,
+				&cmd, drawctxt);
+	}
+	build_reg_to_mem_range(REG_PA_SC_LINE_CNTL, REG_SQ_PS_CONST,
+				&cmd, drawctxt);
+	build_reg_to_mem_range(REG_PA_SC_AA_MASK, REG_PA_SC_AA_MASK,
+				&cmd, drawctxt);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		build_reg_to_mem_range(REG_VGT_VERTEX_REUSE_BLOCK_CNTL,
+				REG_RB_DEPTH_CLEAR,
+				&cmd, drawctxt);
+	} else {
+		build_reg_to_mem_range(REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
+				REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
+				&cmd, drawctxt);
+		build_reg_to_mem_range(REG_RB_COPY_CONTROL,
+				REG_RB_DEPTH_CLEAR,
+				&cmd, drawctxt);
+	}
+	build_reg_to_mem_range(REG_RB_SAMPLE_COUNT_CTL,
+				REG_RB_COLOR_DEST_MASK,
+				&cmd, drawctxt);
+	build_reg_to_mem_range(REG_PA_SU_POLY_OFFSET_FRONT_SCALE,
+				REG_PA_SU_POLY_OFFSET_BACK_OFFSET,
+				&cmd, drawctxt);
+
+	/* Copy ALU constants */
+	cmd =
+	    reg_to_mem(cmd, (drawctxt->gpustate.gpuaddr) & 0xFFFFE000,
+		       REG_SQ_CONSTANT_0, ALU_CONSTANTS);
+
+	/* Copy Tex constants */
+	cmd =
+	    reg_to_mem(cmd,
+		       (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000,
+		       REG_SQ_FETCH_0, TEX_CONSTANTS);
+#else
+
+	/* Insert a wait for idle packet before reading the registers.
+	 * This is to fix a hang/reset seen during stress testing.  In this
+	 * hang, CP encountered a timeout reading SQ's boolean constant
+	 * register. There is logic in the HW that blocks reading of this
+	 * register when the SQ block is not idle, which we believe is
+	 * contributing to the hang.*/
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+
+	/* H/w registers are already shadowed; just need to disable shadowing
+	 * to prevent corruption.
+	 */
+	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
+	*cmd++ = (drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000;
+	*cmd++ = 4 << 16;	/* regs, start=0 */
+	*cmd++ = 0x0;		/* count = 0 */
+
+	/* ALU constants are already shadowed; just need to disable shadowing
+	 * to prevent corruption.
+	 */
+	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
+	*cmd++ = drawctxt->gpustate.gpuaddr & 0xFFFFE000;
+	*cmd++ = 0 << 16;	/* ALU, start=0 */
+	*cmd++ = 0x0;		/* count = 0 */
+
+	/* Tex constants are already shadowed; just need to disable shadowing
+	 *  to prevent corruption.
+	 */
+	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
+	*cmd++ = (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000;
+	*cmd++ = 1 << 16;	/* Tex, start=0 */
+	*cmd++ = 0x0;		/* count = 0 */
+#endif
+
+	/* Need to handle some of the registers separately */
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_SQ_GPR_MANAGEMENT;
+	*cmd++ = ctx->reg_values[0];
+
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_TP0_CHICKEN;
+	*cmd++ = ctx->reg_values[1];
+
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_RBBM_PM_OVERRIDE2;
+	*cmd++ = ctx->reg_values[2];
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
+		unsigned int i;
+		unsigned int j = 3;
+		for (i = REG_LEIA_VSC_BIN_SIZE; i <=
+				REG_LEIA_VSC_PIPE_DATA_LENGTH_7; i++) {
+			*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+			*cmd++ = i;
+			*cmd++ = ctx->reg_values[j];
+			j++;
+		}
+	}
+
+	/* Copy Boolean constants */
+	cmd = reg_to_mem(cmd, ctx->bool_shadow, REG_SQ_CF_BOOLEANS,
+			 BOOL_CONSTANTS);
+
+	/* Copy Loop constants */
+	cmd = reg_to_mem(cmd, ctx->loop_shadow, REG_SQ_CF_LOOP, LOOP_CONSTANTS);
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->reg_save, start, cmd);
+
+	ctx->cmd = cmd;
+}
+
+/*copy colour, depth, & stencil buffers from graphics memory to system memory*/
+static unsigned int *build_gmem2sys_cmds(struct kgsl_device *device,
+					 struct kgsl_yamato_context *drawctxt,
+					 struct tmp_ctx *ctx,
+					 struct gmem_shadow_t *shadow)
+{
+	unsigned int *cmds = shadow->gmem_save_commands;
+	unsigned int *start = cmds;
+	/* Calculate the new offset based on the adjusted base */
+	unsigned int bytesperpixel = format2bytesperpixel[shadow->format];
+	unsigned int addr = shadow->gmemshadow.gpuaddr;
+	unsigned int offset = (addr - (addr & 0xfffff000)) / bytesperpixel;
+
+	/* Store TP0_CHICKEN register */
+	*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmds++ = REG_TP0_CHICKEN;
+	if (ctx)
+		*cmds++ = ctx->chicken_restore;
+	else
+		cmds++;
+
+	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmds++ = 0;
+
+	/* Set TP0_CHICKEN to zero */
+	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
+	*cmds++ = 0x00000000;
+
+	/* Set PA_SC_AA_CONFIG to 0 */
+	*cmds++ = pm4_type0_packet(REG_PA_SC_AA_CONFIG, 1);
+	*cmds++ = 0x00000000;
+
+	/* program shader */
+
+	/* load shader vtx constants ... 5 dwords */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
+	*cmds++ = (0x1 << 16) | SHADER_CONST_ADDR;
+	*cmds++ = 0;
+	/* valid(?) vtx constant flag & addr */
+	*cmds++ = shadow->quad_vertices.gpuaddr | 0x3;
+	/* limit = 12 dwords */
+	*cmds++ = 0x00000030;
+
+	/* Invalidate L2 cache to make sure vertices are updated */
+	*cmds++ = pm4_type0_packet(REG_TC_CNTL_STATUS, 1);
+	*cmds++ = 0x1;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
+	*cmds++ = PM4_REG(REG_VGT_MAX_VTX_INDX);
+	*cmds++ = 0x00ffffff;	/* REG_VGT_MAX_VTX_INDX */
+	*cmds++ = 0x0;		/* REG_VGT_MIN_VTX_INDX */
+	*cmds++ = 0x00000000;	/* REG_VGT_INDX_OFFSET */
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_SC_AA_MASK);
+	*cmds++ = 0x0000ffff;	/* REG_PA_SC_AA_MASK */
+
+	/* load the patched vertex shader stream */
+	cmds = program_shader(cmds, 0, gmem2sys_vtx_pgm, GMEM2SYS_VTX_PGM_LEN);
+
+	/* Load the patched fragment shader stream */
+	cmds =
+	    program_shader(cmds, 1, gmem2sys_frag_pgm, GMEM2SYS_FRAG_PGM_LEN);
+
+	/* SQ_PROGRAM_CNTL / SQ_CONTEXT_MISC */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_SQ_PROGRAM_CNTL);
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		*cmds++ = 0x10018001;
+	else
+		*cmds++ = 0x10010001;
+	*cmds++ = 0x00000008;
+
+	/* resolve */
+
+	/* PA_CL_VTE_CNTL */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_CL_VTE_CNTL);
+	/* disable X/Y/Z transforms, X/Y/Z are premultiplied by W */
+	*cmds++ = 0x00000b00;
+
+	/* program surface info */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_RB_SURFACE_INFO);
+	*cmds++ = shadow->gmem_pitch;	/* pitch, MSAA = 1 */
+
+	/* RB_COLOR_INFO Endian=none, Linear, Format=RGBA8888, Swap=0,
+	 *                Base=gmem_base
+	 */
+	/* gmem base assumed 4K aligned. */
+	if (ctx) {
+		BUG_ON(ctx->gmem_base & 0xFFF);
+		*cmds++ =
+		    (shadow->
+		     format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT) | ctx->
+		    gmem_base;
+	} else {
+		unsigned int temp = *cmds;
+		*cmds++ = (temp & ~RB_COLOR_INFO__COLOR_FORMAT_MASK) |
+			(shadow->format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT);
+	}
+
+	/* disable Z */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_DEPTHCONTROL);
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		*cmds++ = 0x08;
+	else
+		*cmds++ = 0;
+
+	/* set REG_PA_SU_SC_MODE_CNTL
+	 *              Front_ptype = draw triangles
+	 *              Back_ptype = draw triangles
+	 *              Provoking vertex = last
+	 */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_SU_SC_MODE_CNTL);
+	*cmds++ = 0x00080240;
+
+	/* Use maximum scissor values -- quad vertices already have the
+	 * correct bounds */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_SC_SCREEN_SCISSOR_TL);
+	*cmds++ = (0 << 16) | 0;
+	*cmds++ = (0x1fff << 16) | (0x1fff);
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_SC_WINDOW_SCISSOR_TL);
+	*cmds++ = (unsigned int)((1U << 31) | (0 << 16) | 0);
+	*cmds++ = (0x1fff << 16) | (0x1fff);
+
+	/* load the viewport so that z scale = clear depth and
+	 *  z offset = 0.0f
+	 */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_CL_VPORT_ZSCALE);
+	*cmds++ = 0xbf800000;	/* -1.0f */
+	*cmds++ = 0x0;
+
+	/* load the stencil ref value
+	 * $AAM - do this later
+	 */
+
+	/* load the COPY state */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 6);
+	*cmds++ = PM4_REG(REG_RB_COPY_CONTROL);
+	*cmds++ = 0;		/* RB_COPY_CONTROL */
+	*cmds++ = addr & 0xfffff000;	/* RB_COPY_DEST_BASE */
+	*cmds++ = shadow->pitch >> 5;	/* RB_COPY_DEST_PITCH */
+
+	/* Endian=none, Linear, Format=RGBA8888,Swap=0,!Dither,
+	 *  MaskWrite:R=G=B=A=1
+	 */
+	*cmds++ = 0x0003c008 |
+	    (shadow->format << RB_COPY_DEST_INFO__COPY_DEST_FORMAT__SHIFT);
+	/* Make sure we stay in offsetx field. */
+	BUG_ON(offset & 0xfffff000);
+	*cmds++ = offset;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_MODECONTROL);
+	*cmds++ = 0x6;		/* EDRAM copy */
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
+		*cmds++ = 0xc0043600; /* packet 3 3D_DRAW_INDX_2 */
+		*cmds++ = 0x0;
+		*cmds++ = 0x00004046; /* tristrip */
+		*cmds++ = 0x00000004; /* NUM_INDICES */
+		*cmds++ = 0x00010000; /* index: 0x00, 0x01 */
+		*cmds++ = 0x00030002; /* index: 0x02, 0x03 */
+	} else {
+		/* queue the draw packet */
+		*cmds++ = pm4_type3_packet(PM4_DRAW_INDX, 2);
+		*cmds++ = 0;		/* viz query info. */
+		/* PrimType=RectList, NumIndices=3, SrcSel=AutoIndex */
+		*cmds++ = 0x00030088;
+	}
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, shadow->gmem_save, start, cmds);
+
+	return cmds;
+}
+
+/* context restore */
+
+/*copy colour, depth, & stencil buffers from system memory to graphics memory*/
+static unsigned int *build_sys2gmem_cmds(struct kgsl_device *device,
+					 struct kgsl_yamato_context *drawctxt,
+					 struct tmp_ctx *ctx,
+					 struct gmem_shadow_t *shadow)
+{
+	unsigned int *cmds = shadow->gmem_restore_commands;
+	unsigned int *start = cmds;
+
+	/* Store TP0_CHICKEN register */
+	*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmds++ = REG_TP0_CHICKEN;
+	if (ctx)
+		*cmds++ = ctx->chicken_restore;
+	else
+		cmds++;
+
+	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmds++ = 0;
+
+	/* Set TP0_CHICKEN to zero */
+	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
+	*cmds++ = 0x00000000;
+
+	/* Set PA_SC_AA_CONFIG to 0 */
+	*cmds++ = pm4_type0_packet(REG_PA_SC_AA_CONFIG, 1);
+	*cmds++ = 0x00000000;
+	/* shader constants */
+
+	/* vertex buffer constants */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 7);
+
+	*cmds++ = (0x1 << 16) | (9 * 6);
+	/* valid(?) vtx constant flag & addr */
+	*cmds++ = shadow->quad_vertices.gpuaddr | 0x3;
+	/* limit = 12 dwords */
+	*cmds++ = 0x00000030;
+	/* valid(?) vtx constant flag & addr */
+	*cmds++ = shadow->quad_texcoords.gpuaddr | 0x3;
+	/* limit = 8 dwords */
+	*cmds++ = 0x00000020;
+	*cmds++ = 0;
+	*cmds++ = 0;
+
+	/* Invalidate L2 cache to make sure vertices are updated */
+	*cmds++ = pm4_type0_packet(REG_TC_CNTL_STATUS, 1);
+	*cmds++ = 0x1;
+
+	cmds = program_shader(cmds, 0, sys2gmem_vtx_pgm, SYS2GMEM_VTX_PGM_LEN);
+
+	/* Load the patched fragment shader stream */
+	cmds =
+	    program_shader(cmds, 1, sys2gmem_frag_pgm, SYS2GMEM_FRAG_PGM_LEN);
+
+	/* SQ_PROGRAM_CNTL / SQ_CONTEXT_MISC */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_SQ_PROGRAM_CNTL);
+	*cmds++ = 0x10030002;
+	*cmds++ = 0x00000008;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_SC_AA_MASK);
+	*cmds++ = 0x0000ffff;	/* REG_PA_SC_AA_MASK */
+
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		/* PA_SC_VIZ_QUERY */
+		*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+		*cmds++ = PM4_REG(REG_PA_SC_VIZ_QUERY);
+		*cmds++ = 0x0;		/*REG_PA_SC_VIZ_QUERY */
+	}
+
+	/* RB_COLORCONTROL */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_COLORCONTROL);
+	*cmds++ = 0x00000c20;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
+	*cmds++ = PM4_REG(REG_VGT_MAX_VTX_INDX);
+	*cmds++ = 0x00ffffff;	/* mmVGT_MAX_VTX_INDX */
+	*cmds++ = 0x0;		/* mmVGT_MIN_VTX_INDX */
+	*cmds++ = 0x00000000;	/* mmVGT_INDX_OFFSET */
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_VGT_VERTEX_REUSE_BLOCK_CNTL);
+	*cmds++ = 0x00000002;	/* mmVGT_VERTEX_REUSE_BLOCK_CNTL */
+	*cmds++ = 0x00000002;	/* mmVGT_OUT_DEALLOC_CNTL */
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_SQ_INTERPOLATOR_CNTL);
+	*cmds++ = 0xffffffff;	/* mmSQ_INTERPOLATOR_CNTL */
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_SC_AA_CONFIG);
+	*cmds++ = 0x00000000;	/* REG_PA_SC_AA_CONFIG */
+
+	/* set REG_PA_SU_SC_MODE_CNTL
+	 * Front_ptype = draw triangles
+	 * Back_ptype = draw triangles
+	 * Provoking vertex = last
+	 */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_SU_SC_MODE_CNTL);
+	*cmds++ = 0x00080240;
+
+	/* texture constants */
+	*cmds++ =
+	    pm4_type3_packet(PM4_SET_CONSTANT, (SYS2GMEM_TEX_CONST_LEN + 1));
+	*cmds++ = (0x1 << 16) | (0 * 6);
+	memcpy(cmds, sys2gmem_tex_const, SYS2GMEM_TEX_CONST_LEN << 2);
+	cmds[0] |= (shadow->pitch >> 5) << 22;
+	cmds[1] |=
+	    shadow->gmemshadow.gpuaddr | surface_format_table[shadow->format];
+	cmds[2] |= (shadow->width - 1) | (shadow->height - 1) << 13;
+	cmds += SYS2GMEM_TEX_CONST_LEN;
+
+	/* program surface info */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_RB_SURFACE_INFO);
+	*cmds++ = shadow->gmem_pitch;	/* pitch, MSAA = 1 */
+
+	/* RB_COLOR_INFO Endian=none, Linear, Format=RGBA8888, Swap=0,
+	 *                Base=gmem_base
+	 */
+	if (ctx)
+		*cmds++ =
+		    (shadow->
+		     format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT) | ctx->
+		    gmem_base;
+	else {
+		unsigned int temp = *cmds;
+		*cmds++ = (temp & ~RB_COLOR_INFO__COLOR_FORMAT_MASK) |
+			(shadow->format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT);
+	}
+
+	/* RB_DEPTHCONTROL */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_DEPTHCONTROL);
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		*cmds++ = 8;		/* disable Z */
+	else
+		*cmds++ = 0;		/* disable Z */
+
+	/* Use maximum scissor values -- quad vertices already
+	 * have the correct bounds */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_SC_SCREEN_SCISSOR_TL);
+	*cmds++ = (0 << 16) | 0;
+	*cmds++ = ((0x1fff) << 16) | 0x1fff;
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_SC_WINDOW_SCISSOR_TL);
+	*cmds++ = (unsigned int)((1U << 31) | (0 << 16) | 0);
+	*cmds++ = ((0x1fff) << 16) | 0x1fff;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_PA_CL_VTE_CNTL);
+	/* disable X/Y/Z transforms, X/Y/Z are premultiplied by W */
+	*cmds++ = 0x00000b00;
+
+	/*load the viewport so that z scale = clear depth and z offset = 0.0f */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_PA_CL_VPORT_ZSCALE);
+	*cmds++ = 0xbf800000;
+	*cmds++ = 0x0;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_COLOR_MASK);
+	*cmds++ = 0x0000000f;	/* R = G = B = 1:enabled */
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_COLOR_DEST_MASK);
+	*cmds++ = 0xffffffff;
+
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
+	*cmds++ = PM4_REG(REG_SQ_WRAPPING_0);
+	*cmds++ = 0x00000000;
+	*cmds++ = 0x00000000;
+
+	/* load the stencil ref value
+	 *  $AAM - do this later
+	 */
+	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
+	*cmds++ = PM4_REG(REG_RB_MODECONTROL);
+	/* draw pixels with color and depth/stencil component */
+	*cmds++ = 0x4;
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
+		*cmds++ = 0xc0043600; /* packet 3 3D_DRAW_INDX_2 */
+		*cmds++ = 0x0;
+		*cmds++ = 0x00004046; /* tristrip */
+		*cmds++ = 0x00000004; /* NUM_INDICES */
+		*cmds++ = 0x00010000; /* index: 0x00, 0x01 */
+		*cmds++ = 0x00030002; /* index: 0x02, 0x03 */
+	} else {
+		/* queue the draw packet */
+		*cmds++ = pm4_type3_packet(PM4_DRAW_INDX, 2);
+		*cmds++ = 0;		/* viz query info. */
+		/* PrimType=RectList, NumIndices=3, SrcSel=AutoIndex */
+		*cmds++ = 0x00030088;
+	}
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, shadow->gmem_restore, start, cmds);
+
+	return cmds;
+}
+
+/* restore h/w regs, alu constants, texture constants, etc. ... */
+static unsigned *reg_range(unsigned int *cmd, unsigned int start,
+			   unsigned int end)
+{
+	*cmd++ = PM4_REG(start);	/* h/w regs, start addr */
+	*cmd++ = end - start + 1;	/* count */
+	return cmd;
+}
+
+static void build_regrestore_cmds(struct kgsl_device *device,
+				  struct kgsl_yamato_context *drawctxt,
+				  struct tmp_ctx *ctx)
+{
+	unsigned int *start = ctx->cmd;
+	unsigned int *cmd = start;
+
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+
+	/* H/W Registers */
+	/* deferred pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, ???); */
+	cmd++;
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	/* Force mismatch */
+	*cmd++ = ((drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000) | 1;
+#else
+	*cmd++ = (drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000;
+#endif
+
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		cmd = reg_range(cmd, REG_RB_SURFACE_INFO,
+				REG_PA_SC_SCREEN_SCISSOR_BR);
+	} else {
+		cmd = reg_range(cmd, REG_RB_SURFACE_INFO, REG_RB_DEPTH_INFO);
+		cmd = reg_range(cmd, REG_COHER_DEST_BASE_0,
+				REG_PA_SC_SCREEN_SCISSOR_BR);
+	}
+	cmd = reg_range(cmd, REG_PA_SC_WINDOW_OFFSET,
+				REG_PA_SC_WINDOW_SCISSOR_BR);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		cmd = reg_range(cmd, REG_VGT_MAX_VTX_INDX,
+				REG_PA_CL_VPORT_ZOFFSET);
+	} else {
+		cmd = reg_range(cmd, REG_LEIA_PC_MAX_VTX_INDX,
+				REG_LEIA_PC_INDX_OFFSET);
+		cmd = reg_range(cmd, REG_RB_COLOR_MASK, REG_RB_FOG_COLOR);
+		cmd = reg_range(cmd, REG_RB_STENCILREFMASK_BF,
+				REG_PA_CL_VPORT_ZOFFSET);
+	}
+	cmd = reg_range(cmd, REG_SQ_PROGRAM_CNTL, REG_SQ_WRAPPING_1);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
+		cmd = reg_range(cmd, REG_RB_DEPTHCONTROL, REG_RB_MODECONTROL);
+		cmd = reg_range(cmd, REG_PA_SU_POINT_SIZE,
+				REG_PA_SC_VIZ_QUERY); /*REG_VGT_ENHANCE */
+		cmd = reg_range(cmd, REG_PA_SC_LINE_CNTL,
+				REG_RB_COLOR_DEST_MASK);
+	} else {
+		cmd = reg_range(cmd, REG_RB_DEPTHCONTROL, REG_RB_COLORCONTROL);
+		cmd = reg_range(cmd, REG_PA_CL_CLIP_CNTL, REG_PA_CL_VTE_CNTL);
+		cmd = reg_range(cmd, REG_RB_MODECONTROL, REG_LEIA_GRAS_CONTROL);
+		cmd = reg_range(cmd, REG_PA_SU_POINT_SIZE, REG_PA_SU_LINE_CNTL);
+		cmd = reg_range(cmd, REG_PA_SC_LINE_CNTL, REG_SQ_PS_CONST);
+		cmd = reg_range(cmd, REG_PA_SC_AA_MASK, REG_PA_SC_AA_MASK);
+		cmd = reg_range(cmd, REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
+				REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL);
+		cmd = reg_range(cmd, REG_RB_COPY_CONTROL, REG_RB_DEPTH_CLEAR);
+		cmd = reg_range(cmd, REG_RB_SAMPLE_COUNT_CTL,
+				REG_RB_COLOR_DEST_MASK);
+	}
+	cmd = reg_range(cmd, REG_PA_SU_POLY_OFFSET_FRONT_SCALE,
+				REG_PA_SU_POLY_OFFSET_BACK_OFFSET);
+
+	/* Now we know how many register blocks we have, we can compute command
+	 * length
+	 */
+	start[2] =
+	    pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, (cmd - start) - 3);
+	/* Enable shadowing for the entire register block. */
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	start[4] |= (0 << 24) | (4 << 16);	/* Disable shadowing. */
+#else
+	start[4] |= (1 << 24) | (4 << 16);
+#endif
+
+	/* Need to handle some of the registers separately */
+	*cmd++ = pm4_type0_packet(REG_SQ_GPR_MANAGEMENT, 1);
+	ctx->reg_values[0] = gpuaddr(cmd, &drawctxt->gpustate);
+	*cmd++ = 0x00040400;
+
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+	*cmd++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
+	ctx->reg_values[1] = gpuaddr(cmd, &drawctxt->gpustate);
+	*cmd++ = 0x00000000;
+
+	*cmd++ = pm4_type0_packet(REG_RBBM_PM_OVERRIDE2, 1);
+	ctx->reg_values[2] = gpuaddr(cmd, &drawctxt->gpustate);
+	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
+		*cmd++ = 0x00000000;
+	else
+		*cmd++ = 0x80;
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
+		unsigned int i;
+		unsigned int j = 3;
+		for (i = REG_LEIA_VSC_BIN_SIZE; i <=
+				REG_LEIA_VSC_PIPE_DATA_LENGTH_7; i++) {
+			*cmd++ = pm4_type0_packet(i, 1);
+			ctx->reg_values[j] = gpuaddr(cmd, &drawctxt->gpustate);
+			*cmd++ = 0x00000000;
+			j++;
+		}
+	}
+
+	/* ALU Constants */
+	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
+	*cmd++ = drawctxt->gpustate.gpuaddr & 0xFFFFE000;
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	*cmd++ = (0 << 24) | (0 << 16) | 0;	/* Disable shadowing */
+#else
+	*cmd++ = (1 << 24) | (0 << 16) | 0;
+#endif
+	*cmd++ = ALU_CONSTANTS;
+
+	/* Texture Constants */
+	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
+	*cmd++ = (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000;
+#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
+	/* Disable shadowing */
+	*cmd++ = (0 << 24) | (1 << 16) | 0;
+#else
+	*cmd++ = (1 << 24) | (1 << 16) | 0;
+#endif
+	*cmd++ = TEX_CONSTANTS;
+
+	/* Boolean Constants */
+	*cmd++ = pm4_type3_packet(PM4_SET_CONSTANT, 1 + BOOL_CONSTANTS);
+	*cmd++ = (2 << 16) | 0;
+
+	/* the next BOOL_CONSTANT dwords is the shadow area for
+	 *  boolean constants.
+	 */
+	ctx->bool_shadow = gpuaddr(cmd, &drawctxt->gpustate);
+	cmd += BOOL_CONSTANTS;
+
+	/* Loop Constants */
+	*cmd++ = pm4_type3_packet(PM4_SET_CONSTANT, 1 + LOOP_CONSTANTS);
+	*cmd++ = (3 << 16) | 0;
+
+	/* the next LOOP_CONSTANTS dwords is the shadow area for
+	 * loop constants.
+	 */
+	ctx->loop_shadow = gpuaddr(cmd, &drawctxt->gpustate);
+	cmd += LOOP_CONSTANTS;
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->reg_restore, start, cmd);
+
+	ctx->cmd = cmd;
+}
+
+/* quad for saving/restoring gmem */
+static void set_gmem_copy_quad(struct gmem_shadow_t *shadow)
+{
+	/* set vertex buffer values */
+	gmem_copy_quad[1] = uint2float(shadow->height);
+	gmem_copy_quad[3] = uint2float(shadow->width);
+	gmem_copy_quad[4] = uint2float(shadow->height);
+	gmem_copy_quad[9] = uint2float(shadow->width);
+
+	gmem_copy_quad[0] = uint2float(0);
+	gmem_copy_quad[6] = uint2float(0);
+	gmem_copy_quad[7] = uint2float(0);
+	gmem_copy_quad[10] = uint2float(0);
+
+	memcpy(shadow->quad_vertices.hostptr, gmem_copy_quad, QUAD_LEN << 2);
+
+	memcpy(shadow->quad_texcoords.hostptr, gmem_copy_texcoord,
+	       TEXCOORD_LEN << 2);
+}
+
+/* quad for saving/restoring gmem */
+static void build_quad_vtxbuff(struct kgsl_yamato_context *drawctxt,
+		       struct tmp_ctx *ctx, struct gmem_shadow_t *shadow)
+{
+	unsigned int *cmd = ctx->cmd;
+
+	/* quad vertex buffer location (in GPU space) */
+	shadow->quad_vertices.hostptr = cmd;
+	shadow->quad_vertices.gpuaddr = gpuaddr(cmd, &drawctxt->gpustate);
+
+	cmd += QUAD_LEN;
+
+	/* tex coord buffer location (in GPU space) */
+	shadow->quad_texcoords.hostptr = cmd;
+	shadow->quad_texcoords.gpuaddr = gpuaddr(cmd, &drawctxt->gpustate);
+
+	cmd += TEXCOORD_LEN;
+
+	set_gmem_copy_quad(shadow);
+
+	ctx->cmd = cmd;
+}
+
+static void
+build_shader_save_restore_cmds(struct kgsl_yamato_context *drawctxt,
+			       struct tmp_ctx *ctx)
+{
+	unsigned int *cmd = ctx->cmd;
+	unsigned int *save, *restore, *fixup;
+#if defined(PM4_IM_STORE)
+	unsigned int *startSizeVtx, *startSizePix, *startSizeShared;
+#endif
+	unsigned int *partition1;
+	unsigned int *shaderBases, *partition2;
+
+#if defined(PM4_IM_STORE)
+	/* compute vertex, pixel and shared instruction shadow GPU addresses */
+	ctx->shader_vertex = drawctxt->gpustate.gpuaddr + SHADER_OFFSET;
+	ctx->shader_pixel = ctx->shader_vertex + SHADER_SHADOW_SIZE;
+	ctx->shader_shared = ctx->shader_pixel + SHADER_SHADOW_SIZE;
+#endif
+
+	/* restore shader partitioning and instructions */
+
+	restore = cmd;		/* start address */
+
+	/* Invalidate Vertex & Pixel instruction code address and sizes */
+	*cmd++ = pm4_type3_packet(PM4_INVALIDATE_STATE, 1);
+	*cmd++ = 0x00000300;	/* 0x100 = Vertex, 0x200 = Pixel */
+
+	/* Restore previous shader vertex & pixel instruction bases. */
+	*cmd++ = pm4_type3_packet(PM4_SET_SHADER_BASES, 1);
+	shaderBases = cmd++;	/* TBD #5: shader bases (from fixup) */
+
+	/* write the shader partition information to a scratch register */
+	*cmd++ = pm4_type0_packet(REG_SQ_INST_STORE_MANAGMENT, 1);
+	partition1 = cmd++;	/* TBD #4a: partition info (from save) */
+
+#if defined(PM4_IM_STORE)
+	/* load vertex shader instructions from the shadow. */
+	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
+	*cmd++ = ctx->shader_vertex + 0x0;	/* 0x0 = Vertex */
+	startSizeVtx = cmd++;	/* TBD #1: start/size (from save) */
+
+	/* load pixel shader instructions from the shadow. */
+	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
+	*cmd++ = ctx->shader_pixel + 0x1;	/* 0x1 = Pixel */
+	startSizePix = cmd++;	/* TBD #2: start/size (from save) */
+
+	/* load shared shader instructions from the shadow. */
+	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
+	*cmd++ = ctx->shader_shared + 0x2;	/* 0x2 = Shared */
+	startSizeShared = cmd++;	/* TBD #3: start/size (from save) */
+#endif
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->shader_restore, restore, cmd);
+
+	/*
+	 *  fixup SET_SHADER_BASES data
+	 *
+	 *  since self-modifying PM4 code is being used here, a seperate
+	 *  command buffer is used for this fixup operation, to ensure the
+	 *  commands are not read by the PM4 engine before the data fields
+	 *  have been written.
+	 */
+
+	fixup = cmd;		/* start address */
+
+	/* write the shader partition information to a scratch register */
+	*cmd++ = pm4_type0_packet(REG_SCRATCH_REG2, 1);
+	partition2 = cmd++;	/* TBD #4b: partition info (from save) */
+
+	/* mask off unused bits, then OR with shader instruction memory size */
+	*cmd++ = pm4_type3_packet(PM4_REG_RMW, 3);
+	*cmd++ = REG_SCRATCH_REG2;
+	/* AND off invalid bits. */
+	*cmd++ = 0x0FFF0FFF;
+	/* OR in instruction memory size */
+	*cmd++ = (unsigned int)((SHADER_INSTRUCT_LOG2 - 5U) << 29);
+
+	/* write the computed value to the SET_SHADER_BASES data field */
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_SCRATCH_REG2;
+	/* TBD #5: shader bases (to restore) */
+	*cmd++ = gpuaddr(shaderBases, &drawctxt->gpustate);
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->shader_fixup, fixup, cmd);
+
+	/* save shader partitioning and instructions */
+
+	save = cmd;		/* start address */
+
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+
+	/* fetch the SQ_INST_STORE_MANAGMENT register value,
+	 *  store the value in the data fields of the SET_CONSTANT commands
+	 *  above.
+	 */
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_SQ_INST_STORE_MANAGMENT;
+	/* TBD #4a: partition info (to restore) */
+	*cmd++ = gpuaddr(partition1, &drawctxt->gpustate);
+	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
+	*cmd++ = REG_SQ_INST_STORE_MANAGMENT;
+	/* TBD #4b: partition info (to fixup) */
+	*cmd++ = gpuaddr(partition2, &drawctxt->gpustate);
+
+#if defined(PM4_IM_STORE)
+
+	/* store the vertex shader instructions */
+	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
+	*cmd++ = ctx->shader_vertex + 0x0;	/* 0x0 = Vertex */
+	/* TBD #1: start/size (to restore) */
+	*cmd++ = gpuaddr(startSizeVtx, &drawctxt->gpustate);
+
+	/* store the pixel shader instructions */
+	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
+	*cmd++ = ctx->shader_pixel + 0x1;	/* 0x1 = Pixel */
+	/* TBD #2: start/size (to restore) */
+	*cmd++ = gpuaddr(startSizePix, &drawctxt->gpustate);
+
+	/* store the shared shader instructions if vertex base is nonzero */
+
+	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
+	*cmd++ = ctx->shader_shared + 0x2;	/* 0x2 = Shared */
+	/* TBD #3: start/size (to restore) */
+	*cmd++ = gpuaddr(startSizeShared, &drawctxt->gpustate);
+
+#endif
+
+	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
+	*cmd++ = 0;
+
+	/* create indirect buffer command for above command sequence */
+	create_ib1(drawctxt, drawctxt->shader_save, save, cmd);
+
+	ctx->cmd = cmd;
+}
+
+/* create buffers for saving/restoring registers, constants, & GMEM */
+static int
+create_gpustate_shadow(struct kgsl_device *device,
+		       struct kgsl_yamato_context *drawctxt,
+		       struct tmp_ctx *ctx)
+{
+	int result;
+
+	/* Allocate vmalloc memory to store the gpustate */
+	result = kgsl_sharedmem_vmalloc(&drawctxt->gpustate,
+					drawctxt->pagetable, CONTEXT_SIZE);
+
+	if (result)
+		return result;
+
+	drawctxt->flags |= CTXT_FLAGS_STATE_SHADOW;
+
+	/* Blank out h/w register, constant, and command buffer shadows. */
+	kgsl_sharedmem_set(&drawctxt->gpustate, 0, 0, CONTEXT_SIZE);
+
+	/* set-up command and vertex buffer pointers */
+	ctx->cmd = ctx->start
+	    = (unsigned int *)((char *)drawctxt->gpustate.hostptr + CMD_OFFSET);
+
+	/* build indirect command buffers to save & restore regs/constants */
+	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+	build_regrestore_cmds(device, drawctxt, ctx);
+	build_regsave_cmds(device, drawctxt, ctx);
+
+	build_shader_save_restore_cmds(drawctxt, ctx);
+
+	kgsl_cache_range_op(&drawctxt->gpustate,
+			    KGSL_CACHE_OP_FLUSH);
+
+	return 0;
+}
+
+/* create buffers for saving/restoring registers, constants, & GMEM */
+static int
+create_gmem_shadow(struct kgsl_yamato_device *yamato_device,
+		   struct kgsl_yamato_context *drawctxt,
+		   struct tmp_ctx *ctx)
+{
+	struct kgsl_device *device = &yamato_device->dev;
+	int result;
+
+	config_gmemsize(&drawctxt->context_gmem_shadow,
+			yamato_device->gmemspace.sizebytes);
+	ctx->gmem_base = yamato_device->gmemspace.gpu_base;
+
+	result = kgsl_sharedmem_vmalloc(
+				&drawctxt->context_gmem_shadow.gmemshadow,
+			       drawctxt->pagetable,
+			       drawctxt->context_gmem_shadow.size);
+
+	if (result)
+		return result;
+
+	/* we've allocated the shadow, when swapped out, GMEM must be saved. */
+	drawctxt->flags |= CTXT_FLAGS_GMEM_SHADOW | CTXT_FLAGS_GMEM_SAVE;
+
+	/* blank out gmem shadow. */
+	kgsl_sharedmem_set(&drawctxt->context_gmem_shadow.gmemshadow, 0, 0,
+			   drawctxt->context_gmem_shadow.size);
+
+	/* build quad vertex buffer */
+	build_quad_vtxbuff(drawctxt, ctx, &drawctxt->context_gmem_shadow);
+
+	/* build TP0_CHICKEN register restore command buffer */
+	ctx->cmd = build_chicken_restore_cmds(drawctxt, ctx);
+
+	/* build indirect command buffers to save & restore gmem */
+	/* Idle because we are reading PM override registers */
+	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+	drawctxt->context_gmem_shadow.gmem_save_commands = ctx->cmd;
+	ctx->cmd =
+	    build_gmem2sys_cmds(device, drawctxt, ctx,
+				&drawctxt->context_gmem_shadow);
+	drawctxt->context_gmem_shadow.gmem_restore_commands = ctx->cmd;
+	ctx->cmd =
+	    build_sys2gmem_cmds(device, drawctxt, ctx,
+				&drawctxt->context_gmem_shadow);
+
+	kgsl_cache_range_op(&drawctxt->context_gmem_shadow.gmemshadow,
+			    KGSL_CACHE_OP_FLUSH);
+
+	return 0;
+}
+
+/* create a new drawing context */
+
+int
+kgsl_drawctxt_create(struct kgsl_device_private *dev_priv, uint32_t flags,
+		     struct kgsl_context *context)
+{
+	struct kgsl_yamato_context *drawctxt;
+	struct kgsl_device *device = dev_priv->device;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_pagetable *pagetable = dev_priv->process_priv->pagetable;
+	struct tmp_ctx ctx;
+	int ret;
+
+	drawctxt = kzalloc(sizeof(struct kgsl_yamato_context), GFP_KERNEL);
+
+	if (drawctxt == NULL)
+		return -ENOMEM;
+
+	drawctxt->pagetable = pagetable;
+	drawctxt->bin_base_offset = 0;
+
+	ret = create_gpustate_shadow(device, drawctxt, &ctx);
+	if (ret)
+		goto err;
+
+	/* Save the shader instruction memory on context switching */
+	drawctxt->flags |= CTXT_FLAGS_SHADER_SAVE;
+
+	memset(&drawctxt->context_gmem_shadow.gmemshadow,
+			0, sizeof(struct kgsl_memdesc));
+
+	if (!(flags & KGSL_CONTEXT_NO_GMEM_ALLOC)) {
+		/* create gmem shadow */
+		ret = create_gmem_shadow(yamato_device, drawctxt, &ctx);
+		if (ret != 0)
+			goto err;
+	}
+
+	BUG_ON(ctx.cmd - ctx.start > CMD_BUFFER_LEN);
+
+	context->devctxt = drawctxt;
+	return 0;
+err:
+	kgsl_sharedmem_free(&drawctxt->gpustate);
+	kfree(drawctxt);
+	return ret;
+}
+
+/* destroy a drawing context */
+
+int kgsl_drawctxt_destroy(struct kgsl_device *device,
+			  struct kgsl_context *context)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_yamato_context *drawctxt = context->devctxt;
+
+	if (drawctxt == NULL)
+		return -EINVAL;
+
+	/* deactivate context */
+	if (yamato_device->drawctxt_active == drawctxt) {
+		/* no need to save GMEM or shader, the context is
+		 * being destroyed.
+		 */
+		drawctxt->flags &= ~(CTXT_FLAGS_GMEM_SAVE |
+				     CTXT_FLAGS_SHADER_SAVE |
+				     CTXT_FLAGS_GMEM_SHADOW |
+				     CTXT_FLAGS_STATE_SHADOW);
+
+		kgsl_drawctxt_switch(yamato_device, NULL, 0);
+	}
+
+	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+
+	kgsl_sharedmem_free(&drawctxt->gpustate);
+	kgsl_sharedmem_free(&drawctxt->context_gmem_shadow.gmemshadow);
+
+	kfree(drawctxt);
+	context->devctxt = NULL;
+
+	return 0;
+}
+
+/* set bin base offset */
+int kgsl_drawctxt_set_bin_base_offset(struct kgsl_device *device,
+				      struct kgsl_context *context,
+				      unsigned int offset)
+{
+	struct kgsl_yamato_context *drawctxt = context->devctxt;
+
+	if (drawctxt == NULL)
+		return -EINVAL;
+
+	drawctxt->bin_base_offset = offset;
+
+	return 0;
+}
+
+/* switch drawing contexts */
+void
+kgsl_drawctxt_switch(struct kgsl_yamato_device *yamato_device,
+			struct kgsl_yamato_context *drawctxt,
+			unsigned int flags)
+{
+	struct kgsl_yamato_context *active_ctxt =
+	  yamato_device->drawctxt_active;
+	struct kgsl_device *device = &yamato_device->dev;
+	unsigned int cmds[5];
+
+	if (drawctxt) {
+		if (flags & KGSL_CONTEXT_SAVE_GMEM)
+			/* Set the flag in context so that the save is done
+			* when this context is switched out. */
+			drawctxt->flags |= CTXT_FLAGS_GMEM_SAVE;
+		else
+			/* Remove GMEM saving flag from the context */
+			drawctxt->flags &= ~CTXT_FLAGS_GMEM_SAVE;
+	}
+	/* already current? */
+	if (active_ctxt == drawctxt)
+		return;
+
+	KGSL_CTXT_INFO(device, "from %p to %p flags %d\n",
+			yamato_device->drawctxt_active, drawctxt, flags);
+	/* save old context*/
+	if (active_ctxt && active_ctxt->flags & CTXT_FLAGS_GPU_HANG)
+		KGSL_CTXT_WARN(device,
+			"Current active context has caused gpu hang\n");
+
+	if (active_ctxt != NULL) {
+		KGSL_CTXT_INFO(device,
+			"active_ctxt flags %08x\n", active_ctxt->flags);
+		/* save registers and constants. */
+		kgsl_ringbuffer_issuecmds(device, 0, active_ctxt->reg_save, 3);
+
+		if (active_ctxt->flags & CTXT_FLAGS_SHADER_SAVE) {
+			/* save shader partitioning and instructions. */
+			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
+						  active_ctxt->shader_save, 3);
+
+			/* fixup shader partitioning parameter for
+			 *  SET_SHADER_BASES.
+			 */
+			kgsl_ringbuffer_issuecmds(device, 0,
+					active_ctxt->shader_fixup, 3);
+
+			active_ctxt->flags |= CTXT_FLAGS_SHADER_RESTORE;
+		}
+
+		if (active_ctxt->flags & CTXT_FLAGS_GMEM_SAVE
+			&& active_ctxt->flags & CTXT_FLAGS_GMEM_SHADOW) {
+			/* save gmem.
+			 * (note: changes shader. shader must already be saved.)
+			 */
+			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
+				active_ctxt->context_gmem_shadow.gmem_save, 3);
+
+			/* Restore TP0_CHICKEN */
+			kgsl_ringbuffer_issuecmds(device, 0,
+				active_ctxt->chicken_restore, 3);
+
+			active_ctxt->flags |= CTXT_FLAGS_GMEM_RESTORE;
+		}
+	}
+
+	yamato_device->drawctxt_active = drawctxt;
+
+	/* restore new context */
+	if (drawctxt != NULL) {
+
+		KGSL_CTXT_INFO(device,
+			"drawctxt flags %08x\n", drawctxt->flags);
+		kgsl_mmu_setstate(device, drawctxt->pagetable);
+
+#ifndef CONFIG_MSM_KGSL_CFF_DUMP_NO_CONTEXT_MEM_DUMP
+		kgsl_cffdump_syncmem(NULL, &drawctxt->gpustate,
+			drawctxt->gpustate.gpuaddr, LCC_SHADOW_SIZE +
+			REG_SHADOW_SIZE + CMD_BUFFER_SIZE + TEX_SHADOW_SIZE,
+			false);
+#endif
+		cmds[0] = pm4_nop_packet(1);
+		cmds[1] = KGSL_CONTEXT_TO_MEM_IDENTIFIER;
+		cmds[2] = pm4_type3_packet(PM4_MEM_WRITE, 2);
+		cmds[3] = device->memstore.gpuaddr +
+				KGSL_DEVICE_MEMSTORE_OFFSET(current_context);
+		cmds[4] = (unsigned int)yamato_device->drawctxt_active;
+		kgsl_ringbuffer_issuecmds(device, 0, cmds, 5);
+
+		/* restore gmem.
+		 *  (note: changes shader. shader must not already be restored.)
+		 */
+		if (drawctxt->flags & CTXT_FLAGS_GMEM_RESTORE) {
+			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
+				drawctxt->context_gmem_shadow.gmem_restore, 3);
+
+			/* Restore TP0_CHICKEN */
+			kgsl_ringbuffer_issuecmds(device, 0,
+				drawctxt->chicken_restore, 3);
+
+			drawctxt->flags &= ~CTXT_FLAGS_GMEM_RESTORE;
+		}
+
+		/* restore registers and constants. */
+		kgsl_ringbuffer_issuecmds(device, 0,
+					  drawctxt->reg_restore, 3);
+
+		/* restore shader instructions & partitioning. */
+		if (drawctxt->flags & CTXT_FLAGS_SHADER_RESTORE) {
+			kgsl_ringbuffer_issuecmds(device, 0,
+					  drawctxt->shader_restore, 3);
+		}
+
+		cmds[0] = pm4_type3_packet(PM4_SET_BIN_BASE_OFFSET, 1);
+		cmds[1] = drawctxt->bin_base_offset;
+		if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
+			kgsl_ringbuffer_issuecmds(device, 0, cmds, 2);
+
+	} else
+		kgsl_mmu_setstate(device, device->mmu.defaultpagetable);
+}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.h
new file mode 100644
index 0000000..e737d24
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_drawctxt.h
@@ -0,0 +1,113 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __ADRENO_DRAWCTXT_H
+#define __ADRENO_DRAWCTXT_H
+
+#include "a200_reg.h"
+#include "leia_reg.h"
+
+/* Flags */
+
+#define CTXT_FLAGS_NOT_IN_USE		0x00000000
+#define CTXT_FLAGS_IN_USE		0x00000001
+
+/* state shadow memory allocated */
+#define CTXT_FLAGS_STATE_SHADOW		0x00000010
+
+/* gmem shadow memory allocated */
+#define CTXT_FLAGS_GMEM_SHADOW		0x00000100
+/* gmem must be copied to shadow */
+#define CTXT_FLAGS_GMEM_SAVE		0x00000200
+/* gmem can be restored from shadow */
+#define CTXT_FLAGS_GMEM_RESTORE		0x00000400
+/* shader must be copied to shadow */
+#define CTXT_FLAGS_SHADER_SAVE		0x00002000
+/* shader can be restored from shadow */
+#define CTXT_FLAGS_SHADER_RESTORE	0x00004000
+/* Context has caused a GPU hang */
+#define CTXT_FLAGS_GPU_HANG		0x00008000
+
+struct kgsl_device;
+struct kgsl_yamato_device;
+struct kgsl_device_private;
+struct kgsl_context;
+
+/* draw context */
+struct gmem_shadow_t {
+	struct kgsl_memdesc gmemshadow;	/* Shadow buffer address */
+
+	/* 256 KB GMEM surface = 4 bytes-per-pixel x 256 pixels/row x
+	* 256 rows. */
+	/* width & height must be a multiples of 32, in case tiled textures
+	 * are used. */
+	enum COLORFORMATX format;
+	unsigned int size;	/* Size of surface used to store GMEM */
+	unsigned int width;	/* Width of surface used to store GMEM */
+	unsigned int height;	/* Height of surface used to store GMEM */
+	unsigned int pitch;	/* Pitch of surface used to store GMEM */
+	unsigned int gmem_pitch;	/* Pitch value used for GMEM */
+	unsigned int *gmem_save_commands;
+	unsigned int *gmem_restore_commands;
+	unsigned int gmem_save[3];
+	unsigned int gmem_restore[3];
+	struct kgsl_memdesc quad_vertices;
+	struct kgsl_memdesc quad_texcoords;
+};
+
+struct kgsl_yamato_context {
+	uint32_t flags;
+	struct kgsl_pagetable *pagetable;
+	struct kgsl_memdesc gpustate;
+	unsigned int reg_save[3];
+	unsigned int reg_restore[3];
+	unsigned int shader_save[3];
+	unsigned int shader_fixup[3];
+	unsigned int shader_restore[3];
+	unsigned int chicken_restore[3];
+	unsigned int bin_base_offset;
+	/* Information of the GMEM shadow that is created in context create */
+	struct gmem_shadow_t context_gmem_shadow;
+};
+
+
+int kgsl_drawctxt_create(struct kgsl_device_private *dev_priv,
+			 uint32_t flags,
+			 struct kgsl_context *context);
+
+int kgsl_drawctxt_destroy(struct kgsl_device *device,
+			  struct kgsl_context *context);
+
+void kgsl_drawctxt_switch(struct kgsl_yamato_device *yamato_device,
+				struct kgsl_yamato_context *drawctxt,
+				unsigned int flags);
+int kgsl_drawctxt_set_bin_base_offset(struct kgsl_device *device,
+				      struct kgsl_context *context,
+					unsigned int offset);
+
+#endif  /* __ADRENO_DRAWCTXT_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_pm4types.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_pm4types.h
new file mode 100644
index 0000000..246315b
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_pm4types.h
@@ -0,0 +1,193 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __ADRENO_PM4TYPES_H
+#define __ADRENO_PM4TYPES_H
+
+
+#define PM4_PKT_MASK	0xc0000000
+
+#define PM4_TYPE0_PKT	((unsigned int)0 << 30)
+#define PM4_TYPE1_PKT	((unsigned int)1 << 30)
+#define PM4_TYPE2_PKT	((unsigned int)2 << 30)
+#define PM4_TYPE3_PKT	((unsigned int)3 << 30)
+
+
+/* type3 packets */
+/* initialize CP's micro-engine */
+#define PM4_ME_INIT		0x48
+
+/* skip N 32-bit words to get to the next packet */
+#define PM4_NOP			0x10
+
+/* indirect buffer dispatch.  prefetch parser uses this packet type to determine
+*  whether to pre-fetch the IB
+*/
+#define PM4_INDIRECT_BUFFER	0x3f
+
+/* indirect buffer dispatch.  same as IB, but init is pipelined */
+#define PM4_INDIRECT_BUFFER_PFD	0x37
+
+/* wait for the IDLE state of the engine */
+#define PM4_WAIT_FOR_IDLE	0x26
+
+/* wait until a register or memory location is a specific value */
+#define PM4_WAIT_REG_MEM	0x3c
+
+/* wait until a register location is equal to a specific value */
+#define PM4_WAIT_REG_EQ		0x52
+
+/* wait until a register location is >= a specific value */
+#define PM4_WAT_REG_GTE		0x53
+
+/* wait until a read completes */
+#define PM4_WAIT_UNTIL_READ	0x5c
+
+/* wait until all base/size writes from an IB_PFD packet have completed */
+#define PM4_WAIT_IB_PFD_COMPLETE 0x5d
+
+/* register read/modify/write */
+#define PM4_REG_RMW		0x21
+
+/* reads register in chip and writes to memory */
+#define PM4_REG_TO_MEM		0x3e
+
+/* write N 32-bit words to memory */
+#define PM4_MEM_WRITE		0x3d
+
+/* write CP_PROG_COUNTER value to memory */
+#define PM4_MEM_WRITE_CNTR	0x4f
+
+/* conditional execution of a sequence of packets */
+#define PM4_COND_EXEC		0x44
+
+/* conditional write to memory or register */
+#define PM4_COND_WRITE		0x45
+
+/* generate an event that creates a write to memory when completed */
+#define PM4_EVENT_WRITE		0x46
+
+/* generate a VS|PS_done event */
+#define PM4_EVENT_WRITE_SHD	0x58
+
+/* generate a cache flush done event */
+#define PM4_EVENT_WRITE_CFL	0x59
+
+/* generate a z_pass done event */
+#define PM4_EVENT_WRITE_ZPD	0x5b
+
+
+/* initiate fetch of index buffer and draw */
+#define PM4_DRAW_INDX		0x22
+
+/* draw using supplied indices in packet */
+#define PM4_DRAW_INDX_2		0x36
+
+/* initiate fetch of index buffer and binIDs and draw */
+#define PM4_DRAW_INDX_BIN	0x34
+
+/* initiate fetch of bin IDs and draw using supplied indices */
+#define PM4_DRAW_INDX_2_BIN	0x35
+
+
+/* begin/end initiator for viz query extent processing */
+#define PM4_VIZ_QUERY		0x23
+
+/* fetch state sub-blocks and initiate shader code DMAs */
+#define PM4_SET_STATE		0x25
+
+/* load constant into chip and to memory */
+#define PM4_SET_CONSTANT	0x2d
+
+/* load sequencer instruction memory (pointer-based) */
+#define PM4_IM_LOAD		0x27
+
+/* load sequencer instruction memory (code embedded in packet) */
+#define PM4_IM_LOAD_IMMEDIATE	0x2b
+
+/* load constants from a location in memory */
+#define PM4_LOAD_CONSTANT_CONTEXT 0x2e
+
+/* selective invalidation of state pointers */
+#define PM4_INVALIDATE_STATE	0x3b
+
+
+/* dynamically changes shader instruction memory partition */
+#define PM4_SET_SHADER_BASES	0x4A
+
+/* sets the 64-bit BIN_MASK register in the PFP */
+#define PM4_SET_BIN_MASK	0x50
+
+/* sets the 64-bit BIN_SELECT register in the PFP */
+#define PM4_SET_BIN_SELECT	0x51
+
+
+/* updates the current context, if needed */
+#define PM4_CONTEXT_UPDATE	0x5e
+
+/* generate interrupt from the command stream */
+#define PM4_INTERRUPT		0x40
+
+
+/* copy sequencer instruction memory to system memory */
+#define PM4_IM_STORE            0x2c
+
+/* program an offset that will added to the BIN_BASE value of
+ * the 3D_DRAW_INDX_BIN packet */
+#define PM4_SET_BIN_BASE_OFFSET     0x4B
+
+#define PM4_SET_PROTECTED_MODE  0x5f /* sets the register protection mode */
+
+
+/* packet header building macros */
+#define pm4_type0_packet(regindx, cnt) \
+	(PM4_TYPE0_PKT | (((cnt)-1) << 16) | ((regindx) & 0x7FFF))
+
+#define pm4_type0_packet_for_sameregister(regindx, cnt) \
+	((PM4_TYPE0_PKT | (((cnt)-1) << 16) | ((1 << 15) | \
+		((regindx) & 0x7FFF)))
+
+#define pm4_type1_packet(reg0, reg1) \
+	 (PM4_TYPE1_PKT | ((reg1) << 12) | (reg0))
+
+#define pm4_type3_packet(opcode, cnt) \
+	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (((opcode) & 0xFF) << 8))
+
+#define pm4_predicated_type3_packet(opcode, cnt) \
+	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (((opcode) & 0xFF) << 8) | 0x1)
+
+#define pm4_nop_packet(cnt) \
+	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (PM4_NOP << 8))
+
+
+/* packet headers */
+#define PM4_HDR_ME_INIT	pm4_type3_packet(PM4_ME_INIT, 18)
+#define PM4_HDR_INDIRECT_BUFFER_PFD pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)
+#define PM4_HDR_INDIRECT_BUFFER	pm4_type3_packet(PM4_INDIRECT_BUFFER, 2)
+
+#endif	/* __ADRENO_PM4TYPES_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.c
new file mode 100644
index 0000000..6c187c3
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.c
@@ -0,0 +1,869 @@
+/* Copyright (c) 2010-2011, Code Aurora Forum. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301, USA.
+ *
+ */
+
+#include <linux/vmalloc.h>
+
+#include "kgsl.h"
+
+#include "adreno.h"
+#include "adreno_pm4types.h"
+#include "adreno_ringbuffer.h"
+#include "adreno_postmortem.h"
+#include "adreno_debugfs.h"
+
+#include "a200_reg.h"
+
+#define INVALID_RB_CMD 0xaaaaaaaa
+
+struct pm_id_name {
+	uint32_t id;
+	char name[9];
+};
+
+static const struct pm_id_name pm0_types[] = {
+	{REG_PA_SC_AA_CONFIG,		"RPASCAAC"},
+	{REG_RBBM_PM_OVERRIDE2,		"RRBBPMO2"},
+	{REG_SCRATCH_REG2,		"RSCRTRG2"},
+	{REG_SQ_GPR_MANAGEMENT,		"RSQGPRMN"},
+	{REG_SQ_INST_STORE_MANAGMENT,	"RSQINSTS"},
+	{REG_TC_CNTL_STATUS,		"RTCCNTLS"},
+	{REG_TP0_CHICKEN,		"RTP0CHCK"},
+	{REG_CP_TIMESTAMP,		"CP_TM_ST"},
+};
+
+static const struct pm_id_name pm3_types[] = {
+	{PM4_COND_EXEC,			"CND_EXEC"},
+	{PM4_CONTEXT_UPDATE,		"CX__UPDT"},
+	{PM4_DRAW_INDX,			"DRW_NDX_"},
+	{PM4_DRAW_INDX_BIN,		"DRW_NDXB"},
+	{PM4_EVENT_WRITE,		"EVENT_WT"},
+	{PM4_IM_LOAD,			"IN__LOAD"},
+	{PM4_IM_LOAD_IMMEDIATE,		"IM_LOADI"},
+	{PM4_IM_STORE,			"IM_STORE"},
+	{PM4_INDIRECT_BUFFER,		"IND_BUF_"},
+	{PM4_INDIRECT_BUFFER_PFD,	"IND_BUFP"},
+	{PM4_INTERRUPT,			"PM4_INTR"},
+	{PM4_INVALIDATE_STATE,		"INV_STAT"},
+	{PM4_LOAD_CONSTANT_CONTEXT,	"LD_CN_CX"},
+	{PM4_ME_INIT,			"ME__INIT"},
+	{PM4_NOP,			"PM4__NOP"},
+	{PM4_REG_RMW,			"REG__RMW"},
+	{PM4_REG_TO_MEM,		"REG2_MEM"},
+	{PM4_SET_BIN_BASE_OFFSET,	"ST_BIN_O"},
+	{PM4_SET_CONSTANT,		"ST_CONST"},
+	{PM4_SET_PROTECTED_MODE,	"ST_PRT_M"},
+	{PM4_SET_SHADER_BASES,		"ST_SHD_B"},
+	{PM4_WAIT_FOR_IDLE,		"WAIT4IDL"},
+};
+
+/* Offset address pairs: start, end of range to dump (inclusive) */
+
+/* GPU < Z470 */
+
+static const int yamato_registers[] = {
+	0x0000, 0x0008, 0x0010, 0x002c, 0x00ec, 0x00f4,
+	0x0100, 0x0110, 0x0118, 0x011c,
+	0x0700, 0x0704, 0x070c, 0x0720, 0x0754, 0x0764,
+	0x0770, 0x0774, 0x07a8, 0x07a8, 0x07b8, 0x07cc,
+	0x07d8, 0x07dc, 0x07f0, 0x07fc, 0x0e44, 0x0e48,
+	0x0e6c, 0x0e78, 0x0ec8, 0x0ed4, 0x0edc, 0x0edc,
+	0x0fe0, 0x0fec, 0x1100, 0x1100,
+
+	0x110c, 0x1110, 0x112c, 0x112c, 0x1134, 0x113c,
+	0x1148, 0x1148, 0x1150, 0x116c, 0x11fc, 0x11fc,
+	0x15e0, 0x161c, 0x1724, 0x1724, 0x1740, 0x1740,
+	0x1804, 0x1810, 0x1818, 0x1824, 0x182c, 0x1838,
+	0x184c, 0x1850, 0x28a4, 0x28ac, 0x28bc, 0x28c4,
+	0x2900, 0x290c, 0x2914, 0x2914, 0x2938, 0x293c,
+	0x30b0, 0x30b0, 0x30c0, 0x30c0, 0x30e0, 0x30f0,
+	0x3100, 0x3100, 0x3110, 0x3110, 0x3200, 0x3218,
+	0x3220, 0x3250, 0x3264, 0x3268, 0x3290, 0x3294,
+	0x3400, 0x340c, 0x3418, 0x3418, 0x3420, 0x342c,
+	0x34d0, 0x34d4, 0x36b8, 0x3704, 0x3720, 0x3750,
+	0x3760, 0x3764, 0x3800, 0x3800, 0x3808, 0x3810,
+	0x385c, 0x3878, 0x3b00, 0x3b24, 0x3b2c, 0x3b30,
+	0x3b40, 0x3b40, 0x3b50, 0x3b5c, 0x3b80, 0x3b88,
+	0x3c04, 0x3c08, 0x3c30, 0x3c30, 0x3c38, 0x3c48,
+	0x3c98, 0x3ca8, 0x3cb0, 0x3cb0,
+
+	0x8000, 0x8008, 0x8018, 0x803c, 0x8200, 0x8208,
+	0x8400, 0x8424, 0x8430, 0x8450, 0x8600, 0x8610,
+	0x87d4, 0x87dc, 0x8800, 0x8820, 0x8a00, 0x8a0c,
+	0x8a4c, 0x8a50, 0x8c00, 0x8c20, 0x8c48, 0x8c48,
+	0x8c58, 0x8c74, 0x8c90, 0x8c98, 0x8e00, 0x8e0c,
+
+	0x9000, 0x9008, 0x9018, 0x903c, 0x9200, 0x9208,
+	0x9400, 0x9424, 0x9430, 0x9450, 0x9600, 0x9610,
+	0x97d4, 0x97dc, 0x9800, 0x9820, 0x9a00, 0x9a0c,
+	0x9a4c, 0x9a50, 0x9c00, 0x9c20, 0x9c48, 0x9c48,
+	0x9c58, 0x9c74, 0x9c90, 0x9c98, 0x9e00, 0x9e0c,
+
+	0x10000, 0x1000c, 0x12000, 0x12014,
+	0x12400, 0x12400, 0x12420, 0x12420
+};
+
+/* GPU = Z470 */
+
+static const int leia_registers[] = {
+	0x0000, 0x0008, 0x0010, 0x002c, 0x00ec, 0x00f4,
+	0x0100, 0x0110, 0x0118, 0x011c,
+	0x0700, 0x0704, 0x070c, 0x0720, 0x0754, 0x0764,
+	0x0770, 0x0774, 0x07a8, 0x07a8, 0x07b8, 0x07cc,
+	0x07d8, 0x07dc, 0x07f0, 0x07fc, 0x0e44, 0x0e48,
+	0x0e6c, 0x0e78, 0x0ec8, 0x0ed4, 0x0edc, 0x0edc,
+	0x0fe0, 0x0fec, 0x1100, 0x1100,
+
+	0x110c, 0x1110, 0x112c, 0x112c, 0x1134, 0x113c,
+	0x1148, 0x1148, 0x1150, 0x116c, 0x11fc, 0x11fc,
+	0x15e0, 0x161c, 0x1724, 0x1724, 0x1740, 0x1740,
+	0x1804, 0x1810, 0x1818, 0x1824, 0x182c, 0x1838,
+	0x184c, 0x1850, 0x28a4, 0x28ac, 0x28bc, 0x28c4,
+	0x2900, 0x2900, 0x2908, 0x290c, 0x2914, 0x2914,
+	0x2938, 0x293c, 0x30c0, 0x30c0, 0x30e0, 0x30e4,
+	0x30f0, 0x30f0, 0x3200, 0x3204, 0x3220, 0x324c,
+	0x3400, 0x340c, 0x3414, 0x3418, 0x3420, 0x342c,
+	0x34d0, 0x34d4, 0x36b8, 0x3704, 0x3720, 0x3750,
+	0x3760, 0x3764, 0x3800, 0x3800, 0x3808, 0x3810,
+	0x385c, 0x3878, 0x3b00, 0x3b24, 0x3b2c, 0x3b30,
+	0x3b40, 0x3b40, 0x3b50, 0x3b5c, 0x3b80, 0x3b88,
+	0x3c04, 0x3c08, 0x8000, 0x8008, 0x8018, 0x803c,
+	0x8200, 0x8208, 0x8400, 0x8408, 0x8410, 0x8424,
+	0x8430, 0x8450, 0x8600, 0x8610, 0x87d4, 0x87dc,
+	0x8800, 0x8808, 0x8810, 0x8810, 0x8820, 0x8820,
+	0x8a00, 0x8a08, 0x8a50, 0x8a50,
+	0x8c00, 0x8c20, 0x8c24, 0x8c28, 0x8c48, 0x8c48,
+	0x8c58, 0x8c58, 0x8c60, 0x8c74, 0x8c90, 0x8c98,
+	0x8e00, 0x8e0c, 0x9000, 0x9008, 0x9018, 0x903c,
+	0x9200, 0x9208, 0x9400, 0x9408, 0x9410, 0x9424,
+	0x9430, 0x9450, 0x9600, 0x9610, 0x97d4, 0x97dc,
+	0x9800, 0x9808, 0x9810, 0x9818, 0x9820, 0x9820,
+	0x9a00, 0x9a08, 0x9a50, 0x9a50, 0x9c00, 0x9c20,
+	0x9c48, 0x9c48, 0x9c58, 0x9c58, 0x9c60, 0x9c74,
+	0x9c90, 0x9c98, 0x9e00, 0x9e0c,
+
+	0x10000, 0x1000c, 0x12000, 0x12014,
+	0x12400, 0x12400, 0x12420, 0x12420
+};
+
+static struct {
+	int id;
+	const int *registers;
+	int len;
+} kgsl_registers[] = {
+	{ KGSL_CHIPID_LEIA_REV470, leia_registers,
+	  ARRAY_SIZE(leia_registers) / 2 },
+	{ KGSL_CHIPID_LEIA_REV470_TEMP, leia_registers,
+	  ARRAY_SIZE(leia_registers) / 2 },
+	{ KGSL_CHIPID_YAMATODX_REV21, yamato_registers,
+	  ARRAY_SIZE(yamato_registers) / 2 },
+	{ KGSL_CHIPID_YAMATODX_REV211, yamato_registers,
+	  ARRAY_SIZE(yamato_registers) / 2 },
+	{ 0x0, NULL, 0},
+};
+
+static uint32_t kgsl_is_pm4_len(uint32_t word)
+{
+	if (word == INVALID_RB_CMD)
+		return 0;
+
+	return (word >> 16) & 0x3FFF;
+}
+
+static bool kgsl_is_pm4_type(uint32_t word)
+{
+	int i;
+
+	if (word == INVALID_RB_CMD)
+		return 1;
+
+	if (kgsl_is_pm4_len(word) > 16)
+		return 0;
+
+	if ((word & (3<<30)) == PM4_TYPE0_PKT) {
+		for (i = 0; i < ARRAY_SIZE(pm0_types); ++i) {
+			if ((word & 0x7FFF) == pm0_types[i].id)
+				return 1;
+		}
+		return 0;
+	}
+	if ((word & (3<<30)) == PM4_TYPE3_PKT) {
+		for (i = 0; i < ARRAY_SIZE(pm3_types); ++i) {
+			if ((word & 0xFFFF) == (pm3_types[i].id << 8))
+				return 1;
+		}
+		return 0;
+	}
+	return 0;
+}
+
+static const char *kgsl_pm4_name(uint32_t word)
+{
+	int i;
+
+	if (word == INVALID_RB_CMD)
+		return "--------";
+
+	if ((word & (3<<30)) == PM4_TYPE0_PKT) {
+		for (i = 0; i < ARRAY_SIZE(pm0_types); ++i) {
+			if ((word & 0x7FFF) == pm0_types[i].id)
+				return pm0_types[i].name;
+		}
+		return "????????";
+	}
+	if ((word & (3<<30)) == PM4_TYPE3_PKT) {
+		for (i = 0; i < ARRAY_SIZE(pm3_types); ++i) {
+			if ((word & 0xFFFF) == (pm3_types[i].id << 8))
+				return pm3_types[i].name;
+		}
+		return "????????";
+	}
+	return "????????";
+}
+
+static void kgsl_dump_regs(struct kgsl_device *device,
+			   const int *registers, int size)
+{
+	int range = 0, offset = 0;
+
+	for (range = 0; range < size; range++) {
+		/* start and end are in dword offsets */
+		int start = registers[range * 2] / 4;
+		int end = registers[range * 2 + 1] / 4;
+
+		unsigned char linebuf[32 * 3 + 2 + 32 + 1];
+		int linelen, i;
+
+		for (offset = start; offset <= end; offset += linelen) {
+			unsigned int regvals[32/4];
+			linelen = min(end+1-offset, 32/4);
+
+			for (i = 0; i < linelen; ++i)
+				kgsl_regread(device, offset+i, regvals+i);
+
+			hex_dump_to_buffer(regvals, linelen*4, 32, 4,
+				linebuf, sizeof(linebuf), 0);
+			KGSL_LOG_DUMP(device,
+				"REG: %5.5X: %s\n", offset<<2, linebuf);
+		}
+	}
+}
+
+static void dump_ib(struct kgsl_device *device, char* buffId, uint32_t pt_base,
+	uint32_t base_offset, uint32_t ib_base, uint32_t ib_size, bool dump)
+{
+	unsigned int memsize;
+	uint8_t *base_addr = kgsl_sharedmem_convertaddr(device, pt_base,
+		ib_base, &memsize);
+
+	if (base_addr && dump)
+		print_hex_dump(KERN_ERR, buffId, DUMP_PREFIX_OFFSET,
+				 32, 4, base_addr, ib_size*4, 0);
+	else
+		KGSL_LOG_DUMP(device, "%s base:%8.8X  ib_size:%d  "
+			"offset:%5.5X%s\n",
+			buffId, ib_base, ib_size*4, base_offset,
+			base_addr ? "" : " [Invalid]");
+}
+
+#define IB_LIST_SIZE	64
+struct ib_list {
+	int count;
+	uint32_t bases[IB_LIST_SIZE];
+	uint32_t sizes[IB_LIST_SIZE];
+	uint32_t offsets[IB_LIST_SIZE];
+};
+
+static void dump_ib1(struct kgsl_device *device, uint32_t pt_base,
+			uint32_t base_offset,
+			uint32_t ib1_base, uint32_t ib1_size,
+			struct ib_list *ib_list, bool dump)
+{
+	int i, j;
+	uint32_t value;
+	uint32_t *ib1_addr;
+	unsigned int memsize;
+
+	dump_ib(device, "IB1:", pt_base, base_offset, ib1_base,
+		ib1_size, dump);
+
+	/* fetch virtual address for given IB base */
+	ib1_addr = (uint32_t *)kgsl_sharedmem_convertaddr(device, pt_base,
+		ib1_base, &memsize);
+	if (!ib1_addr)
+		return;
+
+	for (i = 0; i+3 < ib1_size; ) {
+		value = ib1_addr[i++];
+		if (value == pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)) {
+			uint32_t ib2_base = ib1_addr[i++];
+			uint32_t ib2_size = ib1_addr[i++];
+
+			/* find previous match */
+			for (j = 0; j < ib_list->count; ++j)
+				if (ib_list->sizes[j] == ib2_size
+					&& ib_list->bases[j] == ib2_base)
+					break;
+
+			if (j < ib_list->count || ib_list->count
+				>= IB_LIST_SIZE)
+				continue;
+
+			/* store match */
+			ib_list->sizes[ib_list->count] = ib2_size;
+			ib_list->bases[ib_list->count] = ib2_base;
+			ib_list->offsets[ib_list->count] = i<<2;
+			++ib_list->count;
+		}
+	}
+}
+
+static void kgsl_dump_rb_buffer(const void *buf, size_t len,
+		char *linebuf, size_t linebuflen, int *argp)
+{
+	const u32 *ptr4 = buf;
+	const int ngroups = len;
+	int lx = 0, j;
+	bool nxsp = 1;
+
+	for (j = 0; j < ngroups; j++) {
+		if (*argp < 0) {
+			lx += scnprintf(linebuf + lx, linebuflen - lx, " <");
+			*argp = -*argp;
+		} else if (nxsp)
+			lx += scnprintf(linebuf + lx, linebuflen - lx, "  ");
+		else
+			nxsp = 1;
+		if (!*argp && kgsl_is_pm4_type(ptr4[j])) {
+			lx += scnprintf(linebuf + lx, linebuflen - lx,
+				"%s", kgsl_pm4_name(ptr4[j]));
+			*argp = -(kgsl_is_pm4_len(ptr4[j])+1);
+		} else {
+			lx += scnprintf(linebuf + lx, linebuflen - lx,
+				"%8.8X", ptr4[j]);
+			if (*argp > 1)
+				--*argp;
+			else if (*argp == 1) {
+				*argp = 0;
+				nxsp = 0;
+				lx += scnprintf(linebuf + lx, linebuflen - lx,
+					"> ");
+			}
+		}
+	}
+	linebuf[lx] = '\0';
+}
+
+static bool kgsl_rb_use_hex(void)
+{
+#ifdef CONFIG_MSM_KGSL_PSTMRTMDMP_RB_HEX
+	return 1;
+#else
+	return 0;
+#endif
+}
+
+static void kgsl_dump_rb(struct kgsl_device *device, const void *buf,
+			 size_t len, int start, int size)
+{
+	const uint32_t *ptr = buf;
+	int i, remaining, args = 0;
+	unsigned char linebuf[32 * 3 + 2 + 32 + 1];
+	const int rowsize = 8;
+
+	len >>= 2;
+	remaining = len;
+	for (i = 0; i < len; i += rowsize) {
+		int linelen = min(remaining, rowsize);
+		remaining -= rowsize;
+
+		if (kgsl_rb_use_hex())
+			hex_dump_to_buffer(ptr+i, linelen*4, rowsize*4, 4,
+				linebuf, sizeof(linebuf), 0);
+		else
+			kgsl_dump_rb_buffer(ptr+i, linelen, linebuf,
+				sizeof(linebuf), &args);
+		KGSL_LOG_DUMP(device,
+			"RB: %4.4X:%s\n", (start+i)%size, linebuf);
+	}
+}
+
+static bool kgsl_ib_dump_enabled(void)
+{
+#ifdef CONFIG_MSM_KGSL_PSTMRTMDMP_NO_IB_DUMP
+	return 0;
+#else
+	return 1;
+#endif
+}
+
+struct log_field {
+	bool show;
+	const char *display;
+};
+
+static int kgsl_dump_fields_line(struct kgsl_device *device,
+				 const char *start, char *str, int slen,
+				 const struct log_field **lines,
+				 int num)
+{
+	const struct log_field *l = *lines;
+	int sptr, count  = 0;
+
+	sptr = snprintf(str, slen, "%s", start);
+
+	for (  ; num && sptr < slen; num--, l++) {
+		int ilen = strlen(l->display);
+
+		if (count)
+			ilen += strlen("  | ");
+
+		if (ilen > (slen - sptr))
+			break;
+
+		if (count++)
+			sptr += snprintf(str + sptr, slen - sptr, " | ");
+
+		sptr += snprintf(str + sptr, slen - sptr, "%s", l->display);
+	}
+
+	KGSL_LOG_DUMP(device, "%s\n", str);
+
+	*lines = l;
+	return num;
+}
+
+static void kgsl_dump_fields(struct kgsl_device *device,
+			     const char *start, const struct log_field *lines,
+			     int num)
+{
+	char lb[90];
+	const char *sstr = start;
+
+	lb[sizeof(lb)  - 1] = '\0';
+
+	while (num) {
+		int ret = kgsl_dump_fields_line(device, sstr, lb,
+			sizeof(lb) - 1, &lines, num);
+
+		if (ret == num)
+			break;
+
+		num = ret;
+		sstr = "        ";
+	}
+}
+
+static int kgsl_dump_yamato(struct kgsl_device *device)
+{
+	unsigned int r1, r2, r3, rbbm_status;
+	unsigned int cp_ib1_base, cp_ib1_bufsz, cp_stat;
+	unsigned int cp_ib2_base, cp_ib2_bufsz;
+	unsigned int pt_base;
+	unsigned int cp_rb_base, rb_count;
+	unsigned int cp_rb_wptr, cp_rb_rptr;
+	unsigned int i;
+	int result = 0;
+	uint32_t *rb_copy;
+	const uint32_t *rb_vaddr;
+	int num_item = 0;
+	int read_idx, write_idx;
+	unsigned int ts_processed, rb_memsize;
+
+	static struct ib_list ib_list;
+
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+
+	struct kgsl_pwrctrl *pwr = &device->pwrctrl;
+
+	mb();
+
+	KGSL_LOG_DUMP(device, "POWER: FLAGS = %08X | ACTIVE POWERLEVEL = %08X",
+			pwr->power_flags, pwr->active_pwrlevel);
+
+	KGSL_LOG_DUMP(device, "POWER: INTERVAL TIMEOUT = %08X ",
+		pwr->interval_timeout);
+
+	KGSL_LOG_DUMP(device, "GRP_CLK = %lu ",
+				  kgsl_get_clkrate(pwr->grp_clks[0]));
+
+	KGSL_LOG_DUMP(device, "BUS CLK = %lu ",
+		kgsl_get_clkrate(pwr->ebi1_clk));
+
+
+	kgsl_regread(device, REG_RBBM_STATUS, &rbbm_status);
+	kgsl_regread(device, REG_RBBM_PM_OVERRIDE1, &r2);
+	kgsl_regread(device, REG_RBBM_PM_OVERRIDE2, &r3);
+	KGSL_LOG_DUMP(device, "RBBM:   STATUS   = %08X | PM_OVERRIDE1 = %08X | "
+		"PM_OVERRIDE2 = %08X\n", rbbm_status, r2, r3);
+
+	kgsl_regread(device, REG_RBBM_INT_CNTL, &r1);
+	kgsl_regread(device, REG_RBBM_INT_STATUS, &r2);
+	kgsl_regread(device, REG_RBBM_READ_ERROR, &r3);
+	KGSL_LOG_DUMP(device, "        INT_CNTL = %08X | INT_STATUS   = %08X | "
+		"READ_ERROR   = %08X\n", r1, r2, r3);
+
+	{
+		char cmdFifo[16];
+		struct log_field lines[] = {
+			{rbbm_status &  0x000F, cmdFifo},
+			{rbbm_status &  BIT(5), "TC busy     "},
+			{rbbm_status &  BIT(8), "HIRQ pending"},
+			{rbbm_status &  BIT(9), "CPRQ pending"},
+			{rbbm_status & BIT(10), "CFRQ pending"},
+			{rbbm_status & BIT(11), "PFRQ pending"},
+			{rbbm_status & BIT(12), "VGT 0DMA bsy"},
+			{rbbm_status & BIT(14), "RBBM WU busy"},
+			{rbbm_status & BIT(16), "CP NRT busy "},
+			{rbbm_status & BIT(18), "MH busy     "},
+			{rbbm_status & BIT(19), "MH chncy bsy"},
+			{rbbm_status & BIT(21), "SX busy     "},
+			{rbbm_status & BIT(22), "TPC busy    "},
+			{rbbm_status & BIT(24), "SC CNTX busy"},
+			{rbbm_status & BIT(25), "PA busy     "},
+			{rbbm_status & BIT(26), "VGT busy    "},
+			{rbbm_status & BIT(27), "SQ cntx1 bsy"},
+			{rbbm_status & BIT(28), "SQ cntx0 bsy"},
+			{rbbm_status & BIT(30), "RB busy     "},
+			{rbbm_status & BIT(31), "Grphs pp bsy"},
+		};
+		snprintf(cmdFifo, sizeof(cmdFifo), "CMD FIFO=%01X  ",
+			rbbm_status & 0xf);
+		kgsl_dump_fields(device, " STATUS=", lines, ARRAY_SIZE(lines));
+	}
+
+	kgsl_regread(device, REG_CP_RB_BASE, &cp_rb_base);
+	kgsl_regread(device, REG_CP_RB_CNTL, &r2);
+	rb_count = 2 << (r2 & (BIT(6)-1));
+	kgsl_regread(device, REG_CP_RB_RPTR_ADDR, &r3);
+	KGSL_LOG_DUMP(device,
+		"CP_RB:  BASE = %08X | CNTL   = %08X | RPTR_ADDR = %08X"
+		"\n", cp_rb_base, r2, r3);
+
+	kgsl_regread(device, REG_CP_RB_RPTR, &cp_rb_rptr);
+	kgsl_regread(device, REG_CP_RB_WPTR, &cp_rb_wptr);
+	kgsl_regread(device, REG_CP_RB_RPTR_WR, &r3);
+	KGSL_LOG_DUMP(device,
+		"        RPTR = %08X | WPTR   = %08X | RPTR_WR   = %08X"
+		"\n", cp_rb_rptr, cp_rb_wptr, r3);
+
+	kgsl_regread(device, REG_CP_IB1_BASE, &cp_ib1_base);
+	kgsl_regread(device, REG_CP_IB1_BUFSZ, &cp_ib1_bufsz);
+	KGSL_LOG_DUMP(device,
+		"CP_IB1: BASE = %08X | BUFSZ  = %d\n", cp_ib1_base,
+		cp_ib1_bufsz);
+
+	kgsl_regread(device, REG_CP_IB2_BASE, &cp_ib2_base);
+	kgsl_regread(device, REG_CP_IB2_BUFSZ, &cp_ib2_bufsz);
+	KGSL_LOG_DUMP(device,
+		"CP_IB2: BASE = %08X | BUFSZ  = %d\n", cp_ib2_base,
+		cp_ib2_bufsz);
+
+	kgsl_regread(device, REG_CP_INT_CNTL, &r1);
+	kgsl_regread(device, REG_CP_INT_STATUS, &r2);
+	KGSL_LOG_DUMP(device, "CP_INT: CNTL = %08X | STATUS = %08X\n", r1, r2);
+
+	kgsl_regread(device, REG_CP_ME_CNTL, &r1);
+	kgsl_regread(device, REG_CP_ME_STATUS, &r2);
+	kgsl_regread(device, REG_MASTER_INT_SIGNAL, &r3);
+	KGSL_LOG_DUMP(device,
+		"CP_ME:  CNTL = %08X | STATUS = %08X | MSTR_INT_SGNL = "
+		"%08X\n", r1, r2, r3);
+
+	kgsl_regread(device, REG_CP_STAT, &cp_stat);
+	KGSL_LOG_DUMP(device, "CP_STAT      = %08X\n", cp_stat);
+#ifndef CONFIG_MSM_KGSL_PSTMRTMDMP_CP_STAT_NO_DETAIL
+	{
+		struct log_field lns[] = {
+			{cp_stat &  BIT(0), "WR_BSY     0"},
+			{cp_stat &  BIT(1), "RD_RQ_BSY  1"},
+			{cp_stat &  BIT(2), "RD_RTN_BSY 2"},
+		};
+		kgsl_dump_fields(device, "    MIU=", lns, ARRAY_SIZE(lns));
+	}
+	{
+		struct log_field lns[] = {
+			{cp_stat &  BIT(5), "RING_BUSY  5"},
+			{cp_stat &  BIT(6), "NDRCTS_BSY 6"},
+			{cp_stat &  BIT(7), "NDRCT2_BSY 7"},
+			{cp_stat &  BIT(9), "ST_BUSY    9"},
+			{cp_stat & BIT(10), "BUSY      10"},
+		};
+		kgsl_dump_fields(device, "    CSF=", lns, ARRAY_SIZE(lns));
+	}
+	{
+		struct log_field lns[] = {
+			{cp_stat & BIT(11), "RNG_Q_BSY 11"},
+			{cp_stat & BIT(12), "NDRCTS_Q_B12"},
+			{cp_stat & BIT(13), "NDRCT2_Q_B13"},
+			{cp_stat & BIT(16), "ST_QUEUE_B16"},
+			{cp_stat & BIT(17), "PFP_BUSY  17"},
+		};
+		kgsl_dump_fields(device, "   RING=", lns, ARRAY_SIZE(lns));
+	}
+	{
+		struct log_field lns[] = {
+			{cp_stat &  BIT(3), "RBIU_BUSY  3"},
+			{cp_stat &  BIT(4), "RCIU_BUSY  4"},
+			{cp_stat & BIT(18), "MQ_RG_BSY 18"},
+			{cp_stat & BIT(19), "MQ_NDRS_BS19"},
+			{cp_stat & BIT(20), "MQ_NDR2_BS20"},
+			{cp_stat & BIT(21), "MIU_WC_STL21"},
+			{cp_stat & BIT(22), "CP_NRT_BSY22"},
+			{cp_stat & BIT(23), "3D_BUSY   23"},
+			{cp_stat & BIT(26), "ME_BUSY   26"},
+			{cp_stat & BIT(29), "ME_WC_BSY 29"},
+			{cp_stat & BIT(30), "MIU_FF EM 30"},
+			{cp_stat & BIT(31), "CP_BUSY   31"},
+		};
+		kgsl_dump_fields(device, " CP_STT=", lns, ARRAY_SIZE(lns));
+	}
+#endif
+
+	kgsl_regread(device, REG_SCRATCH_REG0, &r1);
+	KGSL_LOG_DUMP(device, "SCRATCH_REG0       = %08X\n", r1);
+
+	kgsl_regread(device, REG_COHER_SIZE_PM4, &r1);
+	kgsl_regread(device, REG_COHER_BASE_PM4, &r2);
+	kgsl_regread(device, REG_COHER_STATUS_PM4, &r3);
+	KGSL_LOG_DUMP(device,
+		"COHER:  SIZE_PM4   = %08X | BASE_PM4 = %08X | STATUS_PM4"
+		" = %08X\n", r1, r2, r3);
+
+	kgsl_regread(device, REG_MH_AXI_ERROR, &r1);
+	KGSL_LOG_DUMP(device, "MH:     AXI_ERROR  = %08X\n", r1);
+
+	kgsl_regread(device, REG_MH_MMU_PAGE_FAULT, &r1);
+	kgsl_regread(device, REG_MH_MMU_CONFIG, &r2);
+	kgsl_regread(device, REG_MH_MMU_MPU_BASE, &r3);
+	KGSL_LOG_DUMP(device,
+		"MH_MMU: PAGE_FAULT = %08X | CONFIG   = %08X | MPU_BASE ="
+		" %08X\n", r1, r2, r3);
+
+	kgsl_regread(device, REG_MH_MMU_MPU_END, &r1);
+	kgsl_regread(device, REG_MH_MMU_VA_RANGE, &r2);
+	kgsl_regread(device, REG_MH_MMU_PT_BASE, &pt_base);
+	KGSL_LOG_DUMP(device,
+		"        MPU_END    = %08X | VA_RANGE = %08X | PT_BASE  ="
+		" %08X\n", r1, r2, pt_base);
+
+	KGSL_LOG_DUMP(device, "PAGETABLE SIZE: %08X ", KGSL_PAGETABLE_SIZE);
+
+	kgsl_regread(device, REG_MH_MMU_TRAN_ERROR, &r1);
+	KGSL_LOG_DUMP(device, "        TRAN_ERROR = %08X\n", r1);
+
+	kgsl_regread(device, REG_MH_INTERRUPT_MASK, &r1);
+	kgsl_regread(device, REG_MH_INTERRUPT_STATUS, &r2);
+	KGSL_LOG_DUMP(device,
+		"MH_INTERRUPT: MASK = %08X | STATUS   = %08X\n", r1, r2);
+
+	if (device->ftbl.device_readtimestamp != NULL) {
+		ts_processed = device->ftbl.device_readtimestamp(
+				device, KGSL_TIMESTAMP_RETIRED);
+		KGSL_LOG_DUMP(device, "TIMESTM RTRD: %08X\n", ts_processed);
+	}
+
+	num_item = kgsl_ringbuffer_count(&yamato_device->ringbuffer,
+						cp_rb_rptr);
+	if (num_item <= 0)
+		KGSL_LOG_POSTMORTEM_WRITE(device, "Ringbuffer is Empty.\n");
+
+	rb_copy = vmalloc(rb_count<<2);
+	if (!rb_copy) {
+		KGSL_LOG_POSTMORTEM_WRITE(device,
+			"vmalloc(%d) failed\n", rb_count << 2);
+		result = -ENOMEM;
+		goto end;
+	}
+
+	KGSL_LOG_DUMP(device, "RB: rd_addr:%8.8x  rb_size:%d  num_item:%d\n",
+		cp_rb_base, rb_count<<2, num_item);
+	rb_vaddr = (const uint32_t *)kgsl_sharedmem_convertaddr(device, pt_base,
+					cp_rb_base, &rb_memsize);
+	if (!rb_vaddr) {
+		KGSL_LOG_POSTMORTEM_WRITE(device,
+			"Can't fetch vaddr for CP_RB_BASE\n");
+		goto error_vfree;
+	}
+
+	read_idx = (int)cp_rb_rptr - 64;
+	if (read_idx < 0)
+		read_idx += rb_count;
+	write_idx = (int)cp_rb_wptr + 16;
+	if (write_idx > rb_count)
+		write_idx -= rb_count;
+	num_item += 64+16;
+	if (num_item > rb_count)
+		num_item = rb_count;
+	if (write_idx >= read_idx)
+		memcpy(rb_copy, rb_vaddr+read_idx, num_item<<2);
+	else {
+		int part1_c = rb_count-read_idx;
+		memcpy(rb_copy, rb_vaddr+read_idx, part1_c<<2);
+		memcpy(rb_copy+part1_c, rb_vaddr, (num_item-part1_c)<<2);
+	}
+
+	/* extract the latest ib commands from the buffer */
+	ib_list.count = 0;
+	i = 0;
+	for (read_idx = 0; read_idx < num_item; ) {
+		uint32_t this_cmd = rb_copy[read_idx++];
+		if (this_cmd == pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)) {
+			uint32_t ib_addr = rb_copy[read_idx++];
+			uint32_t ib_size = rb_copy[read_idx++];
+			dump_ib1(device, pt_base, (read_idx-3)<<2, ib_addr,
+				ib_size, &ib_list, 0);
+			for (; i < ib_list.count; ++i)
+				dump_ib(device, "IB2:", pt_base,
+					ib_list.offsets[i],
+					ib_list.bases[i],
+					ib_list.sizes[i], 0);
+		}
+	}
+
+	read_idx = (int)cp_rb_rptr - 64;
+	if (read_idx < 0)
+		read_idx += rb_count;
+	KGSL_LOG_DUMP(device,
+		"RB: addr=%8.8x  window:%4.4x-%4.4x, start:%4.4x\n",
+		cp_rb_base, cp_rb_rptr, cp_rb_wptr, read_idx);
+	kgsl_dump_rb(device, rb_copy, num_item<<2, read_idx, rb_count);
+
+	if (kgsl_ib_dump_enabled()) {
+		for (read_idx = 64; read_idx >= 0; --read_idx) {
+			uint32_t this_cmd = rb_copy[read_idx];
+			if (this_cmd == pm4_type3_packet(
+				PM4_INDIRECT_BUFFER_PFD, 2)) {
+				uint32_t ib_addr = rb_copy[read_idx+1];
+				uint32_t ib_size = rb_copy[read_idx+2];
+				if (cp_ib1_bufsz && cp_ib1_base == ib_addr) {
+					KGSL_LOG_DUMP(device,
+						"IB1: base:%8.8X  "
+						"count:%d\n", ib_addr, ib_size);
+					dump_ib(device, "IB1: ", pt_base,
+						read_idx<<2, ib_addr, ib_size,
+						1);
+				}
+			}
+		}
+		for (i = 0; i < ib_list.count; ++i) {
+			if (cp_ib2_bufsz && cp_ib2_base == ib_list.bases[i]) {
+				uint32_t ib_size = ib_list.sizes[i];
+				uint32_t ib_offset = ib_list.offsets[i];
+				KGSL_LOG_DUMP(device,
+					"IB2: base:%8.8X  count:%d\n",
+					cp_ib2_base, ib_size);
+				dump_ib(device, "IB2: ", pt_base, ib_offset,
+					ib_list.bases[i], ib_size, 1);
+			}
+		}
+	}
+
+	/* Dump the registers if the user asked for it */
+
+	for (i = 0; kgsl_pmregs_enabled() && kgsl_registers[i].id; i++) {
+		if (kgsl_registers[i].id == device->chip_id) {
+			kgsl_dump_regs(device, kgsl_registers[i].registers,
+				       kgsl_registers[i].len);
+			break;
+		}
+	}
+
+error_vfree:
+	vfree(rb_copy);
+end:
+	return result;
+}
+
+/**
+ * kgsl_postmortem_dump - Dump the current GPU state
+ * @device - A pointer to the KGSL device to dump
+ * @manual - A flag that indicates if this was a manually triggered
+ *           dump (from debugfs).  If zero, then this is assumed to be a
+ *           dump automaticlaly triggered from a hang
+*/
+
+int kgsl_postmortem_dump(struct kgsl_device *device, int manual)
+{
+	bool saved_nap;
+
+	BUG_ON(device == NULL);
+
+	/* For a manual dump, make sure that the system is idle */
+
+	if (manual) {
+		if (device->active_cnt != 0) {
+			mutex_unlock(&device->mutex);
+			wait_for_completion(&device->suspend_gate);
+			mutex_lock(&device->mutex);
+		}
+
+		if (device->state == KGSL_STATE_ACTIVE)
+			kgsl_idle(device,  KGSL_TIMEOUT_DEFAULT);
+
+	}
+	/* Disable the idle timer so we don't get interrupted */
+	del_timer(&device->idle_timer);
+
+	/* Turn off napping to make sure we have the clocks full
+	   attention through the following process */
+	saved_nap = device->pwrctrl.nap_allowed;
+	device->pwrctrl.nap_allowed = false;
+
+	/* Force on the clocks */
+	kgsl_pwrctrl_wake(device);
+
+	/* Disable the irq */
+	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
+
+	/* If this is not a manual trigger, then set up the
+	   state to try to recover */
+
+	if (!manual) {
+		device->state = KGSL_STATE_DUMP_AND_RECOVER;
+		KGSL_PWR_WARN(device,
+				"state -> DUMP_AND_RECOVER, device %d\n",
+				device->id);
+	}
+
+	KGSL_DRV_ERR(device,
+			"wait for work in workqueue to complete\n");
+	mutex_unlock(&device->mutex);
+	flush_workqueue(device->work_queue);
+	mutex_lock(&device->mutex);
+	kgsl_dump_yamato(device);
+
+	/* Restore nap mode */
+	device->pwrctrl.nap_allowed = saved_nap;
+
+	/* On a manual trigger, turn on the interrupts and put
+	   the clocks to sleep.  They will recover themselves
+	   on the next event.  For a hang, leave things as they
+	   are until recovery kicks in. */
+
+	if (manual) {
+		kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_ON);
+
+		/* try to go into a sleep mode until the next event */
+		device->requested_state = KGSL_STATE_SLEEP;
+		kgsl_pwrctrl_sleep(device);
+	}
+
+	KGSL_DRV_ERR(device, "Dump Finished\n");
+
+	return 0;
+}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.h
new file mode 100644
index 0000000..1727405
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_postmortem.h
@@ -0,0 +1,37 @@
+/* Copyright (c) 2010-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#ifndef __ADRENO_POSTMORTEM_H
+#define __ADRENO_POSTMORTEM_H
+
+struct kgsl_device;
+
+int kgsl_postmortem_dump(struct kgsl_device *device, int manual);
+
+#endif /* __ADRENO_POSTMORTEM_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.c
new file mode 100644
index 0000000..9849e3e
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.c
@@ -0,0 +1,938 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301, USA.
+ *
+ */
+#include <linux/firmware.h>
+#include <linux/slab.h>
+
+#include "kgsl.h"
+#include "adreno.h"
+#include "adreno_pm4types.h"
+#include "adreno_ringbuffer.h"
+
+#include "a200_reg.h"
+
+#define VALID_STATUS_COUNT_MAX	10
+#define GSL_RB_NOP_SIZEDWORDS				2
+/* protected mode error checking below register address 0x800
+*  note: if CP_INTERRUPT packet is used then checking needs
+*  to change to below register address 0x7C8
+*/
+#define GSL_RB_PROTECTED_MODE_CONTROL		0x200001F2
+
+#define GSL_CP_INT_MASK \
+	(CP_INT_CNTL__SW_INT_MASK | \
+	CP_INT_CNTL__T0_PACKET_IN_IB_MASK | \
+	CP_INT_CNTL__OPCODE_ERROR_MASK | \
+	CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK | \
+	CP_INT_CNTL__RESERVED_BIT_ERROR_MASK | \
+	CP_INT_CNTL__IB_ERROR_MASK | \
+	CP_INT_CNTL__IB2_INT_MASK | \
+	CP_INT_CNTL__IB1_INT_MASK | \
+	CP_INT_CNTL__RB_INT_MASK)
+
+#define YAMATO_PFP_FW "yamato_pfp.fw"
+#define YAMATO_PM4_FW "yamato_pm4.fw"
+#define LEIA_PFP_470_FW "leia_pfp_470.fw"
+#define LEIA_PM4_470_FW "leia_pm4_470.fw"
+
+/*  ringbuffer size log2 quadwords equivalent */
+inline unsigned int kgsl_ringbuffer_sizelog2quadwords(unsigned int sizedwords)
+{
+	unsigned int sizelog2quadwords = 0;
+	int i = sizedwords >> 1;
+
+	while (i >>= 1)
+		sizelog2quadwords++;
+
+	return sizelog2quadwords;
+}
+
+
+/* functions */
+void kgsl_cp_intrcallback(struct kgsl_device *device)
+{
+	unsigned int status = 0, num_reads = 0, master_status = 0;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+
+	kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL, &master_status);
+	while (!status && (num_reads < VALID_STATUS_COUNT_MAX) &&
+		(master_status & MASTER_INT_SIGNAL__CP_INT_STAT)) {
+		kgsl_yamato_regread_isr(device, REG_CP_INT_STATUS, &status);
+		kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL,
+					&master_status);
+		num_reads++;
+	}
+	if (num_reads > 1)
+		KGSL_DRV_WARN(device,
+			"Looped %d times to read REG_CP_INT_STATUS\n",
+			num_reads);
+	if (!status) {
+		if (master_status & MASTER_INT_SIGNAL__CP_INT_STAT) {
+			/* This indicates that we could not read CP_INT_STAT.
+			 * As a precaution just wake up processes so
+			 * they can check their timestamps. Since, we
+			 * did not ack any interrupts this interrupt will
+			 * be generated again */
+			KGSL_DRV_WARN(device, "Unable to read CP_INT_STATUS\n");
+			wake_up_interruptible_all(&device->wait_queue);
+		} else
+			KGSL_DRV_WARN(device, "Spurious interrput detected\n");
+		return;
+	}
+
+	if (status & CP_INT_CNTL__RB_INT_MASK) {
+		/* signal intr completion event */
+		unsigned int enableflag = 0;
+		kgsl_sharedmem_writel(&rb->device->memstore,
+			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
+			enableflag);
+		wmb();
+		KGSL_CMD_WARN(rb->device, "ringbuffer rb interrupt\n");
+	}
+
+	if (status & CP_INT_CNTL__T0_PACKET_IN_IB_MASK) {
+		KGSL_CMD_CRIT(rb->device,
+			"ringbuffer TO packet in IB interrupt\n");
+		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
+	}
+	if (status & CP_INT_CNTL__OPCODE_ERROR_MASK) {
+		KGSL_CMD_CRIT(rb->device,
+			"ringbuffer opcode error interrupt\n");
+		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
+	}
+	if (status & CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK) {
+		KGSL_CMD_CRIT(rb->device,
+			"ringbuffer protected mode error interrupt\n");
+		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
+	}
+	if (status & CP_INT_CNTL__RESERVED_BIT_ERROR_MASK) {
+		KGSL_CMD_CRIT(rb->device,
+			"ringbuffer reserved bit error interrupt\n");
+		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
+	}
+	if (status & CP_INT_CNTL__IB_ERROR_MASK) {
+		KGSL_CMD_CRIT(rb->device,
+			"ringbuffer IB error interrupt\n");
+		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
+	}
+	if (status & CP_INT_CNTL__SW_INT_MASK)
+		KGSL_CMD_INFO(rb->device, "ringbuffer software interrupt\n");
+
+	if (status & CP_INT_CNTL__IB2_INT_MASK)
+		KGSL_CMD_INFO(rb->device, "ringbuffer ib2 interrupt\n");
+
+	if (status & (~GSL_CP_INT_MASK))
+		KGSL_CMD_WARN(rb->device,
+			"bad bits in REG_CP_INT_STATUS %08x\n", status);
+
+	/* only ack bits we understand */
+	status &= GSL_CP_INT_MASK;
+	kgsl_yamato_regwrite_isr(device, REG_CP_INT_ACK, status);
+
+	if (status & (CP_INT_CNTL__IB1_INT_MASK | CP_INT_CNTL__RB_INT_MASK)) {
+		KGSL_CMD_WARN(rb->device, "ringbuffer ib1/rb interrupt\n");
+		wake_up_interruptible_all(&device->wait_queue);
+		atomic_notifier_call_chain(&(device->ts_notifier_list),
+					   device->id,
+					   NULL);
+	}
+}
+
+static void kgsl_ringbuffer_submit(struct kgsl_ringbuffer *rb)
+{
+	BUG_ON(rb->wptr == 0);
+
+	GSL_RB_UPDATE_WPTR_POLLING(rb);
+	/* Drain write buffer and data memory barrier */
+	dsb();
+	wmb();
+
+	/* Memory fence to ensure all data has posted.  On some systems,
+	* like 7x27, the register block is not allocated as strongly ordered
+	* memory.  Adding a memory fence ensures ordering during ringbuffer
+	* submits.*/
+	mb();
+	outer_sync();
+
+	kgsl_yamato_regwrite(rb->device, REG_CP_RB_WPTR, rb->wptr);
+
+	rb->flags |= KGSL_FLAGS_ACTIVE;
+}
+
+static int
+kgsl_ringbuffer_waitspace(struct kgsl_ringbuffer *rb, unsigned int numcmds,
+			  int wptr_ahead)
+{
+	int nopcount;
+	unsigned int freecmds;
+	unsigned int *cmds;
+	uint cmds_gpu;
+
+	/* if wptr ahead, fill the remaining with NOPs */
+	if (wptr_ahead) {
+		/* -1 for header */
+		nopcount = rb->sizedwords - rb->wptr - 1;
+
+		cmds = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
+		cmds_gpu = rb->buffer_desc.gpuaddr + sizeof(uint)*rb->wptr;
+
+		GSL_RB_WRITE(cmds, cmds_gpu, pm4_nop_packet(nopcount));
+
+		/* Make sure that rptr is not 0 before submitting
+		 * commands at the end of ringbuffer. We do not
+		 * want the rptr and wptr to become equal when
+		 * the ringbuffer is not empty */
+		do {
+			GSL_RB_GET_READPTR(rb, &rb->rptr);
+		} while (!rb->rptr);
+
+		rb->wptr++;
+
+		kgsl_ringbuffer_submit(rb);
+
+		rb->wptr = 0;
+	}
+
+	/* wait for space in ringbuffer */
+	do {
+		GSL_RB_GET_READPTR(rb, &rb->rptr);
+
+		freecmds = rb->rptr - rb->wptr;
+
+	} while ((freecmds != 0) && (freecmds <= numcmds));
+
+	return 0;
+}
+
+
+static unsigned int *kgsl_ringbuffer_allocspace(struct kgsl_ringbuffer *rb,
+					     unsigned int numcmds)
+{
+	unsigned int	*ptr = NULL;
+	int				status = 0;
+
+	BUG_ON(numcmds >= rb->sizedwords);
+
+	GSL_RB_GET_READPTR(rb, &rb->rptr);
+	/* check for available space */
+	if (rb->wptr >= rb->rptr) {
+		/* wptr ahead or equal to rptr */
+		/* reserve dwords for nop packet */
+		if ((rb->wptr + numcmds) > (rb->sizedwords -
+				GSL_RB_NOP_SIZEDWORDS))
+			status = kgsl_ringbuffer_waitspace(rb, numcmds, 1);
+	} else {
+		/* wptr behind rptr */
+		if ((rb->wptr + numcmds) >= rb->rptr)
+			status  = kgsl_ringbuffer_waitspace(rb, numcmds, 0);
+		/* check for remaining space */
+		/* reserve dwords for nop packet */
+		if ((rb->wptr + numcmds) > (rb->sizedwords -
+				GSL_RB_NOP_SIZEDWORDS))
+			status = kgsl_ringbuffer_waitspace(rb, numcmds, 1);
+	}
+
+	if (status == 0) {
+		ptr = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
+		rb->wptr += numcmds;
+	}
+
+	return ptr;
+}
+
+static int _load_firmware(struct kgsl_device *device, const char *fwfile,
+			  void **data, int *len)
+{
+	const struct firmware *fw = NULL;
+	int ret;
+
+	ret = request_firmware(&fw, fwfile, device->dev);
+
+	if (ret) {
+		KGSL_DRV_ERR(device, "request_firmware(%s) failed: %d\n",
+			     fwfile, ret);
+		return ret;
+	}
+
+	*data = kmalloc(fw->size, GFP_KERNEL);
+
+	if (*data) {
+		memcpy(*data, fw->data, fw->size);
+		*len = fw->size;
+	} else
+		KGSL_MEM_ERR(device, "kmalloc(%d) failed\n", fw->size);
+
+	release_firmware(fw);
+	return (*data != NULL) ? 0 : -ENOMEM;
+}
+
+static int kgsl_ringbuffer_load_pm4_ucode(struct kgsl_device *device)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	const char *fwfile;
+	int i, ret = 0;
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		fwfile =  LEIA_PM4_470_FW;
+	else
+		fwfile =  YAMATO_PM4_FW;
+
+	if (yamato_device->pm4_fw == NULL) {
+		int len;
+		unsigned int *ptr;
+
+		ret = _load_firmware(device, fwfile, (void *) &ptr, &len);
+		if (ret)
+			goto err;
+
+		/* PM4 size is 3 dword aligned plus 1 dword of version */
+		if (len % ((sizeof(uint32_t) * 3)) != sizeof(uint32_t)) {
+			KGSL_DRV_ERR(device, "Bad firmware size: %d\n", len);
+			ret = -EINVAL;
+			goto err;
+		}
+
+		yamato_device->pm4_fw_size = len / sizeof(uint32_t);
+		yamato_device->pm4_fw = ptr;
+	}
+
+	KGSL_DRV_INFO(device, "loading pm4 ucode version: %d\n",
+		yamato_device->pm4_fw[0]);
+
+	kgsl_yamato_regwrite(device, REG_CP_DEBUG, 0x02000000);
+	kgsl_yamato_regwrite(device, REG_CP_ME_RAM_WADDR, 0);
+	for (i = 1; i < yamato_device->pm4_fw_size; i++)
+		kgsl_yamato_regwrite(device, REG_CP_ME_RAM_DATA,
+				     yamato_device->pm4_fw[i]);
+err:
+	return ret;
+}
+
+static int kgsl_ringbuffer_load_pfp_ucode(struct kgsl_device *device)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	const char *fwfile;
+	int i, ret = 0;
+
+	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
+		fwfile =  LEIA_PFP_470_FW;
+	else
+		fwfile = YAMATO_PFP_FW;
+
+	if (yamato_device->pfp_fw == NULL) {
+		int len;
+		unsigned int *ptr;
+
+		ret = _load_firmware(device, fwfile, (void *) &ptr, &len);
+		if (ret)
+			goto err;
+
+		/* PFP size shold be dword aligned */
+		if (len % sizeof(uint32_t) != 0) {
+			KGSL_DRV_ERR(device, "Bad firmware size: %d\n", len);
+			ret = -EINVAL;
+			goto err;
+		}
+
+		yamato_device->pfp_fw_size = len / sizeof(uint32_t);
+		yamato_device->pfp_fw = ptr;
+	}
+
+	KGSL_DRV_INFO(device, "loading pfp ucode version: %d\n",
+		yamato_device->pfp_fw[0]);
+
+	kgsl_yamato_regwrite(device, REG_CP_PFP_UCODE_ADDR, 0);
+	for (i = 1; i < yamato_device->pfp_fw_size; i++)
+		kgsl_yamato_regwrite(device, REG_CP_PFP_UCODE_DATA,
+				     yamato_device->pfp_fw[i]);
+err:
+	return ret;
+}
+
+int kgsl_ringbuffer_start(struct kgsl_ringbuffer *rb, unsigned int init_ram)
+{
+	int status;
+	/*cp_rb_cntl_u cp_rb_cntl; */
+	union reg_cp_rb_cntl cp_rb_cntl;
+	unsigned int *cmds, rb_cntl;
+	struct kgsl_device *device = rb->device;
+	uint cmds_gpu;
+
+	if (rb->flags & KGSL_FLAGS_STARTED)
+		return 0;
+
+	if (init_ram) {
+		rb->timestamp = 0;
+		GSL_RB_INIT_TIMESTAMP(rb);
+	}
+
+	kgsl_sharedmem_set(&rb->memptrs_desc, 0, 0,
+			   sizeof(struct kgsl_rbmemptrs));
+
+	kgsl_sharedmem_set(&rb->buffer_desc, 0, 0xAA,
+			   (rb->sizedwords << 2));
+
+	kgsl_yamato_regwrite(device, REG_CP_RB_WPTR_BASE,
+			     (rb->memptrs_desc.gpuaddr
+			      + GSL_RB_MEMPTRS_WPTRPOLL_OFFSET));
+
+	/* setup WPTR delay */
+	kgsl_yamato_regwrite(device, REG_CP_RB_WPTR_DELAY, 0 /*0x70000010 */);
+
+	/*setup REG_CP_RB_CNTL */
+	kgsl_yamato_regread(device, REG_CP_RB_CNTL, &rb_cntl);
+	cp_rb_cntl.val = rb_cntl;
+	/* size of ringbuffer */
+	cp_rb_cntl.f.rb_bufsz =
+		kgsl_ringbuffer_sizelog2quadwords(rb->sizedwords);
+	/* quadwords to read before updating mem RPTR */
+	cp_rb_cntl.f.rb_blksz = rb->blksizequadwords;
+	cp_rb_cntl.f.rb_poll_en = GSL_RB_CNTL_POLL_EN; /* WPTR polling */
+	/* mem RPTR writebacks */
+	cp_rb_cntl.f.rb_no_update =  GSL_RB_CNTL_NO_UPDATE;
+
+	kgsl_yamato_regwrite(device, REG_CP_RB_CNTL, cp_rb_cntl.val);
+
+	kgsl_yamato_regwrite(device, REG_CP_RB_BASE, rb->buffer_desc.gpuaddr);
+
+	kgsl_yamato_regwrite(device, REG_CP_RB_RPTR_ADDR,
+			     rb->memptrs_desc.gpuaddr +
+			     GSL_RB_MEMPTRS_RPTR_OFFSET);
+
+	/* explicitly clear all cp interrupts */
+	kgsl_yamato_regwrite(device, REG_CP_INT_ACK, 0xFFFFFFFF);
+
+	/* setup scratch/timestamp */
+	kgsl_yamato_regwrite(device, REG_SCRATCH_ADDR,
+			     device->memstore.gpuaddr +
+			     KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp));
+
+	kgsl_yamato_regwrite(device, REG_SCRATCH_UMSK,
+			     GSL_RB_MEMPTRS_SCRATCH_MASK);
+
+	/* load the CP ucode */
+
+	status = kgsl_ringbuffer_load_pm4_ucode(device);
+	if (status != 0)
+		return status;
+
+	/* load the prefetch parser ucode */
+	status = kgsl_ringbuffer_load_pfp_ucode(device);
+	if (status != 0)
+		return status;
+
+	kgsl_yamato_regwrite(device, REG_CP_QUEUE_THRESHOLDS, 0x000C0804);
+
+	rb->rptr = 0;
+	rb->wptr = 0;
+
+	/* clear ME_HALT to start micro engine */
+	kgsl_yamato_regwrite(device, REG_CP_ME_CNTL, 0);
+
+	/* ME_INIT */
+	cmds = kgsl_ringbuffer_allocspace(rb, 19);
+	cmds_gpu = rb->buffer_desc.gpuaddr + sizeof(uint)*(rb->wptr-19);
+
+	GSL_RB_WRITE(cmds, cmds_gpu, PM4_HDR_ME_INIT);
+	/* All fields present (bits 9:0) */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x000003ff);
+	/* Disable/Enable Real-Time Stream processing (present but ignored) */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+	/* Enable (2D <-> 3D) implicit synchronization (present but ignored) */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_RB_SURFACE_INFO));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SC_WINDOW_OFFSET));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_VGT_MAX_VTX_INDX));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_SQ_PROGRAM_CNTL));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_RB_DEPTHCONTROL));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SU_POINT_SIZE));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SC_LINE_CNTL));
+	GSL_RB_WRITE(cmds, cmds_gpu,
+		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SU_POLY_OFFSET_FRONT_SCALE));
+
+	/* Vertex and Pixel Shader Start Addresses in instructions
+	* (3 DWORDS per instruction) */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x80000180);
+	/* Maximum Contexts */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000001);
+	/* Write Confirm Interval and The CP will wait the
+	* wait_interval * 16 clocks between polling  */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+
+	/* NQ and External Memory Swap */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+	/* Protected mode error checking */
+	GSL_RB_WRITE(cmds, cmds_gpu, GSL_RB_PROTECTED_MODE_CONTROL);
+	/* Disable header dumping and Header dump address */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+	/* Header dump size */
+	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
+
+	kgsl_ringbuffer_submit(rb);
+
+	/* idle device to validate ME INIT */
+	status = kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+
+	kgsl_yamato_regwrite(rb->device, REG_CP_INT_CNTL, GSL_CP_INT_MASK);
+	if (status == 0)
+		rb->flags |= KGSL_FLAGS_STARTED;
+
+	return status;
+}
+
+int kgsl_ringbuffer_stop(struct kgsl_ringbuffer *rb)
+{
+	if (rb->flags & KGSL_FLAGS_STARTED) {
+		kgsl_yamato_regwrite(rb->device, REG_CP_INT_CNTL, 0);
+
+		/* ME_HALT */
+		kgsl_yamato_regwrite(rb->device, REG_CP_ME_CNTL, 0x10000000);
+
+		rb->flags &= ~KGSL_FLAGS_STARTED;
+	}
+
+	return 0;
+}
+
+int kgsl_ringbuffer_init(struct kgsl_device *device)
+{
+	int status;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+
+	rb->device = device;
+	rb->sizedwords = (2 << kgsl_cfg_rb_sizelog2quadwords);
+	rb->blksizequadwords = kgsl_cfg_rb_blksizequadwords;
+
+	/* allocate memory for ringbuffer */
+	status = kgsl_allocate_contig(&rb->buffer_desc, (rb->sizedwords << 2));
+	if (status != 0) {
+		kgsl_ringbuffer_close(rb);
+		return status;
+	}
+
+	/* allocate memory for polling and timestamps */
+	/* This really can be at 4 byte alignment boundry but for using MMU
+	 * we need to make it at page boundary */
+	status = kgsl_allocate_contig(&rb->memptrs_desc,
+	       sizeof(struct kgsl_rbmemptrs));
+	if (status != 0) {
+		kgsl_ringbuffer_close(rb);
+		return status;
+	}
+
+	/* overlay structure on memptrs memory */
+	rb->memptrs = (struct kgsl_rbmemptrs *) rb->memptrs_desc.hostptr;
+
+	return 0;
+}
+
+int kgsl_ringbuffer_close(struct kgsl_ringbuffer *rb)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(
+							rb->device);
+	if (rb->buffer_desc.hostptr)
+		kgsl_sharedmem_free(&rb->buffer_desc);
+
+	if (rb->memptrs_desc.hostptr)
+		kgsl_sharedmem_free(&rb->memptrs_desc);
+
+	if (yamato_device->pfp_fw != NULL)
+		kfree(yamato_device->pfp_fw);
+	if (yamato_device->pm4_fw != NULL)
+		kfree(yamato_device->pm4_fw);
+	yamato_device->pfp_fw = NULL;
+	yamato_device->pm4_fw = NULL;
+
+	memset(rb, 0, sizeof(struct kgsl_ringbuffer));
+
+	return 0;
+}
+
+static uint32_t
+kgsl_ringbuffer_addcmds(struct kgsl_ringbuffer *rb,
+				unsigned int flags, unsigned int *cmds,
+				int sizedwords)
+{
+	unsigned int *ringcmds;
+	unsigned int timestamp;
+	unsigned int total_sizedwords = sizedwords + 6;
+	unsigned int i;
+	unsigned int rcmd_gpu;
+
+	/* reserve space to temporarily turn off protected mode
+	*  error checking if needed
+	*/
+	total_sizedwords += flags & KGSL_CMD_FLAGS_PMODE ? 4 : 0;
+	total_sizedwords += !(flags & KGSL_CMD_FLAGS_NO_TS_CMP) ? 7 : 0;
+	total_sizedwords += !(flags & KGSL_CMD_FLAGS_NOT_KERNEL_CMD) ? 2 : 0;
+
+	ringcmds = kgsl_ringbuffer_allocspace(rb, total_sizedwords);
+	rcmd_gpu = rb->buffer_desc.gpuaddr
+		+ sizeof(uint)*(rb->wptr-total_sizedwords);
+
+	if (!(flags & KGSL_CMD_FLAGS_NOT_KERNEL_CMD)) {
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_nop_packet(1));
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, KGSL_CMD_IDENTIFIER);
+	}
+	if (flags & KGSL_CMD_FLAGS_PMODE) {
+		/* disable protected mode error checking */
+		GSL_RB_WRITE(ringcmds, rcmd_gpu,
+			pm4_type3_packet(PM4_SET_PROTECTED_MODE, 1));
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, 0);
+	}
+
+	for (i = 0; i < sizedwords; i++) {
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, *cmds);
+		cmds++;
+	}
+
+	if (flags & KGSL_CMD_FLAGS_PMODE) {
+		/* re-enable protected mode error checking */
+		GSL_RB_WRITE(ringcmds, rcmd_gpu,
+			pm4_type3_packet(PM4_SET_PROTECTED_MODE, 1));
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, 1);
+	}
+
+	rb->timestamp++;
+	timestamp = rb->timestamp;
+
+	/* start-of-pipeline and end-of-pipeline timestamps */
+	GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_type0_packet(REG_CP_TIMESTAMP, 1));
+	GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
+	GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_type3_packet(PM4_EVENT_WRITE, 3));
+	GSL_RB_WRITE(ringcmds, rcmd_gpu, CACHE_FLUSH_TS);
+	GSL_RB_WRITE(ringcmds, rcmd_gpu,
+		     (rb->device->memstore.gpuaddr +
+		      KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp)));
+	GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
+
+	if (!(flags & KGSL_CMD_FLAGS_NO_TS_CMP)) {
+		/* Conditional execution based on memory values */
+		GSL_RB_WRITE(ringcmds, rcmd_gpu,
+			pm4_type3_packet(PM4_COND_EXEC, 4));
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, (rb->device->memstore.gpuaddr +
+			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable)) >> 2);
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, (rb->device->memstore.gpuaddr +
+			KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts)) >> 2);
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
+		/* # of conditional command DWORDs */
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, 2);
+		GSL_RB_WRITE(ringcmds, rcmd_gpu,
+			pm4_type3_packet(PM4_INTERRUPT, 1));
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, CP_INT_CNTL__RB_INT_MASK);
+	}
+
+	kgsl_ringbuffer_submit(rb);
+
+	/* return timestamp of issued coREG_ands */
+	return timestamp;
+}
+
+void
+kgsl_ringbuffer_issuecmds(struct kgsl_device *device,
+						unsigned int flags,
+						unsigned int *cmds,
+						int sizedwords)
+{
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
+
+	if (device->state & KGSL_STATE_HUNG)
+		return;
+	kgsl_ringbuffer_addcmds(rb, flags, cmds, sizedwords);
+}
+
+int
+kgsl_ringbuffer_issueibcmds(struct kgsl_device_private *dev_priv,
+				struct kgsl_context *context,
+				struct kgsl_ibdesc *ibdesc,
+				unsigned int numibs,
+				uint32_t *timestamp,
+				unsigned int flags)
+{
+	struct kgsl_device *device = dev_priv->device;
+	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
+	unsigned int *link;
+	unsigned int *cmds;
+	unsigned int i;
+	struct kgsl_yamato_context *drawctxt = context->devctxt;
+
+	if (device->state & KGSL_STATE_HUNG)
+		return -EBUSY;
+	if (!(yamato_device->ringbuffer.flags & KGSL_FLAGS_STARTED) ||
+	      context == NULL)
+		return -EINVAL;
+
+	BUG_ON(ibdesc == 0);
+	BUG_ON(numibs == 0);
+
+	if (drawctxt->flags & CTXT_FLAGS_GPU_HANG) {
+		KGSL_CTXT_WARN(device, "Context %p caused a gpu hang.."
+			" will not accept commands for this context\n",
+			drawctxt);
+		return -EDEADLK;
+	}
+	link = kzalloc(sizeof(unsigned int) * numibs * 3, GFP_KERNEL);
+	cmds = link;
+	if (!link) {
+		KGSL_MEM_ERR(device, "Failed to allocate memory for for command"
+			" submission, size %x\n", numibs * 3);
+		return -ENOMEM;
+	}
+	for (i = 0; i < numibs; i++) {
+		(void)kgsl_cffdump_parse_ibs(dev_priv, NULL,
+			ibdesc[i].gpuaddr, ibdesc[i].sizedwords, false);
+
+		*cmds++ = PM4_HDR_INDIRECT_BUFFER_PFD;
+		*cmds++ = ibdesc[i].gpuaddr;
+		*cmds++ = ibdesc[i].sizedwords;
+	}
+
+	kgsl_setstate(device,
+		      kgsl_pt_get_flags(device->mmu.hwpagetable,
+					device->id));
+
+	kgsl_drawctxt_switch(yamato_device, drawctxt, flags);
+
+	*timestamp = kgsl_ringbuffer_addcmds(&yamato_device->ringbuffer,
+					KGSL_CMD_FLAGS_NOT_KERNEL_CMD,
+					&link[0], (cmds - link));
+
+	KGSL_CMD_INFO(device, "ctxt %d g %08x numibs %d ts %d\n",
+		context->id, (unsigned int)ibdesc, numibs, *timestamp);
+
+	kfree(link);
+
+#ifdef CONFIG_MSM_KGSL_CFF_DUMP
+	/*
+	 * insert wait for idle after every IB1
+	 * this is conservative but works reliably and is ok
+	 * even for performance simulations
+	 */
+	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
+#endif
+
+	return 0;
+}
+
+int kgsl_ringbuffer_extract(struct kgsl_ringbuffer *rb,
+				unsigned int *temp_rb_buffer,
+				int *rb_size)
+{
+	struct kgsl_device *device = rb->device;
+	unsigned int rb_rptr;
+	unsigned int retired_timestamp;
+	unsigned int temp_idx = 0;
+	unsigned int value;
+	unsigned int val1;
+	unsigned int val2;
+	unsigned int val3;
+	unsigned int copy_rb_contents = 0;
+	unsigned int cur_context;
+	unsigned int j;
+
+	GSL_RB_GET_READPTR(rb, &rb->rptr);
+
+	retired_timestamp = device->ftbl.device_readtimestamp(
+				device, KGSL_TIMESTAMP_RETIRED);
+	rmb();
+	KGSL_DRV_ERR(device, "GPU successfully executed till ts: %x\n",
+			retired_timestamp);
+	/*
+	 * We need to go back in history by 4 dwords from the current location
+	 * of read pointer as 4 dwords are read to match the end of a command.
+	 * Also, take care of wrap around when moving back
+	 */
+	if (rb->rptr >= 4)
+		rb_rptr = (rb->rptr - 4) * sizeof(unsigned int);
+	else
+		rb_rptr = rb->buffer_desc.size -
+			((4 - rb->rptr) * sizeof(unsigned int));
+	/* Read the rb contents going backwards to locate end of last
+	 * sucessfully executed command */
+	while ((rb_rptr / sizeof(unsigned int)) != rb->wptr) {
+		kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
+		rmb();
+		if (value == retired_timestamp) {
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			kgsl_sharedmem_readl(&rb->buffer_desc, &val2, rb_rptr);
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			kgsl_sharedmem_readl(&rb->buffer_desc, &val3, rb_rptr);
+			rmb();
+			/* match the pattern found at the end of a command */
+			if ((val1 == 2 &&
+				val2 == pm4_type3_packet(PM4_INTERRUPT, 1)
+				&& val3 == CP_INT_CNTL__RB_INT_MASK) ||
+				(val1 == pm4_type3_packet(PM4_EVENT_WRITE, 3)
+				&& val2 == CACHE_FLUSH_TS &&
+				val3 == (rb->device->memstore.gpuaddr +
+				KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp)))) {
+				rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+				KGSL_DRV_ERR(device,
+					"Found end of last executed "
+					"command at offset: %x\n",
+					rb_rptr / sizeof(unsigned int));
+				break;
+			} else {
+				if (rb_rptr < (3 * sizeof(unsigned int)))
+					rb_rptr = rb->buffer_desc.size -
+						(3 * sizeof(unsigned int))
+							+ rb_rptr;
+				else
+					rb_rptr -= (3 * sizeof(unsigned int));
+			}
+		}
+
+		if (rb_rptr == 0)
+			rb_rptr = rb->buffer_desc.size - sizeof(unsigned int);
+		else
+			rb_rptr -= sizeof(unsigned int);
+	}
+
+	if ((rb_rptr / sizeof(unsigned int)) == rb->wptr) {
+		KGSL_DRV_ERR(device,
+			"GPU recovery from hang not possible because last"
+			" successful timestamp is overwritten\n");
+		return -EINVAL;
+	}
+	/* rb_rptr is now pointing to the first dword of the command following
+	 * the last sucessfully executed command sequence. Assumption is that
+	 * GPU is hung in the command sequence pointed by rb_rptr */
+	/* make sure the GPU is not hung in a command submitted by kgsl
+	 * itself */
+	kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
+	kgsl_sharedmem_readl(&rb->buffer_desc, &val2,
+				adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size));
+	rmb();
+	if (val1 == pm4_nop_packet(1) && val2 == KGSL_CMD_IDENTIFIER) {
+		KGSL_DRV_ERR(device,
+			"GPU recovery from hang not possible because "
+			"of hang in kgsl command\n");
+		return -EINVAL;
+	}
+
+	/* current_context is the context that is presently active in the
+	 * GPU, i.e the context in which the hang is caused */
+	kgsl_sharedmem_readl(&device->memstore, &cur_context,
+		KGSL_DEVICE_MEMSTORE_OFFSET(current_context));
+	while ((rb_rptr / sizeof(unsigned int)) != rb->wptr) {
+		kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
+		rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+						rb->buffer_desc.size);
+		rmb();
+		/* check for context switch indicator */
+		if (value == KGSL_CONTEXT_TO_MEM_IDENTIFIER) {
+			kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			rmb();
+			BUG_ON(value != pm4_type3_packet(PM4_MEM_WRITE, 2));
+			kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			rmb();
+			BUG_ON(val1 != (device->memstore.gpuaddr +
+				KGSL_DEVICE_MEMSTORE_OFFSET(current_context)));
+			kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
+			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
+							rb->buffer_desc.size);
+			rmb();
+			BUG_ON((copy_rb_contents == 0) &&
+				(value == cur_context));
+			/* if context switches to a context that did not cause
+			 * hang then start saving the rb contents as those
+			 * commands can be executed */
+			if (value != cur_context) {
+				copy_rb_contents = 1;
+				temp_rb_buffer[temp_idx++] = pm4_nop_packet(1);
+				temp_rb_buffer[temp_idx++] =
+						KGSL_CMD_IDENTIFIER;
+				temp_rb_buffer[temp_idx++] = pm4_nop_packet(1);
+				temp_rb_buffer[temp_idx++] =
+						KGSL_CONTEXT_TO_MEM_IDENTIFIER;
+				temp_rb_buffer[temp_idx++] =
+					pm4_type3_packet(PM4_MEM_WRITE, 2);
+				temp_rb_buffer[temp_idx++] = val1;
+				temp_rb_buffer[temp_idx++] = value;
+			} else {
+				/* if temp_idx is not 0 then we do not need to
+				 * copy extra dwords indicating a kernel cmd */
+				if (temp_idx)
+					temp_idx -= 3;
+				copy_rb_contents = 0;
+			}
+		} else if (copy_rb_contents)
+			temp_rb_buffer[temp_idx++] = value;
+	}
+
+	*rb_size = temp_idx;
+	KGSL_DRV_ERR(device, "Extracted rb contents, size: %x\n", *rb_size);
+	for (temp_idx = 0; temp_idx < *rb_size;) {
+		char str[80];
+		int idx = 0;
+		if ((temp_idx + 8) <= *rb_size)
+			j = 8;
+		else
+			j = *rb_size - temp_idx;
+		for (; j != 0; j--)
+			idx += scnprintf(str + idx, 80 - idx,
+				"%8.8X ", temp_rb_buffer[temp_idx++]);
+		printk(KERN_ALERT "%s", str);
+	}
+	return 0;
+}
+
+void
+kgsl_ringbuffer_restore(struct kgsl_ringbuffer *rb, unsigned int *rb_buff,
+			int num_rb_contents)
+{
+	int i;
+	unsigned int *ringcmds;
+	unsigned int rcmd_gpu;
+
+	if (!num_rb_contents)
+		return;
+
+	if (num_rb_contents > (rb->buffer_desc.size - rb->wptr)) {
+		kgsl_yamato_regwrite(rb->device, REG_CP_RB_RPTR, 0);
+		rb->rptr = 0;
+		BUG_ON(num_rb_contents > rb->buffer_desc.size);
+	}
+	ringcmds = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
+	rcmd_gpu = rb->buffer_desc.gpuaddr + sizeof(unsigned int) * rb->wptr;
+	for (i = 0; i < num_rb_contents; i++)
+		GSL_RB_WRITE(ringcmds, rcmd_gpu, rb_buff[i]);
+	rb->wptr += num_rb_contents;
+	kgsl_ringbuffer_submit(rb);
+}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.h
new file mode 100644
index 0000000..6c39ee8
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/adreno_ringbuffer.h
@@ -0,0 +1,204 @@
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef __ADRENO_RINGBUFFER_H
+#define __ADRENO_RINGBUFFER_H
+
+#define GSL_RB_USE_MEM_RPTR
+#define GSL_RB_USE_MEM_TIMESTAMP
+#define GSL_DEVICE_SHADOW_MEMSTORE_TO_USER
+
+/* ringbuffer sizes log2quadword */
+#define GSL_RB_SIZE_8		0
+#define GSL_RB_SIZE_16		1
+#define GSL_RB_SIZE_32		2
+#define GSL_RB_SIZE_64		3
+#define GSL_RB_SIZE_128		4
+#define GSL_RB_SIZE_256		5
+#define GSL_RB_SIZE_512		6
+#define GSL_RB_SIZE_1K  	7
+#define GSL_RB_SIZE_2K  	8
+#define GSL_RB_SIZE_4K  	9
+#define GSL_RB_SIZE_8K  	10
+#define GSL_RB_SIZE_16K 	11
+#define GSL_RB_SIZE_32K 	12
+#define GSL_RB_SIZE_64K 	13
+#define GSL_RB_SIZE_128K	14
+#define GSL_RB_SIZE_256K	15
+#define GSL_RB_SIZE_512K	16
+#define GSL_RB_SIZE_1M		17
+#define GSL_RB_SIZE_2M		18
+#define GSL_RB_SIZE_4M		19
+
+/* Yamato ringbuffer config*/
+static const unsigned int kgsl_cfg_rb_sizelog2quadwords = GSL_RB_SIZE_32K;
+static const unsigned int kgsl_cfg_rb_blksizequadwords  = GSL_RB_SIZE_16;
+
+/* CP timestamp register */
+#define	REG_CP_TIMESTAMP		 REG_SCRATCH_REG0
+
+
+struct kgsl_device;
+struct kgsl_device_private;
+
+#define GSL_RB_MEMPTRS_SCRATCH_COUNT	 8
+struct kgsl_rbmemptrs {
+	int  rptr;
+	int  wptr_poll;
+};
+
+#define GSL_RB_MEMPTRS_RPTR_OFFSET \
+	(offsetof(struct kgsl_rbmemptrs, rptr))
+
+#define GSL_RB_MEMPTRS_WPTRPOLL_OFFSET \
+	(offsetof(struct kgsl_rbmemptrs, wptr_poll))
+
+struct kgsl_ringbuffer {
+	struct kgsl_device *device;
+	uint32_t flags;
+
+	struct kgsl_memdesc buffer_desc;
+
+	struct kgsl_memdesc memptrs_desc;
+	struct kgsl_rbmemptrs *memptrs;
+
+	/*ringbuffer size */
+	unsigned int sizedwords;
+	unsigned int blksizequadwords;
+
+	unsigned int wptr; /* write pointer offset in dwords from baseaddr */
+	unsigned int rptr; /* read pointer offset in dwords from baseaddr */
+	uint32_t timestamp;
+};
+
+/* dword base address of the GFX decode space */
+#define GSL_HAL_SUBBLOCK_OFFSET(reg) ((unsigned int)((reg) - (0x2000)))
+
+#define GSL_RB_WRITE(ring, gpuaddr, data) \
+	do { \
+		writel(data, ring); \
+		kgsl_cffdump_setmem(gpuaddr, data, 4); \
+		ring++; \
+		gpuaddr += sizeof(uint); \
+		wmb(); \
+	} while (0)
+
+/* timestamp */
+#ifdef GSL_DEVICE_SHADOW_MEMSTORE_TO_USER
+#define GSL_RB_USE_MEM_TIMESTAMP
+#endif /* GSL_DEVICE_SHADOW_MEMSTORE_TO_USER */
+
+#ifdef GSL_RB_USE_MEM_TIMESTAMP
+/* enable timestamp (...scratch0) memory shadowing */
+#define GSL_RB_MEMPTRS_SCRATCH_MASK 0x1
+#define GSL_RB_INIT_TIMESTAMP(rb)
+
+#else
+#define GSL_RB_MEMPTRS_SCRATCH_MASK 0x0
+#define GSL_RB_INIT_TIMESTAMP(rb) \
+		kgsl_yamato_regwrite((rb)->device->id, REG_CP_TIMESTAMP, 0)
+
+#endif /* GSL_RB_USE_MEMTIMESTAMP */
+
+/* mem rptr */
+#ifdef GSL_RB_USE_MEM_RPTR
+#define GSL_RB_CNTL_NO_UPDATE 0x0 /* enable */
+#define GSL_RB_GET_READPTR(rb, data) \
+	do { \
+		*(data) = readl(&(rb)->memptrs->rptr); \
+		rmb(); \
+	} while (0)
+#else
+#define GSL_RB_CNTL_NO_UPDATE 0x1 /* disable */
+#define GSL_RB_GET_READPTR(rb, data) \
+	do { \
+		kgsl_yamato_regread((rb)->device->id, REG_CP_RB_RPTR, (data)); \
+	} while (0)
+#endif /* GSL_RB_USE_MEMRPTR */
+
+/* wptr polling */
+#ifdef GSL_RB_USE_WPTR_POLLING
+#define GSL_RB_CNTL_POLL_EN 0x1 /* enable */
+#define GSL_RB_UPDATE_WPTR_POLLING(rb) \
+	do { writel((rb)->wptr, &((rb)->memptrs->wptr_poll)); } while (0)
+#else
+#define GSL_RB_CNTL_POLL_EN 0x0 /* disable */
+#define GSL_RB_UPDATE_WPTR_POLLING(rb)
+#endif	/* GSL_RB_USE_WPTR_POLLING */
+
+int kgsl_ringbuffer_issueibcmds(struct kgsl_device_private *dev_priv,
+				struct kgsl_context *context,
+				struct kgsl_ibdesc *ibdesc, unsigned int numibs,
+				uint32_t *timestamp,
+				unsigned int flags);
+
+int kgsl_ringbuffer_init(struct kgsl_device *device);
+
+int kgsl_ringbuffer_start(struct kgsl_ringbuffer *rb, unsigned int init_ram);
+
+int kgsl_ringbuffer_stop(struct kgsl_ringbuffer *rb);
+
+int kgsl_ringbuffer_close(struct kgsl_ringbuffer *rb);
+
+void kgsl_ringbuffer_issuecmds(struct kgsl_device *device,
+					unsigned int flags,
+					unsigned int *cmdaddr,
+					int sizedwords);
+
+void kgsl_cp_intrcallback(struct kgsl_device *device);
+
+int kgsl_ringbuffer_extract(struct kgsl_ringbuffer *rb,
+				unsigned int *temp_rb_buffer,
+				int *rb_size);
+
+void
+kgsl_ringbuffer_restore(struct kgsl_ringbuffer *rb, unsigned int *rb_buff,
+			int num_rb_contents);
+
+static inline int kgsl_ringbuffer_count(struct kgsl_ringbuffer *rb,
+	unsigned int rptr)
+{
+	if (rb->wptr >= rptr)
+		return rb->wptr - rptr;
+	return rb->wptr + rb->sizedwords - rptr;
+}
+
+/* Increment a value by 4 bytes with wrap-around based on size */
+static inline unsigned int adreno_ringbuffer_inc_wrapped(unsigned int val,
+							unsigned int size)
+{
+	return (val + sizeof(unsigned int)) % size;
+}
+
+static inline int
+kgsl_allocate_contig(struct kgsl_memdesc *memdesc, size_t size)
+{
+	return kgsl_sharedmem_alloc_coherent(memdesc, size);
+}
+
+#endif  /* __ADRENO_RINGBUFFER_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.c
index 7e03aab..c8b7221 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.c
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.c
@@ -15,38 +15,26 @@
  * 02110-1301, USA.
  *
  */
-#include <linux/platform_device.h>
 #include <linux/fb.h>
 #include <linux/file.h>
 #include <linux/fs.h>
+#include <linux/debugfs.h>
 #include <linux/uaccess.h>
-#include <linux/init.h>
-#include <linux/list.h>
-#include <linux/io.h>
-#include <linux/irq.h>
 #include <linux/interrupt.h>
-#include <linux/mm.h>
+#include <linux/workqueue.h>
 #include <linux/android_pmem.h>
-#include <linux/highmem.h>
 #include <linux/vmalloc.h>
-#include <linux/notifier.h>
 #include <linux/pm_runtime.h>
-#include <asm/atomic.h>
 #include <linux/genlock.h>
 
 #include <linux/ashmem.h>
+#include <linux/major.h>
 
 #include "kgsl.h"
-#include "kgsl_mmu.h"
-#include "kgsl_yamato.h"
-#include "kgsl_g12.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_postmortem.h"
 
 #include "kgsl_debugfs.h"
-#include "kgsl_log.h"
-#include "kgsl_drm.h"
 #include "kgsl_cffdump.h"
+#include "adreno_ringbuffer.h"
 
 #undef MODULE_PARAM_PREFIX
 #define MODULE_PARAM_PREFIX "kgsl."
@@ -76,7 +64,7 @@ static int kgsl_add_event(struct kgsl_device *device, u32 ts,
 /* FIXME
 	unsigned int cur = device->ftbl->readtimestamp(device,
 */
-	unsigned int cur = device->ftbl.device_cmdstream_readtimestamp(device,
+	unsigned int cur = device->ftbl.device_readtimestamp(device,
 		KGSL_TIMESTAMP_RETIRED);
 
 	if (cb == NULL)
@@ -261,7 +249,7 @@ static void kgsl_memqueue_drain(struct kgsl_device *device)
 	BUG_ON(!mutex_is_locked(&device->mutex));
 
 	/* get current EOP timestamp */
-	ts_processed = device->ftbl.device_cmdstream_readtimestamp(
+	ts_processed = device->ftbl.device_readtimestamp(
 					device,
 					KGSL_TIMESTAMP_RETIRED);
 
@@ -373,9 +361,9 @@ int kgsl_unregister_ts_notifier(struct kgsl_device *device,
 int kgsl_check_timestamp(struct kgsl_device *device, unsigned int timestamp)
 {
 	unsigned int ts_processed;
-	BUG_ON(device->ftbl.device_cmdstream_readtimestamp == NULL);
+	BUG_ON(device->ftbl.device_readtimestamp == NULL);
 
-	ts_processed = device->ftbl.device_cmdstream_readtimestamp(
+	ts_processed = device->ftbl.device_readtimestamp(
 			device, KGSL_TIMESTAMP_RETIRED);
 
 	return timestamp_cmp(ts_processed, timestamp);
@@ -709,7 +697,6 @@ static int kgsl_release(struct inode *inodep, struct file *filep)
 	device->open_count--;
 	if (device->open_count == 0) {
 		result = device->ftbl.device_stop(device);
-		kgsl_cmdstream_close(device);
 		device->state = KGSL_STATE_INIT;
 		KGSL_PWR_WARN(device, "state -> INIT, device %d\n", device->id);
 	}
@@ -802,6 +789,11 @@ static int kgsl_open(struct inode *inodep, struct file *filep)
 	}
 	device->open_count++;
 	mutex_unlock(&device->mutex);
+
+	KGSL_DRV_INFO(device, "Initialized %s: mmu=%s pagetable_count=%d\n",
+		device->name, kgsl_mmu_isenabled(&dev_priv->device->mmu) ? "on" : "off",
+		KGSL_PAGETABLE_COUNT);
+
 	return result;
 
 err_putprocess:
@@ -868,64 +860,6 @@ struct kgsl_mem_entry *
 	return memdesc->hostptr + (memdesc->gpuaddr - gpuaddr);
 }
 
-uint8_t *kgsl_sharedmem_convertaddr(struct kgsl_device *device,
-	unsigned int pt_base, unsigned int gpuaddr, unsigned int *size)
-{
-	uint8_t *result = NULL;
-	struct kgsl_mem_entry *entry;
-	struct kgsl_process_private *priv;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *ringbuffer = &yamato_device->ringbuffer;
-
-	if (kgsl_gpuaddr_in_memdesc(&ringbuffer->buffer_desc, gpuaddr)) {
-		return kgsl_gpuaddr_to_vaddr(&ringbuffer->buffer_desc,
-					gpuaddr, size);
-	}
-
-	if (kgsl_gpuaddr_in_memdesc(&ringbuffer->memptrs_desc, gpuaddr)) {
-		return kgsl_gpuaddr_to_vaddr(&ringbuffer->memptrs_desc,
-					gpuaddr, size);
-	}
-
-	if (kgsl_gpuaddr_in_memdesc(&device->memstore, gpuaddr)) {
-		return kgsl_gpuaddr_to_vaddr(&device->memstore,
-					gpuaddr, size);
-	}
-
-	mutex_lock(&kgsl_driver.process_mutex);
-	list_for_each_entry(priv, &kgsl_driver.process_list, list) {
-		if (pt_base != 0
-			&& priv->pagetable
-			&& priv->pagetable->base.gpuaddr != pt_base) {
-			continue;
-		}
-
-		spin_lock(&priv->mem_lock);
-		entry = kgsl_sharedmem_find_region(priv, gpuaddr,
-						sizeof(unsigned int));
-		if (entry) {
-			result = kgsl_gpuaddr_to_vaddr(&entry->memdesc,
-							gpuaddr, size);
-			spin_unlock(&priv->mem_lock);
-			mutex_unlock(&kgsl_driver.process_mutex);
-			return result;
-		}
-		spin_unlock(&priv->mem_lock);
-	}
-	mutex_unlock(&kgsl_driver.process_mutex);
-
-	BUG_ON(!mutex_is_locked(&device->mutex));
-	list_for_each_entry(entry, &device->memqueue, list) {
-		if (kgsl_gpuaddr_in_memdesc(&entry->memdesc, gpuaddr)) {
-			result = kgsl_gpuaddr_to_vaddr(&entry->memdesc,
-							gpuaddr, size);
-			break;
-		}
-
-	}
-	return result;
-}
-
 /*call all ioctl sub functions with driver locked*/
 static long kgsl_ioctl_device_getproperty(struct kgsl_device_private *dev_priv,
 					  unsigned int cmd, void *data)
@@ -1159,7 +1093,7 @@ static long kgsl_ioctl_cmdstream_readtimestamp(struct kgsl_device_private
 	struct kgsl_cmdstream_readtimestamp *param = data;
 
 	param->timestamp =
-		dev_priv->device->ftbl.device_cmdstream_readtimestamp(
+		dev_priv->device->ftbl.device_readtimestamp(
 			dev_priv->device, param->type);
 
 	return 0;
@@ -1206,7 +1140,8 @@ static long kgsl_ioctl_drawctxt_create(struct kgsl_device_private *dev_priv,
 		goto done;
 	}
 
-	result = dev_priv->device->ftbl.device_drawctxt_create(dev_priv,
+	if (dev_priv->device->ftbl.device_drawctxt_create != NULL)
+		result = dev_priv->device->ftbl.device_drawctxt_create(dev_priv,
 					param->flags,
 					context);
 
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.h
index 536d0d9..e23a614 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.h
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl.h
@@ -26,13 +26,14 @@
  * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#ifndef _GSL_DRIVER_H
-#define _GSL_DRIVER_H
+#ifndef __KGSL_H
+#define __KGSL_H
 
 #include <linux/types.h>
 #include <linux/msm_kgsl.h>
 #include <linux/platform_device.h>
 #include <linux/clk.h>
+#include <linux/interrupt.h>
 #include <linux/mutex.h>
 #include <linux/cdev.h>
 #include <linux/regulator/consumer.h>
@@ -40,7 +41,10 @@
 #include <asm/atomic.h>
 
 #include "kgsl_device.h"
+#include "kgsl_pwrctrl.h"
 #include "kgsl_sharedmem.h"
+#include "kgsl_log.h"
+#include "kgsl_cffdump.h"
 
 #define KGSL_NAME "kgsl"
 
@@ -58,9 +62,6 @@
 #define DRM_KGSL_GEM_CACHE_OP_TO_DEV	0x0001
 #define DRM_KGSL_GEM_CACHE_OP_FROM_DEV	0x0002
 
-#define KGSL_NUM_2D_DEVICES 2
-#define IDX_2D(X) ((X)-KGSL_DEVICE_2D0)
-
 /* The size of each entry in a page table */
 #define KGSL_PAGETABLE_ENTRY_SIZE  4
 
@@ -165,8 +166,6 @@ struct kgsl_mem_entry {
 struct kgsl_mem_entry *kgsl_sharedmem_find_region(
 	struct kgsl_process_private *private, unsigned int gpuaddr,
 	size_t size);
-uint8_t *kgsl_sharedmem_convertaddr(struct kgsl_device *device,
-	unsigned int pt_base, unsigned int gpuaddr, unsigned int *size);
 int kgsl_idle(struct kgsl_device *device, unsigned int timeout);
 int kgsl_setstate(struct kgsl_device *device, uint32_t flags);
 
@@ -274,4 +273,4 @@ static inline bool timestamp_cmp(unsigned int new, unsigned int old)
 	kref_put(&entry->refcount, kgsl_mem_entry_destroy);
 }
 
-#endif /* _GSL_DRIVER_H */
+#endif /* __KGSL_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.c
deleted file mode 100644
index 1dd78be..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.c
+++ /dev/null
@@ -1,54 +0,0 @@
-/* Copyright (c) 2009-2010, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301, USA.
- *
- */
-
-#include "kgsl.h"
-#include "kgsl_log.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_sharedmem.h"
-#include "kgsl_yamato.h"
-
-int kgsl_cmdstream_close(struct kgsl_device *device)
-{
-	struct kgsl_mem_entry *entry, *entry_tmp;
-
-	BUG_ON(!mutex_is_locked(&device->mutex));
-
-	list_for_each_entry_safe(entry, entry_tmp, &device->memqueue, list) {
-		list_del(&entry->list);
-		kgsl_mem_entry_put(entry);
-	}
-	return 0;
-}
-
-uint32_t
-kgsl_cmdstream_readtimestamp(struct kgsl_device *device,
-			     enum kgsl_timestamp_type type)
-{
-	uint32_t timestamp = 0;
-
-	if (type == KGSL_TIMESTAMP_CONSUMED)
-		KGSL_CMDSTREAM_GET_SOP_TIMESTAMP(device,
-						 (unsigned int *)&timestamp);
-	else if (type == KGSL_TIMESTAMP_RETIRED)
-		KGSL_CMDSTREAM_GET_EOP_TIMESTAMP(device,
-						 (unsigned int *)&timestamp);
-	rmb();
-
-	return timestamp;
-}
-
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.h
deleted file mode 100644
index e3b8ca4..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_cmdstream.h
+++ /dev/null
@@ -1,70 +0,0 @@
-/* Copyright (c) 2009-2011, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-
-#ifndef __KGSL_CMDSTREAM_H
-#define __KGSL_CMDSTREAM_H
-
-#include <linux/msm_kgsl.h>
-#include "kgsl_device.h"
-
-#ifdef KGSL_DEVICE_SHADOW_MEMSTORE_TO_USER
-#define KGSL_CMDSTREAM_USE_MEM_TIMESTAMP
-#endif /* KGSL_DEVICE_SHADOW_MEMSTORE_TO_USER */
-
-#ifdef KGSL_CMDSTREAM_USE_MEM_TIMESTAMP
-#define KGSL_CMDSTREAM_GET_SOP_TIMESTAMP(device, data) 	\
-		kgsl_sharedmem_readl(&device->memstore, (data),	\
-				KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp))
-#else
-#define KGSL_CMDSTREAM_GET_SOP_TIMESTAMP(device, data)	\
-		kgsl_yamato_regread(device, REG_CP_TIMESTAMP, (data))
-#endif /* KGSL_CMDSTREAM_USE_MEM_TIMESTAMP */
-
-#define KGSL_CMDSTREAM_GET_EOP_TIMESTAMP(device, data)	\
-		kgsl_sharedmem_readl(&device->memstore, (data),	\
-				KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp))
-
-/* Flags to control command packet settings */
-#define KGSL_CMD_FLAGS_PMODE			0x00000001
-#define KGSL_CMD_FLAGS_NO_TS_CMP		0x00000002
-#define KGSL_CMD_FLAGS_NOT_KERNEL_CMD		0x00000004
-
-/* Command identifiers */
-#define KGSL_CONTEXT_TO_MEM_IDENTIFIER		0xDEADBEEF
-#define KGSL_CMD_IDENTIFIER			0xFEEDFACE
-
-struct kgsl_mem_entry;
-
-int kgsl_cmdstream_close(struct kgsl_device *device);
-
-uint32_t
-kgsl_cmdstream_readtimestamp(struct kgsl_device *device,
-			     enum kgsl_timestamp_type type);
-
-#endif /* __KGSL_CMDSTREAM_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_device.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_device.h
index 92a406f..ca08ca7 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_device.h
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_device.h
@@ -26,20 +26,11 @@
  * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#ifndef _KGSL_DEVICE_H
-#define _KGSL_DEVICE_H
-
-#include <linux/types.h>
-#include <linux/irqreturn.h>
-#include <linux/wait.h>
-#include <linux/workqueue.h>
-#include <linux/mutex.h>
-#include <linux/msm_kgsl.h>
+#ifndef __KGSL_DEVICE_H
+#define __KGSL_DEVICE_H
 #include <linux/idr.h>
 #include <linux/wakelock.h>
 
-#include <asm/atomic.h>
-
 #include "kgsl_mmu.h"
 #include "kgsl_pwrctrl.h"
 #include "kgsl_log.h"
@@ -108,7 +99,7 @@ struct kgsl_functable {
 	int (*device_waittimestamp) (struct kgsl_device *device,
 					unsigned int timestamp,
 					unsigned int msecs);
-	unsigned int (*device_cmdstream_readtimestamp) (
+	unsigned int (*device_readtimestamp) (
 					struct kgsl_device *device,
 					enum kgsl_timestamp_type type);
 	int (*device_issueibcmds) (struct kgsl_device_private *dev_priv,
@@ -134,10 +125,10 @@ struct kgsl_functable {
 };
 
 struct kgsl_memregion {
-	unsigned char  *mmio_virt_base;
-	unsigned int   mmio_phys_base;
-	uint32_t      gpu_base;
-	unsigned int   sizebytes;
+	unsigned char *mmio_virt_base;
+	unsigned int mmio_phys_base;
+	uint32_t gpu_base;
+	unsigned int sizebytes;
 };
 
 struct kgsl_event {
@@ -153,14 +144,14 @@ struct kgsl_device {
 	const char *name;
 	unsigned int ver_major;
 	unsigned int ver_minor;
-	uint32_t       flags;
-	enum kgsl_deviceid    id;
-	unsigned int      chip_id;
+	uint32_t flags;
+	enum kgsl_deviceid id;
+	unsigned int chip_id;
 	struct kgsl_memregion regspace;
 	struct kgsl_memdesc memstore;
 	const char *iomemname;
 
-	struct kgsl_mmu 	  mmu;
+	struct kgsl_mmu mmu;
 	struct completion hwaccess_gate;
 	struct kgsl_functable ftbl;
 	struct work_struct idle_check_ws;
@@ -170,8 +161,8 @@ struct kgsl_device {
 
 	struct atomic_notifier_head ts_notifier_list;
 	struct mutex mutex;
-	uint32_t		state;
-	uint32_t		requested_state;
+	uint32_t state;
+	uint32_t requested_state;
 
 	struct list_head memqueue;
 	unsigned int active_cnt;
@@ -228,18 +219,6 @@ struct kgsl_device_private {
 	struct kgsl_process_private *process_priv;
 };
 
-struct kgsl_devconfig {
-	struct kgsl_memregion regspace;
-
-	unsigned int     mmu_config;
-	uint32_t        mpu_base;
-	int              mpu_range;
-	uint32_t        va_base;
-	unsigned int     va_range;
-
-	struct kgsl_memregion gmemspace;
-};
-
 struct kgsl_power_stats {
 	s64 total_time;
 	s64 busy_time;
@@ -276,4 +255,4 @@ static inline int kgsl_create_device_workqueue(struct kgsl_device *device)
 	return  (ctxt && ctxt->dev_priv == dev_priv) ? ctxt : NULL;
 }
 
-#endif  /* _KGSL_DEVICE_H */
+#endif  /* __KGSL_DEVICE_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.c
deleted file mode 100644
index 765146f..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.c
+++ /dev/null
@@ -1,1726 +0,0 @@
-/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301, USA.
- *
- */
-#include <linux/string.h>
-#include <linux/types.h>
-#include <linux/slab.h>
-#include <linux/msm_kgsl.h>
-
-#include "yamato_reg.h"
-#include "leia_reg.h"
-#include "kgsl.h"
-#include "kgsl_yamato.h"
-#include "kgsl_log.h"
-#include "kgsl_pm4types.h"
-#include "kgsl_drawctxt.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_cffdump.h"
-
-/*
-*
-*  Memory Map for Register, Constant & Instruction Shadow, and Command Buffers
-*  (34.5KB)
-*
-*  +---------------------+------------+-------------+---+---------------------+
-*  | ALU Constant Shadow | Reg Shadow | C&V Buffers |Tex| Shader Instr Shadow |
-*  +---------------------+------------+-------------+---+---------------------+
-*    ________________________________/               \____________________
-*   /                                                                     |
-*  +--------------+-----------+------+-----------+------------------------+
-*  | Restore Regs | Save Regs | Quad | Gmem Save | Gmem Restore | unused  |
-*  +--------------+-----------+------+-----------+------------------------+
-*
-* 		 8K - ALU Constant Shadow (8K aligned)
-* 		 4K - H/W Register Shadow (8K aligned)
-* 		 4K - Command and Vertex Buffers
-* 				- Indirect command buffer : Const/Reg restore
-* 					- includes Loop & Bool const shadows
-* 				- Indirect command buffer : Const/Reg save
-* 				- Quad vertices & texture coordinates
-* 				- Indirect command buffer : Gmem save
-* 				- Indirect command buffer : Gmem restore
-* 				- Unused (padding to 8KB boundary)
-* 		<1K - Texture Constant Shadow (768 bytes) (8K aligned)
-*       18K - Shader Instruction Shadow
-*               - 6K vertex (32 byte aligned)
-*               - 6K pixel  (32 byte aligned)
-*               - 6K shared (32 byte aligned)
-*
-*  Note: Reading constants into a shadow, one at a time using REG_TO_MEM, takes
-*  3 DWORDS per DWORD transfered, plus 1 DWORD for the shadow, for a total of
-*  16 bytes per constant.  If the texture constants were transfered this way,
-*  the Command & Vertex Buffers section would extend past the 16K boundary.
-*  By moving the texture constant shadow area to start at 16KB boundary, we
-*  only require approximately 40 bytes more memory, but are able to use the
-*  LOAD_CONSTANT_CONTEXT shadowing feature for the textures, speeding up
-*  context switching.
-*
-*  [Using LOAD_CONSTANT_CONTEXT shadowing feature for the Loop and/or Bool
-*  constants would require an additional 8KB each, for alignment.]
-*
-*/
-
-/* Constants */
-
-#define ALU_CONSTANTS	2048	/* DWORDS */
-#define NUM_REGISTERS	1024	/* DWORDS */
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-#define CMD_BUFFER_LEN  9216	/* DWORDS */
-#else
-#define CMD_BUFFER_LEN	3072	/* DWORDS */
-#endif
-#define TEX_CONSTANTS		(32*6)	/* DWORDS */
-#define BOOL_CONSTANTS		8	/* DWORDS */
-#define LOOP_CONSTANTS		56	/* DWORDS */
-#define SHADER_INSTRUCT_LOG2	9U	/* 2^n == SHADER_INSTRUCTIONS */
-
-#if defined(PM4_IM_STORE)
-/* 96-bit instructions */
-#define SHADER_INSTRUCT		(1<<SHADER_INSTRUCT_LOG2)
-#else
-#define SHADER_INSTRUCT		0
-#endif
-
-/* LOAD_CONSTANT_CONTEXT shadow size */
-#define LCC_SHADOW_SIZE		0x2000	/* 8KB */
-
-#define ALU_SHADOW_SIZE		LCC_SHADOW_SIZE	/* 8KB */
-#define REG_SHADOW_SIZE		0x1000	/* 4KB */
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-#define CMD_BUFFER_SIZE     0x9000	/* 36KB */
-#else
-#define CMD_BUFFER_SIZE		0x3000	/* 12KB */
-#endif
-#define TEX_SHADOW_SIZE		(TEX_CONSTANTS*4)	/* 768 bytes */
-#define SHADER_SHADOW_SIZE      (SHADER_INSTRUCT*12)	/* 6KB */
-
-#define REG_OFFSET		LCC_SHADOW_SIZE
-#define CMD_OFFSET		(REG_OFFSET + REG_SHADOW_SIZE)
-#define TEX_OFFSET		(CMD_OFFSET + CMD_BUFFER_SIZE)
-#define	SHADER_OFFSET		((TEX_OFFSET + TEX_SHADOW_SIZE + 32) & ~31)
-
-#define CONTEXT_SIZE		(SHADER_OFFSET + 3 * SHADER_SHADOW_SIZE)
-
-/* temporary work structure */
-struct tmp_ctx {
-	unsigned int *start;	/* Command & Vertex buffer start */
-	unsigned int *cmd;	/* Next available dword in C&V buffer */
-
-	/* address of buffers, needed when creating IB1 command buffers. */
-	uint32_t bool_shadow;	/* bool constants */
-	uint32_t loop_shadow;	/* loop constants */
-
-#if defined(PM4_IM_STORE)
-	uint32_t shader_shared;	/* shared shader instruction shadow */
-	uint32_t shader_vertex;	/* vertex shader instruction shadow */
-	uint32_t shader_pixel;	/* pixel shader instruction shadow */
-#endif
-
-	/* Addresses in command buffer where separately handled registers
-	 * are saved
-	 */
-	uint32_t reg_values[33];
-	uint32_t chicken_restore;
-
-	uint32_t gmem_base;	/* Base gpu address of GMEM */
-
-};
-
-/* Helper function to calculate IEEE754 single precision float values
-*  without FPU
-*/
-unsigned int uint2float(unsigned int uintval)
-{
-	unsigned int exp = 0;
-	unsigned int frac = 0;
-	unsigned int u = uintval;
-
-	/* Handle zero separately */
-	if (uintval == 0)
-		return 0;
-	/* Find log2 of u */
-	if (u >= 0x10000) {
-		exp += 16;
-		u >>= 16;
-	}
-	if (u >= 0x100) {
-		exp += 8;
-		u >>= 8;
-	}
-	if (u >= 0x10) {
-		exp += 4;
-		u >>= 4;
-	}
-	if (u >= 0x4) {
-		exp += 2;
-		u >>= 2;
-	}
-	if (u >= 0x2) {
-		exp += 1;
-		u >>= 1;
-	}
-
-	/* Calculate fraction */
-	if (23 > exp)
-		frac = (uintval & (~(1 << exp))) << (23 - exp);
-
-	/* Exp is biased by 127 and shifted 23 bits */
-	exp = (exp + 127) << 23;
-
-	return exp | frac;
-}
-
-/* context save (gmem -> sys) */
-
-/* pre-compiled vertex shader program
-*
-*  attribute vec4  P;
-*  void main(void)
-*  {
-*    gl_Position = P;
-*  }
-*/
-#define GMEM2SYS_VTX_PGM_LEN	0x12
-
-static unsigned int gmem2sys_vtx_pgm[GMEM2SYS_VTX_PGM_LEN] = {
-	0x00011003, 0x00001000, 0xc2000000,
-	0x00001004, 0x00001000, 0xc4000000,
-	0x00001005, 0x00002000, 0x00000000,
-	0x1cb81000, 0x00398a88, 0x00000003,
-	0x140f803e, 0x00000000, 0xe2010100,
-	0x14000000, 0x00000000, 0xe2000000
-};
-
-/* pre-compiled fragment shader program
-*
-*  precision highp float;
-*  uniform   vec4  clear_color;
-*  void main(void)
-*  {
-*     gl_FragColor = clear_color;
-*  }
-*/
-
-#define GMEM2SYS_FRAG_PGM_LEN	0x0c
-
-static unsigned int gmem2sys_frag_pgm[GMEM2SYS_FRAG_PGM_LEN] = {
-	0x00000000, 0x1002c400, 0x10000000,
-	0x00001003, 0x00002000, 0x00000000,
-	0x140f8000, 0x00000000, 0x22000000,
-	0x14000000, 0x00000000, 0xe2000000
-};
-
-/* context restore (sys -> gmem) */
-/* pre-compiled vertex shader program
-*
-*  attribute vec4 position;
-*  attribute vec4 texcoord;
-*  varying   vec4 texcoord0;
-*  void main()
-*  {
-*     gl_Position = position;
-*     texcoord0 = texcoord;
-*  }
-*/
-
-#define SYS2GMEM_VTX_PGM_LEN	0x18
-
-static unsigned int sys2gmem_vtx_pgm[SYS2GMEM_VTX_PGM_LEN] = {
-	0x00052003, 0x00001000, 0xc2000000, 0x00001005,
-	0x00001000, 0xc4000000, 0x00001006, 0x10071000,
-	0x20000000, 0x18981000, 0x0039ba88, 0x00000003,
-	0x12982000, 0x40257b08, 0x00000002, 0x140f803e,
-	0x00000000, 0xe2010100, 0x140f8000, 0x00000000,
-	0xe2020200, 0x14000000, 0x00000000, 0xe2000000
-};
-
-/* pre-compiled fragment shader program
-*
-*  precision mediump   float;
-*  uniform   sampler2D tex0;
-*  varying   vec4      texcoord0;
-*  void main()
-*  {
-*     gl_FragColor = texture2D(tex0, texcoord0.xy);
-*  }
-*/
-
-#define SYS2GMEM_FRAG_PGM_LEN	0x0f
-
-static unsigned int sys2gmem_frag_pgm[SYS2GMEM_FRAG_PGM_LEN] = {
-	0x00011002, 0x00001000, 0xc4000000, 0x00001003,
-	0x10041000, 0x20000000, 0x10000001, 0x1ffff688,
-	0x00000002, 0x140f8000, 0x00000000, 0xe2000000,
-	0x14000000, 0x00000000, 0xe2000000
-};
-
-/* shader texture constants (sysmem -> gmem)  */
-#define SYS2GMEM_TEX_CONST_LEN	6
-
-static unsigned int sys2gmem_tex_const[SYS2GMEM_TEX_CONST_LEN] = {
-	/* Texture, FormatXYZW=Unsigned, ClampXYZ=Wrap/Repeat,
-	 * RFMode=ZeroClamp-1, Dim=1:2d
-	 */
-	0x00000002,		/* Pitch = TBD */
-
-	/* Format=6:8888_WZYX, EndianSwap=0:None, ReqSize=0:256bit, DimHi=0,
-	 * NearestClamp=1:OGL Mode
-	 */
-	0x00000800,		/* Address[31:12] = TBD */
-
-	/* Width, Height, EndianSwap=0:None */
-	0,			/* Width & Height = TBD */
-
-	/* NumFormat=0:RF, DstSelXYZW=XYZW, ExpAdj=0, MagFilt=MinFilt=0:Point,
-	 * Mip=2:BaseMap
-	 */
-	0 << 1 | 1 << 4 | 2 << 7 | 3 << 10 | 2 << 23,
-
-	/* VolMag=VolMin=0:Point, MinMipLvl=0, MaxMipLvl=1, LodBiasH=V=0,
-	 * Dim3d=0
-	 */
-	0,
-
-	/* BorderColor=0:ABGRBlack, ForceBC=0:diable, TriJuice=0, Aniso=0,
-	 * Dim=1:2d, MipPacking=0
-	 */
-	1 << 9			/* Mip Address[31:12] = TBD */
-};
-
-/* quad for copying GMEM to context shadow */
-#define QUAD_LEN				12
-
-static unsigned int gmem_copy_quad[QUAD_LEN] = {
-	0x00000000, 0x00000000, 0x3f800000,
-	0x00000000, 0x00000000, 0x3f800000,
-	0x00000000, 0x00000000, 0x3f800000,
-	0x00000000, 0x00000000, 0x3f800000
-};
-
-#define TEXCOORD_LEN			8
-
-static unsigned int gmem_copy_texcoord[TEXCOORD_LEN] = {
-	0x00000000, 0x3f800000,
-	0x3f800000, 0x3f800000,
-	0x00000000, 0x00000000,
-	0x3f800000, 0x00000000
-};
-
-#define NUM_COLOR_FORMATS   13
-
-static enum SURFACEFORMAT surface_format_table[NUM_COLOR_FORMATS] = {
-	FMT_4_4_4_4,		/* COLORX_4_4_4_4 */
-	FMT_1_5_5_5,		/* COLORX_1_5_5_5 */
-	FMT_5_6_5,		/* COLORX_5_6_5 */
-	FMT_8,			/* COLORX_8 */
-	FMT_8_8,		/* COLORX_8_8 */
-	FMT_8_8_8_8,		/* COLORX_8_8_8_8 */
-	FMT_8_8_8_8,		/* COLORX_S8_8_8_8 */
-	FMT_16_FLOAT,		/* COLORX_16_FLOAT */
-	FMT_16_16_FLOAT,	/* COLORX_16_16_FLOAT */
-	FMT_16_16_16_16_FLOAT,	/* COLORX_16_16_16_16_FLOAT */
-	FMT_32_FLOAT,		/* COLORX_32_FLOAT */
-	FMT_32_32_FLOAT,	/* COLORX_32_32_FLOAT */
-	FMT_32_32_32_32_FLOAT,	/* COLORX_32_32_32_32_FLOAT */
-};
-
-static unsigned int format2bytesperpixel[NUM_COLOR_FORMATS] = {
-	2,			/* COLORX_4_4_4_4 */
-	2,			/* COLORX_1_5_5_5 */
-	2,			/* COLORX_5_6_5 */
-	1,			/* COLORX_8 */
-	2,			/* COLORX_8_8 8*/
-	4,			/* COLORX_8_8_8_8 */
-	4,			/* COLORX_S8_8_8_8 */
-	2,			/* COLORX_16_FLOAT */
-	4,			/* COLORX_16_16_FLOAT */
-	8,			/* COLORX_16_16_16_16_FLOAT */
-	4,			/* COLORX_32_FLOAT */
-	8,			/* COLORX_32_32_FLOAT */
-	16,			/* COLORX_32_32_32_32_FLOAT */
-};
-
-/* shader linkage info */
-#define SHADER_CONST_ADDR	(11 * 6 + 3)
-
-/* gmem command buffer length */
-#define PM4_REG(reg)		((0x4 << 16) | (GSL_HAL_SUBBLOCK_OFFSET(reg)))
-
-/* functions */
-static void config_gmemsize(struct gmem_shadow_t *shadow, int gmem_size)
-{
-	int w = 64, h = 64;	/* 16KB surface, minimum */
-
-	shadow->format = COLORX_8_8_8_8;
-	/* convert from bytes to 32-bit words */
-	gmem_size = (gmem_size + 3) / 4;
-
-	/* find the right surface size, close to a square. */
-	while (w * h < gmem_size)
-		if (w < h)
-			w *= 2;
-		else
-			h *= 2;
-
-	shadow->width = w;
-	shadow->pitch = w;
-	shadow->height = h;
-	shadow->gmem_pitch = shadow->pitch;
-
-	shadow->size = shadow->pitch * shadow->height * 4;
-}
-
-static unsigned int gpuaddr(unsigned int *cmd, struct kgsl_memdesc *memdesc)
-{
-	return memdesc->gpuaddr + ((char *)cmd - (char *)memdesc->hostptr);
-}
-
-static void
-create_ib1(struct kgsl_yamato_context *drawctxt, unsigned int *cmd,
-	   unsigned int *start, unsigned int *end)
-{
-	cmd[0] = PM4_HDR_INDIRECT_BUFFER_PFD;
-	cmd[1] = gpuaddr(start, &drawctxt->gpustate);
-	cmd[2] = end - start;
-}
-
-static unsigned int *program_shader(unsigned int *cmds, int vtxfrag,
-				    unsigned int *shader_pgm, int dwords)
-{
-	/* load the patched vertex shader stream */
-	*cmds++ = pm4_type3_packet(PM4_IM_LOAD_IMMEDIATE, 2 + dwords);
-	/* 0=vertex shader, 1=fragment shader */
-	*cmds++ = vtxfrag;
-	/* instruction start & size (in 32-bit words) */
-	*cmds++ = ((0 << 16) | dwords);
-
-	memcpy(cmds, shader_pgm, dwords << 2);
-	cmds += dwords;
-
-	return cmds;
-}
-
-static unsigned int *reg_to_mem(unsigned int *cmds, uint32_t dst,
-				uint32_t src, int dwords)
-{
-	while (dwords-- > 0) {
-		*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-		*cmds++ = src++;
-		*cmds++ = dst;
-		dst += 4;
-	}
-
-	return cmds;
-}
-
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-
-static void build_reg_to_mem_range(unsigned int start, unsigned int end,
-				   unsigned int **cmd,
-				   struct kgsl_yamato_context *drawctxt)
-{
-	unsigned int i = start;
-
-	for (i = start; i <= end; i++) {
-		*(*cmd)++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-		*(*cmd)++ = i;
-		*(*cmd)++ =
-		    ((drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000) +
-		    (i - 0x2000) * 4;
-	}
-}
-
-#endif
-
-/* chicken restore */
-static unsigned int *build_chicken_restore_cmds(
-					struct kgsl_yamato_context *drawctxt,
-					struct tmp_ctx *ctx)
-{
-	unsigned int *start = ctx->cmd;
-	unsigned int *cmds = start;
-
-	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmds++ = 0;
-
-	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
-	ctx->chicken_restore = gpuaddr(cmds, &drawctxt->gpustate);
-	*cmds++ = 0x00000000;
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->chicken_restore, start, cmds);
-
-	return cmds;
-}
-
-/* save h/w regs, alu constants, texture contants, etc. ...
-*  requires: bool_shadow_gpuaddr, loop_shadow_gpuaddr
-*/
-static void build_regsave_cmds(struct kgsl_device *device,
-			       struct kgsl_yamato_context *drawctxt,
-			       struct tmp_ctx *ctx)
-{
-	unsigned int *start = ctx->cmd;
-	unsigned int *cmd = start;
-
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	/* Make sure the HW context has the correct register values
-	 * before reading them. */
-	*cmd++ = pm4_type3_packet(PM4_CONTEXT_UPDATE, 1);
-	*cmd++ = 0;
-#endif
-
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	/* Write HW registers into shadow */
-	build_reg_to_mem_range(REG_RB_SURFACE_INFO, REG_RB_DEPTH_INFO,
-				&cmd, drawctxt);
-	build_reg_to_mem_range(REG_COHER_DEST_BASE_0,
-				REG_PA_SC_SCREEN_SCISSOR_BR,
-				&cmd, drawctxt);
-	build_reg_to_mem_range(REG_PA_SC_WINDOW_OFFSET,
-				REG_PA_SC_WINDOW_SCISSOR_BR,
-				&cmd, drawctxt);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		build_reg_to_mem_range(REG_VGT_MAX_VTX_INDX, REG_RB_FOG_COLOR,
-				&cmd, drawctxt);
-	} else {
-		build_reg_to_mem_range(REG_LEIA_PC_MAX_VTX_INDX,
-				REG_LEIA_PC_INDX_OFFSET,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_RB_COLOR_MASK,
-				REG_RB_FOG_COLOR,
-				&cmd, drawctxt);
-	}
-	build_reg_to_mem_range(REG_RB_STENCILREFMASK_BF,
-				REG_PA_CL_VPORT_ZOFFSET,
-				&cmd, drawctxt);
-	build_reg_to_mem_range(REG_SQ_PROGRAM_CNTL, REG_SQ_WRAPPING_1,
-				&cmd, drawctxt);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		build_reg_to_mem_range(REG_RB_DEPTHCONTROL, REG_RB_MODECONTROL,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_PA_SU_POINT_SIZE,
-				REG_PA_SC_LINE_STIPPLE,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_PA_SC_VIZ_QUERY, REG_PA_SC_VIZ_QUERY,
-				&cmd, drawctxt);
-	} else {
-		build_reg_to_mem_range(REG_RB_DEPTHCONTROL,
-				REG_RB_COLORCONTROL,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_PA_CL_CLIP_CNTL,
-				REG_PA_CL_VTE_CNTL,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_RB_MODECONTROL,
-				REG_LEIA_GRAS_CONTROL,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_PA_SU_POINT_SIZE,
-				REG_PA_SU_LINE_CNTL,
-				&cmd, drawctxt);
-	}
-	build_reg_to_mem_range(REG_PA_SC_LINE_CNTL, REG_SQ_PS_CONST,
-				&cmd, drawctxt);
-	build_reg_to_mem_range(REG_PA_SC_AA_MASK, REG_PA_SC_AA_MASK,
-				&cmd, drawctxt);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		build_reg_to_mem_range(REG_VGT_VERTEX_REUSE_BLOCK_CNTL,
-				REG_RB_DEPTH_CLEAR,
-				&cmd, drawctxt);
-	} else {
-		build_reg_to_mem_range(REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
-				REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
-				&cmd, drawctxt);
-		build_reg_to_mem_range(REG_RB_COPY_CONTROL,
-				REG_RB_DEPTH_CLEAR,
-				&cmd, drawctxt);
-	}
-	build_reg_to_mem_range(REG_RB_SAMPLE_COUNT_CTL,
-				REG_RB_COLOR_DEST_MASK,
-				&cmd, drawctxt);
-	build_reg_to_mem_range(REG_PA_SU_POLY_OFFSET_FRONT_SCALE,
-				REG_PA_SU_POLY_OFFSET_BACK_OFFSET,
-				&cmd, drawctxt);
-
-	/* Copy ALU constants */
-	cmd =
-	    reg_to_mem(cmd, (drawctxt->gpustate.gpuaddr) & 0xFFFFE000,
-		       REG_SQ_CONSTANT_0, ALU_CONSTANTS);
-
-	/* Copy Tex constants */
-	cmd =
-	    reg_to_mem(cmd,
-		       (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000,
-		       REG_SQ_FETCH_0, TEX_CONSTANTS);
-#else
-
-	/* Insert a wait for idle packet before reading the registers.
-	 * This is to fix a hang/reset seen during stress testing.  In this
-	 * hang, CP encountered a timeout reading SQ's boolean constant
-	 * register. There is logic in the HW that blocks reading of this
-	 * register when the SQ block is not idle, which we believe is
-	 * contributing to the hang.*/
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-
-	/* H/w registers are already shadowed; just need to disable shadowing
-	 * to prevent corruption.
-	 */
-	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
-	*cmd++ = (drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000;
-	*cmd++ = 4 << 16;	/* regs, start=0 */
-	*cmd++ = 0x0;		/* count = 0 */
-
-	/* ALU constants are already shadowed; just need to disable shadowing
-	 * to prevent corruption.
-	 */
-	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
-	*cmd++ = drawctxt->gpustate.gpuaddr & 0xFFFFE000;
-	*cmd++ = 0 << 16;	/* ALU, start=0 */
-	*cmd++ = 0x0;		/* count = 0 */
-
-	/* Tex constants are already shadowed; just need to disable shadowing
-	 *  to prevent corruption.
-	 */
-	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
-	*cmd++ = (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000;
-	*cmd++ = 1 << 16;	/* Tex, start=0 */
-	*cmd++ = 0x0;		/* count = 0 */
-#endif
-
-	/* Need to handle some of the registers separately */
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_SQ_GPR_MANAGEMENT;
-	*cmd++ = ctx->reg_values[0];
-
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_TP0_CHICKEN;
-	*cmd++ = ctx->reg_values[1];
-
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_RBBM_PM_OVERRIDE2;
-	*cmd++ = ctx->reg_values[2];
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		unsigned int i;
-		unsigned int j = 3;
-		for (i = REG_LEIA_VSC_BIN_SIZE; i <=
-				REG_LEIA_VSC_PIPE_DATA_LENGTH_7; i++) {
-			*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-			*cmd++ = i;
-			*cmd++ = ctx->reg_values[j];
-			j++;
-		}
-	}
-
-	/* Copy Boolean constants */
-	cmd = reg_to_mem(cmd, ctx->bool_shadow, REG_SQ_CF_BOOLEANS,
-			 BOOL_CONSTANTS);
-
-	/* Copy Loop constants */
-	cmd = reg_to_mem(cmd, ctx->loop_shadow, REG_SQ_CF_LOOP, LOOP_CONSTANTS);
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->reg_save, start, cmd);
-
-	ctx->cmd = cmd;
-}
-
-/*copy colour, depth, & stencil buffers from graphics memory to system memory*/
-static unsigned int *build_gmem2sys_cmds(struct kgsl_device *device,
-					 struct kgsl_yamato_context *drawctxt,
-					 struct tmp_ctx *ctx,
-					 struct gmem_shadow_t *shadow)
-{
-	unsigned int *cmds = shadow->gmem_save_commands;
-	unsigned int *start = cmds;
-	/* Calculate the new offset based on the adjusted base */
-	unsigned int bytesperpixel = format2bytesperpixel[shadow->format];
-	unsigned int addr = shadow->gmemshadow.gpuaddr;
-	unsigned int offset = (addr - (addr & 0xfffff000)) / bytesperpixel;
-
-	/* Store TP0_CHICKEN register */
-	*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmds++ = REG_TP0_CHICKEN;
-	if (ctx)
-		*cmds++ = ctx->chicken_restore;
-	else
-		cmds++;
-
-	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmds++ = 0;
-
-	/* Set TP0_CHICKEN to zero */
-	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
-	*cmds++ = 0x00000000;
-
-	/* Set PA_SC_AA_CONFIG to 0 */
-	*cmds++ = pm4_type0_packet(REG_PA_SC_AA_CONFIG, 1);
-	*cmds++ = 0x00000000;
-
-	/* program shader */
-
-	/* load shader vtx constants ... 5 dwords */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
-	*cmds++ = (0x1 << 16) | SHADER_CONST_ADDR;
-	*cmds++ = 0;
-	/* valid(?) vtx constant flag & addr */
-	*cmds++ = shadow->quad_vertices.gpuaddr | 0x3;
-	/* limit = 12 dwords */
-	*cmds++ = 0x00000030;
-
-	/* Invalidate L2 cache to make sure vertices are updated */
-	*cmds++ = pm4_type0_packet(REG_TC_CNTL_STATUS, 1);
-	*cmds++ = 0x1;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
-	*cmds++ = PM4_REG(REG_VGT_MAX_VTX_INDX);
-	*cmds++ = 0x00ffffff;	/* REG_VGT_MAX_VTX_INDX */
-	*cmds++ = 0x0;		/* REG_VGT_MIN_VTX_INDX */
-	*cmds++ = 0x00000000;	/* REG_VGT_INDX_OFFSET */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_SC_AA_MASK);
-	*cmds++ = 0x0000ffff;	/* REG_PA_SC_AA_MASK */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLORCONTROL);
-	*cmds++ = 0x00000c20;
-
-	/* load the patched vertex shader stream */
-	cmds = program_shader(cmds, 0, gmem2sys_vtx_pgm, GMEM2SYS_VTX_PGM_LEN);
-
-	/* Load the patched fragment shader stream */
-	cmds =
-	    program_shader(cmds, 1, gmem2sys_frag_pgm, GMEM2SYS_FRAG_PGM_LEN);
-
-	/* SQ_PROGRAM_CNTL / SQ_CONTEXT_MISC */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_SQ_PROGRAM_CNTL);
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		*cmds++ = 0x10018001;
-	else
-		*cmds++ = 0x10010001;
-	*cmds++ = 0x00000008;
-
-	/* resolve */
-
-	/* PA_CL_VTE_CNTL */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_CL_VTE_CNTL);
-	/* disable X/Y/Z transforms, X/Y/Z are premultiplied by W */
-	*cmds++ = 0x00000b00;
-
-	/* program surface info */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_RB_SURFACE_INFO);
-	*cmds++ = shadow->gmem_pitch;	/* pitch, MSAA = 1 */
-
-	/* RB_COLOR_INFO Endian=none, Linear, Format=RGBA8888, Swap=0,
-	 *                Base=gmem_base
-	 */
-	/* gmem base assumed 4K aligned. */
-	if (ctx) {
-		BUG_ON(ctx->gmem_base & 0xFFF);
-		*cmds++ =
-		    (shadow->
-		     format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT) | ctx->
-		    gmem_base;
-	} else {
-		unsigned int temp = *cmds;
-		*cmds++ = (temp & ~RB_COLOR_INFO__COLOR_FORMAT_MASK) |
-			(shadow->format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT);
-	}
-
-	/* disable Z */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_DEPTHCONTROL);
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		*cmds++ = 0x08;
-	else
-		*cmds++ = 0;
-
-	/* set REG_PA_SU_SC_MODE_CNTL
-	 *              Front_ptype = draw triangles
-	 *              Back_ptype = draw triangles
-	 *              Provoking vertex = last
-	 */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_SU_SC_MODE_CNTL);
-	*cmds++ = 0x00080240;
-
-	/* Use maximum scissor values -- quad vertices already have the
-	 * correct bounds */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_SC_SCREEN_SCISSOR_TL);
-	*cmds++ = (0 << 16) | 0;
-	*cmds++ = (0x1fff << 16) | (0x1fff);
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_SC_WINDOW_SCISSOR_TL);
-	*cmds++ = (unsigned int)((1U << 31) | (0 << 16) | 0);
-	*cmds++ = (0x1fff << 16) | (0x1fff);
-
-	/* load the viewport so that z scale = clear depth and
-	 *  z offset = 0.0f
-	 */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_CL_VPORT_ZSCALE);
-	*cmds++ = 0xbf800000;	/* -1.0f */
-	*cmds++ = 0x0;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLOR_MASK);
-	*cmds++ = 0x0000000f;	/* R = G = B = 1:enabled */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLOR_DEST_MASK);
-	*cmds++ = 0xffffffff;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_SQ_WRAPPING_0);
-	*cmds++ = 0x00000000;
-	*cmds++ = 0x00000000;
-
-	/* load the stencil ref value
-	 * $AAM - do this later
-	 */
-
-	/* load the COPY state */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 6);
-	*cmds++ = PM4_REG(REG_RB_COPY_CONTROL);
-	*cmds++ = 0;		/* RB_COPY_CONTROL */
-	*cmds++ = addr & 0xfffff000;	/* RB_COPY_DEST_BASE */
-	*cmds++ = shadow->pitch >> 5;	/* RB_COPY_DEST_PITCH */
-
-	/* Endian=none, Linear, Format=RGBA8888,Swap=0,!Dither,
-	 *  MaskWrite:R=G=B=A=1
-	 */
-	*cmds++ = 0x0003c008 |
-	    (shadow->format << RB_COPY_DEST_INFO__COPY_DEST_FORMAT__SHIFT);
-	/* Make sure we stay in offsetx field. */
-	BUG_ON(offset & 0xfffff000);
-	*cmds++ = offset;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_MODECONTROL);
-	*cmds++ = 0x6;		/* EDRAM copy */
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-		*cmds++ = PM4_REG(REG_LEIA_RB_LRZ_VSC_CONTROL);
-		*cmds++ = 0;
-	}
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_CL_CLIP_CNTL);
-	*cmds++ = 0x00010000;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		*cmds++ = 0xc0043600; /* packet 3 3D_DRAW_INDX_2 */
-		*cmds++ = 0x0;
-		*cmds++ = 0x00004046; /* tristrip */
-		*cmds++ = 0x00000004; /* NUM_INDICES */
-		*cmds++ = 0x00010000; /* index: 0x00, 0x01 */
-		*cmds++ = 0x00030002; /* index: 0x02, 0x03 */
-	} else {
-		/* queue the draw packet */
-		*cmds++ = pm4_type3_packet(PM4_DRAW_INDX, 2);
-		*cmds++ = 0;		/* viz query info. */
-		/* PrimType=RectList, NumIndices=3, SrcSel=AutoIndex */
-		*cmds++ = 0x00030088;
-	}
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, shadow->gmem_save, start, cmds);
-
-	return cmds;
-}
-
-/* context restore */
-
-/*copy colour, depth, & stencil buffers from system memory to graphics memory*/
-static unsigned int *build_sys2gmem_cmds(struct kgsl_device *device,
-					 struct kgsl_yamato_context *drawctxt,
-					 struct tmp_ctx *ctx,
-					 struct gmem_shadow_t *shadow)
-{
-	unsigned int *cmds = shadow->gmem_restore_commands;
-	unsigned int *start = cmds;
-
-	/* Store TP0_CHICKEN register */
-	*cmds++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmds++ = REG_TP0_CHICKEN;
-	if (ctx)
-		*cmds++ = ctx->chicken_restore;
-	else
-		cmds++;
-
-	*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmds++ = 0;
-
-	/* Set TP0_CHICKEN to zero */
-	*cmds++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
-	*cmds++ = 0x00000000;
-
-	/* Set PA_SC_AA_CONFIG to 0 */
-	*cmds++ = pm4_type0_packet(REG_PA_SC_AA_CONFIG, 1);
-	*cmds++ = 0x00000000;
-	/* shader constants */
-
-	/* vertex buffer constants */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 7);
-
-	*cmds++ = (0x1 << 16) | (9 * 6);
-	/* valid(?) vtx constant flag & addr */
-	*cmds++ = shadow->quad_vertices.gpuaddr | 0x3;
-	/* limit = 12 dwords */
-	*cmds++ = 0x00000030;
-	/* valid(?) vtx constant flag & addr */
-	*cmds++ = shadow->quad_texcoords.gpuaddr | 0x3;
-	/* limit = 8 dwords */
-	*cmds++ = 0x00000020;
-	*cmds++ = 0;
-	*cmds++ = 0;
-
-	/* Invalidate L2 cache to make sure vertices are updated */
-	*cmds++ = pm4_type0_packet(REG_TC_CNTL_STATUS, 1);
-	*cmds++ = 0x1;
-
-	cmds = program_shader(cmds, 0, sys2gmem_vtx_pgm, SYS2GMEM_VTX_PGM_LEN);
-
-	/* Load the patched fragment shader stream */
-	cmds =
-	    program_shader(cmds, 1, sys2gmem_frag_pgm, SYS2GMEM_FRAG_PGM_LEN);
-
-	/* SQ_PROGRAM_CNTL / SQ_CONTEXT_MISC */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_SQ_PROGRAM_CNTL);
-	*cmds++ = 0x10030002;
-	*cmds++ = 0x00000008;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_SC_AA_MASK);
-	*cmds++ = 0x0000ffff;	/* REG_PA_SC_AA_MASK */
-
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		/* PA_SC_VIZ_QUERY */
-		*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-		*cmds++ = PM4_REG(REG_PA_SC_VIZ_QUERY);
-		*cmds++ = 0x0;		/*REG_PA_SC_VIZ_QUERY */
-	}
-
-	/* RB_COLORCONTROL */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLORCONTROL);
-	*cmds++ = 0x00000c20;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 4);
-	*cmds++ = PM4_REG(REG_VGT_MAX_VTX_INDX);
-	*cmds++ = 0x00ffffff;	/* mmVGT_MAX_VTX_INDX */
-	*cmds++ = 0x0;		/* mmVGT_MIN_VTX_INDX */
-	*cmds++ = 0x00000000;	/* mmVGT_INDX_OFFSET */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_VGT_VERTEX_REUSE_BLOCK_CNTL);
-	*cmds++ = 0x00000002;	/* mmVGT_VERTEX_REUSE_BLOCK_CNTL */
-	*cmds++ = 0x00000002;	/* mmVGT_OUT_DEALLOC_CNTL */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_SQ_INTERPOLATOR_CNTL);
-	//*cmds++ = 0x0000ffff; //mmSQ_INTERPOLATOR_CNTL
-	*cmds++ = 0xffffffff;	//mmSQ_INTERPOLATOR_CNTL
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_SC_AA_CONFIG);
-	*cmds++ = 0x00000000;	/* REG_PA_SC_AA_CONFIG */
-
-	/* set REG_PA_SU_SC_MODE_CNTL
-	 * Front_ptype = draw triangles
-	 * Back_ptype = draw triangles
-	 * Provoking vertex = last
-	 */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_SU_SC_MODE_CNTL);
-	*cmds++ = 0x00080240;
-
-	/* texture constants */
-	*cmds++ =
-	    pm4_type3_packet(PM4_SET_CONSTANT, (SYS2GMEM_TEX_CONST_LEN + 1));
-	*cmds++ = (0x1 << 16) | (0 * 6);
-	memcpy(cmds, sys2gmem_tex_const, SYS2GMEM_TEX_CONST_LEN << 2);
-	cmds[0] |= (shadow->pitch >> 5) << 22;
-	cmds[1] |=
-	    shadow->gmemshadow.gpuaddr | surface_format_table[shadow->format];
-	cmds[2] |= (shadow->width - 1) | (shadow->height - 1) << 13;
-	cmds += SYS2GMEM_TEX_CONST_LEN;
-
-	/* program surface info */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_RB_SURFACE_INFO);
-	*cmds++ = shadow->gmem_pitch;	/* pitch, MSAA = 1 */
-
-	/* RB_COLOR_INFO Endian=none, Linear, Format=RGBA8888, Swap=0,
-	 *                Base=gmem_base
-	 */
-	if (ctx)
-		*cmds++ =
-		    (shadow->
-		     format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT) | ctx->
-		    gmem_base;
-	else {
-		unsigned int temp = *cmds;
-		*cmds++ = (temp & ~RB_COLOR_INFO__COLOR_FORMAT_MASK) |
-			(shadow->format << RB_COLOR_INFO__COLOR_FORMAT__SHIFT);
-	}
-
-	/* RB_DEPTHCONTROL */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_DEPTHCONTROL);
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		*cmds++ = 8;		/* disable Z */
-	else
-		*cmds++ = 0;		/* disable Z */
-
-	/* Use maximum scissor values -- quad vertices already
-	 * have the correct bounds */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_SC_SCREEN_SCISSOR_TL);
-	*cmds++ = (0 << 16) | 0;
-	*cmds++ = ((0x1fff) << 16) | 0x1fff;
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_SC_WINDOW_SCISSOR_TL);
-	*cmds++ = (unsigned int)((1U << 31) | (0 << 16) | 0);
-	*cmds++ = ((0x1fff) << 16) | 0x1fff;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_CL_VTE_CNTL);
-	/* disable X/Y/Z transforms, X/Y/Z are premultiplied by W */
-	*cmds++ = 0x00000b00;
-
-	/*load the viewport so that z scale = clear depth and z offset = 0.0f */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_PA_CL_VPORT_ZSCALE);
-	*cmds++ = 0xbf800000;
-	*cmds++ = 0x0;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLOR_MASK);
-	*cmds++ = 0x0000000f;	/* R = G = B = 1:enabled */
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_COLOR_DEST_MASK);
-	*cmds++ = 0xffffffff;
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 3);
-	*cmds++ = PM4_REG(REG_SQ_WRAPPING_0);
-	*cmds++ = 0x00000000;
-	*cmds++ = 0x00000000;
-
-	/* load the stencil ref value
-	 *  $AAM - do this later
-	 */
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_RB_MODECONTROL);
-	/* draw pixels with color and depth/stencil component */
-	*cmds++ = 0x4;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-		*cmds++ = PM4_REG(REG_LEIA_RB_LRZ_VSC_CONTROL);
-		*cmds++ = 0;
-	}
-
-	*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-	*cmds++ = PM4_REG(REG_PA_CL_CLIP_CNTL);
-	*cmds++ = 0x00010000;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		*cmds++ = 0xc0043600; /* packet 3 3D_DRAW_INDX_2 */
-		*cmds++ = 0x0;
-		*cmds++ = 0x00004046; /* tristrip */
-		*cmds++ = 0x00000004; /* NUM_INDICES */
-		*cmds++ = 0x00010000; /* index: 0x00, 0x01 */
-		*cmds++ = 0x00030002; /* index: 0x02, 0x03 */
-	} else {
-		/* queue the draw packet */
-		*cmds++ = pm4_type3_packet(PM4_DRAW_INDX, 2);
-		*cmds++ = 0;		/* viz query info. */
-		/* PrimType=RectList, NumIndices=3, SrcSel=AutoIndex */
-		*cmds++ = 0x00030088;
-	}
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, shadow->gmem_restore, start, cmds);
-
-	return cmds;
-}
-
-/* restore h/w regs, alu constants, texture constants, etc. ... */
-static unsigned *reg_range(unsigned int *cmd, unsigned int start,
-			   unsigned int end)
-{
-	*cmd++ = PM4_REG(start);	/* h/w regs, start addr */
-	*cmd++ = end - start + 1;	/* count */
-	return cmd;
-}
-
-static void build_regrestore_cmds(struct kgsl_device *device,
-				  struct kgsl_yamato_context *drawctxt,
-				  struct tmp_ctx *ctx)
-{
-	unsigned int *start = ctx->cmd;
-	unsigned int *cmd = start;
-
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-
-	/* H/W Registers */
-	/* deferred pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, ???); */
-	cmd++;
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	/* Force mismatch */
-	*cmd++ = ((drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000) | 1;
-#else
-	*cmd++ = (drawctxt->gpustate.gpuaddr + REG_OFFSET) & 0xFFFFE000;
-#endif
-
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		cmd = reg_range(cmd, REG_RB_SURFACE_INFO,
-				REG_PA_SC_SCREEN_SCISSOR_BR);
-	} else {
-		cmd = reg_range(cmd, REG_RB_SURFACE_INFO, REG_RB_DEPTH_INFO);
-		cmd = reg_range(cmd, REG_COHER_DEST_BASE_0,
-				REG_PA_SC_SCREEN_SCISSOR_BR);
-	}
-	cmd = reg_range(cmd, REG_PA_SC_WINDOW_OFFSET,
-				REG_PA_SC_WINDOW_SCISSOR_BR);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		cmd = reg_range(cmd, REG_VGT_MAX_VTX_INDX,
-				REG_PA_CL_VPORT_ZOFFSET);
-	} else {
-		cmd = reg_range(cmd, REG_LEIA_PC_MAX_VTX_INDX,
-				REG_LEIA_PC_INDX_OFFSET);
-		cmd = reg_range(cmd, REG_RB_COLOR_MASK, REG_RB_FOG_COLOR);
-		cmd = reg_range(cmd, REG_RB_STENCILREFMASK_BF,
-				REG_PA_CL_VPORT_ZOFFSET);
-	}
-	cmd = reg_range(cmd, REG_SQ_PROGRAM_CNTL, REG_SQ_WRAPPING_1);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		cmd = reg_range(cmd, REG_RB_DEPTHCONTROL, REG_RB_MODECONTROL);
-		cmd = reg_range(cmd, REG_PA_SU_POINT_SIZE,
-				REG_PA_SC_VIZ_QUERY); /*REG_VGT_ENHANCE */
-		cmd = reg_range(cmd, REG_PA_SC_LINE_CNTL,
-				REG_RB_COLOR_DEST_MASK);
-	} else {
-		cmd = reg_range(cmd, REG_RB_DEPTHCONTROL, REG_RB_COLORCONTROL);
-		cmd = reg_range(cmd, REG_PA_CL_CLIP_CNTL, REG_PA_CL_VTE_CNTL);
-		cmd = reg_range(cmd, REG_RB_MODECONTROL, REG_LEIA_GRAS_CONTROL);
-		cmd = reg_range(cmd, REG_PA_SU_POINT_SIZE, REG_PA_SU_LINE_CNTL);
-		cmd = reg_range(cmd, REG_PA_SC_LINE_CNTL, REG_SQ_PS_CONST);
-		cmd = reg_range(cmd, REG_PA_SC_AA_MASK, REG_PA_SC_AA_MASK);
-		cmd = reg_range(cmd, REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL,
-				REG_LEIA_PC_VERTEX_REUSE_BLOCK_CNTL);
-		cmd = reg_range(cmd, REG_RB_COPY_CONTROL, REG_RB_DEPTH_CLEAR);
-		cmd = reg_range(cmd, REG_RB_SAMPLE_COUNT_CTL,
-				REG_RB_COLOR_DEST_MASK);
-	}
-	cmd = reg_range(cmd, REG_PA_SU_POLY_OFFSET_FRONT_SCALE,
-				REG_PA_SU_POLY_OFFSET_BACK_OFFSET);
-
-	/* Now we know how many register blocks we have, we can compute command
-	 * length
-	 */
-	start[2] =
-	    pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, (cmd - start) - 3);
-	/* Enable shadowing for the entire register block. */
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	start[4] |= (0 << 24) | (4 << 16);	/* Disable shadowing. */
-#else
-	start[4] |= (1 << 24) | (4 << 16);
-#endif
-
-	/* Need to handle some of the registers separately */
-	*cmd++ = pm4_type0_packet(REG_SQ_GPR_MANAGEMENT, 1);
-	ctx->reg_values[0] = gpuaddr(cmd, &drawctxt->gpustate);
-	*cmd++ = 0x00040400;
-
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-	*cmd++ = pm4_type0_packet(REG_TP0_CHICKEN, 1);
-	ctx->reg_values[1] = gpuaddr(cmd, &drawctxt->gpustate);
-	*cmd++ = 0x00000000;
-
-	*cmd++ = pm4_type0_packet(REG_RBBM_PM_OVERRIDE2, 1);
-	ctx->reg_values[2] = gpuaddr(cmd, &drawctxt->gpustate);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
-		*cmd++ = 0x00000000;
-	else
-		*cmd++ = 0x80;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		unsigned int i;
-		unsigned int j = 3;
-		for (i = REG_LEIA_VSC_BIN_SIZE; i <=
-				REG_LEIA_VSC_PIPE_DATA_LENGTH_7; i++) {
-			*cmd++ = pm4_type0_packet(i, 1);
-			ctx->reg_values[j] = gpuaddr(cmd, &drawctxt->gpustate);
-			*cmd++ = 0x00000000;
-			j++;
-		}
-	}
-
-	/* ALU Constants */
-	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
-	*cmd++ = drawctxt->gpustate.gpuaddr & 0xFFFFE000;
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	*cmd++ = (0 << 24) | (0 << 16) | 0;	/* Disable shadowing */
-#else
-	*cmd++ = (1 << 24) | (0 << 16) | 0;
-#endif
-	*cmd++ = ALU_CONSTANTS;
-
-	/* Texture Constants */
-	*cmd++ = pm4_type3_packet(PM4_LOAD_CONSTANT_CONTEXT, 3);
-	*cmd++ = (drawctxt->gpustate.gpuaddr + TEX_OFFSET) & 0xFFFFE000;
-#ifdef CONFIG_MSM_KGSL_DISABLE_SHADOW_WRITES
-	/* Disable shadowing */
-	*cmd++ = (0 << 24) | (1 << 16) | 0;
-#else
-	*cmd++ = (1 << 24) | (1 << 16) | 0;
-#endif
-	*cmd++ = TEX_CONSTANTS;
-
-	/* Boolean Constants */
-	*cmd++ = pm4_type3_packet(PM4_SET_CONSTANT, 1 + BOOL_CONSTANTS);
-	*cmd++ = (2 << 16) | 0;
-
-	/* the next BOOL_CONSTANT dwords is the shadow area for
-	 *  boolean constants.
-	 */
-	ctx->bool_shadow = gpuaddr(cmd, &drawctxt->gpustate);
-	cmd += BOOL_CONSTANTS;
-
-	/* Loop Constants */
-	*cmd++ = pm4_type3_packet(PM4_SET_CONSTANT, 1 + LOOP_CONSTANTS);
-	*cmd++ = (3 << 16) | 0;
-
-	/* the next LOOP_CONSTANTS dwords is the shadow area for
-	 * loop constants.
-	 */
-	ctx->loop_shadow = gpuaddr(cmd, &drawctxt->gpustate);
-	cmd += LOOP_CONSTANTS;
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->reg_restore, start, cmd);
-
-	ctx->cmd = cmd;
-}
-
-/* quad for saving/restoring gmem */
-static void set_gmem_copy_quad(struct gmem_shadow_t *shadow)
-{
-	/* set vertex buffer values */
-	gmem_copy_quad[1] = uint2float(shadow->height);
-	gmem_copy_quad[3] = uint2float(shadow->width);
-	gmem_copy_quad[4] = uint2float(shadow->height);
-	gmem_copy_quad[9] = uint2float(shadow->width);
-
-	gmem_copy_quad[0] = uint2float(0);
-	gmem_copy_quad[6] = uint2float(0);
-	gmem_copy_quad[7] = uint2float(0);
-	gmem_copy_quad[10] = uint2float(0);
-
-	memcpy(shadow->quad_vertices.hostptr, gmem_copy_quad, QUAD_LEN << 2);
-
-	memcpy(shadow->quad_texcoords.hostptr, gmem_copy_texcoord,
-	       TEXCOORD_LEN << 2);
-}
-
-/* quad for saving/restoring gmem */
-static void build_quad_vtxbuff(struct kgsl_yamato_context *drawctxt,
-		       struct tmp_ctx *ctx, struct gmem_shadow_t *shadow)
-{
-	unsigned int *cmd = ctx->cmd;
-
-	/* quad vertex buffer location (in GPU space) */
-	shadow->quad_vertices.hostptr = cmd;
-	shadow->quad_vertices.gpuaddr = gpuaddr(cmd, &drawctxt->gpustate);
-
-	cmd += QUAD_LEN;
-
-	/* tex coord buffer location (in GPU space) */
-	shadow->quad_texcoords.hostptr = cmd;
-	shadow->quad_texcoords.gpuaddr = gpuaddr(cmd, &drawctxt->gpustate);
-
-	cmd += TEXCOORD_LEN;
-
-	set_gmem_copy_quad(shadow);
-
-	ctx->cmd = cmd;
-}
-
-static void
-build_shader_save_restore_cmds(struct kgsl_yamato_context *drawctxt,
-			       struct tmp_ctx *ctx)
-{
-	unsigned int *cmd = ctx->cmd;
-	unsigned int *save, *restore, *fixup;
-#if defined(PM4_IM_STORE)
-	unsigned int *startSizeVtx, *startSizePix, *startSizeShared;
-#endif
-	unsigned int *partition1;
-	unsigned int *shaderBases, *partition2;
-
-#if defined(PM4_IM_STORE)
-	/* compute vertex, pixel and shared instruction shadow GPU addresses */
-	ctx->shader_vertex = drawctxt->gpustate.gpuaddr + SHADER_OFFSET;
-	ctx->shader_pixel = ctx->shader_vertex + SHADER_SHADOW_SIZE;
-	ctx->shader_shared = ctx->shader_pixel + SHADER_SHADOW_SIZE;
-#endif
-
-	/* restore shader partitioning and instructions */
-
-	restore = cmd;		/* start address */
-
-	/* Invalidate Vertex & Pixel instruction code address and sizes */
-	*cmd++ = pm4_type3_packet(PM4_INVALIDATE_STATE, 1);
-	*cmd++ = 0x00000300;	/* 0x100 = Vertex, 0x200 = Pixel */
-
-	/* Restore previous shader vertex & pixel instruction bases. */
-	*cmd++ = pm4_type3_packet(PM4_SET_SHADER_BASES, 1);
-	shaderBases = cmd++;	/* TBD #5: shader bases (from fixup) */
-
-	/* write the shader partition information to a scratch register */
-	*cmd++ = pm4_type0_packet(REG_SQ_INST_STORE_MANAGMENT, 1);
-	partition1 = cmd++;	/* TBD #4a: partition info (from save) */
-
-#if defined(PM4_IM_STORE)
-	/* load vertex shader instructions from the shadow. */
-	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
-	*cmd++ = ctx->shader_vertex + 0x0;	/* 0x0 = Vertex */
-	startSizeVtx = cmd++;	/* TBD #1: start/size (from save) */
-
-	/* load pixel shader instructions from the shadow. */
-	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
-	*cmd++ = ctx->shader_pixel + 0x1;	/* 0x1 = Pixel */
-	startSizePix = cmd++;	/* TBD #2: start/size (from save) */
-
-	/* load shared shader instructions from the shadow. */
-	*cmd++ = pm4_type3_packet(PM4_IM_LOAD, 2);
-	*cmd++ = ctx->shader_shared + 0x2;	/* 0x2 = Shared */
-	startSizeShared = cmd++;	/* TBD #3: start/size (from save) */
-#endif
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->shader_restore, restore, cmd);
-
-	/*
-	 *  fixup SET_SHADER_BASES data
-	 *
-	 *  since self-modifying PM4 code is being used here, a seperate
-	 *  command buffer is used for this fixup operation, to ensure the
-	 *  commands are not read by the PM4 engine before the data fields
-	 *  have been written.
-	 */
-
-	fixup = cmd;		/* start address */
-
-	/* write the shader partition information to a scratch register */
-	*cmd++ = pm4_type0_packet(REG_SCRATCH_REG2, 1);
-	partition2 = cmd++;	/* TBD #4b: partition info (from save) */
-
-	/* mask off unused bits, then OR with shader instruction memory size */
-	*cmd++ = pm4_type3_packet(PM4_REG_RMW, 3);
-	*cmd++ = REG_SCRATCH_REG2;
-	/* AND off invalid bits. */
-	*cmd++ = 0x0FFF0FFF;
-	/* OR in instruction memory size */
-	*cmd++ = (unsigned int)((SHADER_INSTRUCT_LOG2 - 5U) << 29);
-
-	/* write the computed value to the SET_SHADER_BASES data field */
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_SCRATCH_REG2;
-	/* TBD #5: shader bases (to restore) */
-	*cmd++ = gpuaddr(shaderBases, &drawctxt->gpustate);
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->shader_fixup, fixup, cmd);
-
-	/* save shader partitioning and instructions */
-
-	save = cmd;		/* start address */
-
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-
-	/* fetch the SQ_INST_STORE_MANAGMENT register value,
-	 *  store the value in the data fields of the SET_CONSTANT commands
-	 *  above.
-	 */
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_SQ_INST_STORE_MANAGMENT;
-	/* TBD #4a: partition info (to restore) */
-	*cmd++ = gpuaddr(partition1, &drawctxt->gpustate);
-	*cmd++ = pm4_type3_packet(PM4_REG_TO_MEM, 2);
-	*cmd++ = REG_SQ_INST_STORE_MANAGMENT;
-	/* TBD #4b: partition info (to fixup) */
-	*cmd++ = gpuaddr(partition2, &drawctxt->gpustate);
-
-#if defined(PM4_IM_STORE)
-
-	/* store the vertex shader instructions */
-	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
-	*cmd++ = ctx->shader_vertex + 0x0;	/* 0x0 = Vertex */
-	/* TBD #1: start/size (to restore) */
-	*cmd++ = gpuaddr(startSizeVtx, &drawctxt->gpustate);
-
-	/* store the pixel shader instructions */
-	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
-	*cmd++ = ctx->shader_pixel + 0x1;	/* 0x1 = Pixel */
-	/* TBD #2: start/size (to restore) */
-	*cmd++ = gpuaddr(startSizePix, &drawctxt->gpustate);
-
-	/* store the shared shader instructions if vertex base is nonzero */
-
-	*cmd++ = pm4_type3_packet(PM4_IM_STORE, 2);
-	*cmd++ = ctx->shader_shared + 0x2;	/* 0x2 = Shared */
-	/* TBD #3: start/size (to restore) */
-	*cmd++ = gpuaddr(startSizeShared, &drawctxt->gpustate);
-
-#endif
-
-	*cmd++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-	*cmd++ = 0;
-
-	/* create indirect buffer command for above command sequence */
-	create_ib1(drawctxt, drawctxt->shader_save, save, cmd);
-
-	ctx->cmd = cmd;
-}
-
-/* create buffers for saving/restoring registers, constants, & GMEM */
-static int
-create_gpustate_shadow(struct kgsl_device *device,
-		       struct kgsl_yamato_context *drawctxt,
-		       struct tmp_ctx *ctx)
-{
-	int result;
-
-	/* Allocate vmalloc memory to store the gpustate */
-	result = kgsl_sharedmem_vmalloc(&drawctxt->gpustate,
-					drawctxt->pagetable, CONTEXT_SIZE);
-
-	if (result)
-		return result;
-
-	drawctxt->flags |= CTXT_FLAGS_STATE_SHADOW;
-
-	/* Blank out h/w register, constant, and command buffer shadows. */
-	kgsl_sharedmem_set(&drawctxt->gpustate, 0, 0, CONTEXT_SIZE);
-
-	/* set-up command and vertex buffer pointers */
-	ctx->cmd = ctx->start
-	    = (unsigned int *)((char *)drawctxt->gpustate.hostptr + CMD_OFFSET);
-
-	/* build indirect command buffers to save & restore regs/constants */
-	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-	build_regrestore_cmds(device, drawctxt, ctx);
-	build_regsave_cmds(device, drawctxt, ctx);
-
-	build_shader_save_restore_cmds(drawctxt, ctx);
-
-	kgsl_cache_range_op(&drawctxt->gpustate,
-			    KGSL_CACHE_OP_FLUSH);
-
-	return 0;
-}
-
-/* create buffers for saving/restoring registers, constants, & GMEM */
-static int
-create_gmem_shadow(struct kgsl_yamato_device *yamato_device,
-		   struct kgsl_yamato_context *drawctxt,
-		   struct tmp_ctx *ctx)
-{
-	struct kgsl_device *device = &yamato_device->dev;
-	int result;
-
-	config_gmemsize(&drawctxt->context_gmem_shadow,
-			yamato_device->gmemspace.sizebytes);
-	ctx->gmem_base = yamato_device->gmemspace.gpu_base;
-
-	result = kgsl_sharedmem_vmalloc(
-				&drawctxt->context_gmem_shadow.gmemshadow,
-			       drawctxt->pagetable,
-			       drawctxt->context_gmem_shadow.size);
-
-	if (result)
-		return result;
-
-	/* we've allocated the shadow, when swapped out, GMEM must be saved. */
-	drawctxt->flags |= CTXT_FLAGS_GMEM_SHADOW | CTXT_FLAGS_GMEM_SAVE;
-
-	/* blank out gmem shadow. */
-	kgsl_sharedmem_set(&drawctxt->context_gmem_shadow.gmemshadow, 0, 0,
-			   drawctxt->context_gmem_shadow.size);
-
-	/* build quad vertex buffer */
-	build_quad_vtxbuff(drawctxt, ctx, &drawctxt->context_gmem_shadow);
-
-	/* build TP0_CHICKEN register restore command buffer */
-	ctx->cmd = build_chicken_restore_cmds(drawctxt, ctx);
-
-	/* build indirect command buffers to save & restore gmem */
-	/* Idle because we are reading PM override registers */
-	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-	drawctxt->context_gmem_shadow.gmem_save_commands = ctx->cmd;
-	ctx->cmd =
-	    build_gmem2sys_cmds(device, drawctxt, ctx,
-				&drawctxt->context_gmem_shadow);
-	drawctxt->context_gmem_shadow.gmem_restore_commands = ctx->cmd;
-	ctx->cmd =
-	    build_sys2gmem_cmds(device, drawctxt, ctx,
-				&drawctxt->context_gmem_shadow);
-
-	kgsl_cache_range_op(&drawctxt->context_gmem_shadow.gmemshadow,
-			    KGSL_CACHE_OP_FLUSH);
-
-	return 0;
-}
-
-/* create a new drawing context */
-
-int
-kgsl_drawctxt_create(struct kgsl_device_private *dev_priv, uint32_t flags,
-		     struct kgsl_context *context)
-{
-	struct kgsl_yamato_context *drawctxt;
-	struct kgsl_device *device = dev_priv->device;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_pagetable *pagetable = dev_priv->process_priv->pagetable;
-	struct tmp_ctx ctx;
-	int ret;
-
-	drawctxt = kzalloc(sizeof(struct kgsl_yamato_context), GFP_KERNEL);
-
-	if (drawctxt == NULL)
-		return -ENOMEM;
-
-	drawctxt->pagetable = pagetable;
-	drawctxt->bin_base_offset = 0;
-
-	ret = create_gpustate_shadow(device, drawctxt, &ctx);
-	if (ret)
-		goto err;
-
-	/* Save the shader instruction memory on context switching */
-	drawctxt->flags |= CTXT_FLAGS_SHADER_SAVE;
-
-	memset(&drawctxt->context_gmem_shadow.gmemshadow,
-			0, sizeof(struct kgsl_memdesc));
-
-	if (!(flags & KGSL_CONTEXT_NO_GMEM_ALLOC)) {
-		/* create gmem shadow */
-		ret = create_gmem_shadow(yamato_device, drawctxt, &ctx);
-		if (ret != 0)
-			goto err;
-	}
-
-	BUG_ON(ctx.cmd - ctx.start > CMD_BUFFER_LEN);
-
-	context->devctxt = drawctxt;
-	return 0;
-err:
-	kgsl_sharedmem_free(&drawctxt->gpustate);
-	kfree(drawctxt);
-	return ret;
-}
-
-/* destroy a drawing context */
-
-int kgsl_drawctxt_destroy(struct kgsl_device *device,
-			  struct kgsl_context *context)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_yamato_context *drawctxt = context->devctxt;
-
-	if (drawctxt == NULL)
-		return -EINVAL;
-
-	/* deactivate context */
-	if (yamato_device->drawctxt_active == drawctxt) {
-		/* no need to save GMEM or shader, the context is
-		 * being destroyed.
-		 */
-		drawctxt->flags &= ~(CTXT_FLAGS_GMEM_SAVE |
-				     CTXT_FLAGS_SHADER_SAVE |
-				     CTXT_FLAGS_GMEM_SHADOW |
-				     CTXT_FLAGS_STATE_SHADOW);
-
-		kgsl_drawctxt_switch(yamato_device, NULL, 0);
-	}
-
-	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-
-	kgsl_sharedmem_free(&drawctxt->gpustate);
-	kgsl_sharedmem_free(&drawctxt->context_gmem_shadow.gmemshadow);
-
-	kfree(drawctxt);
-	context->devctxt = NULL;
-
-	return 0;
-}
-
-/* set bin base offset */
-int kgsl_drawctxt_set_bin_base_offset(struct kgsl_device *device,
-				      struct kgsl_context *context,
-				      unsigned int offset)
-{
-	struct kgsl_yamato_context *drawctxt = context->devctxt;
-
-	if (drawctxt == NULL)
-		return -EINVAL;
-
-	drawctxt->bin_base_offset = offset;
-
-	return 0;
-}
-
-/* switch drawing contexts */
-void
-kgsl_drawctxt_switch(struct kgsl_yamato_device *yamato_device,
-			struct kgsl_yamato_context *drawctxt,
-			unsigned int flags)
-{
-	struct kgsl_yamato_context *active_ctxt =
-	  yamato_device->drawctxt_active;
-	struct kgsl_device *device = &yamato_device->dev;
-	unsigned int cmds[5];
-
-	if (drawctxt) {
-		if (flags & KGSL_CONTEXT_SAVE_GMEM)
-			/* Set the flag in context so that the save is done
-			* when this context is switched out. */
-			drawctxt->flags |= CTXT_FLAGS_GMEM_SAVE;
-		else
-			/* Remove GMEM saving flag from the context */
-			drawctxt->flags &= ~CTXT_FLAGS_GMEM_SAVE;
-	}
-	/* already current? */
-	if (active_ctxt == drawctxt)
-		return;
-
-	KGSL_CTXT_INFO(device, "from %p to %p flags %d\n",
-			yamato_device->drawctxt_active, drawctxt, flags);
-	/* save old context*/
-	if (active_ctxt && active_ctxt->flags & CTXT_FLAGS_GPU_HANG)
-		KGSL_CTXT_WARN(device,
-			"Current active context has caused gpu hang\n");
-
-	if (active_ctxt != NULL) {
-		KGSL_CTXT_INFO(device,
-			"active_ctxt flags %08x\n", active_ctxt->flags);
-		/* save registers and constants. */
-		kgsl_ringbuffer_issuecmds(device, 0, active_ctxt->reg_save, 3);
-
-		if (active_ctxt->flags & CTXT_FLAGS_SHADER_SAVE) {
-			/* save shader partitioning and instructions. */
-			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
-						  active_ctxt->shader_save, 3);
-
-			/* fixup shader partitioning parameter for
-			 *  SET_SHADER_BASES.
-			 */
-			kgsl_ringbuffer_issuecmds(device, 0,
-					active_ctxt->shader_fixup, 3);
-
-			active_ctxt->flags |= CTXT_FLAGS_SHADER_RESTORE;
-		}
-
-		if (active_ctxt->flags & CTXT_FLAGS_GMEM_SAVE
-			&& active_ctxt->flags & CTXT_FLAGS_GMEM_SHADOW) {
-			/* save gmem.
-			 * (note: changes shader. shader must already be saved.)
-			 */
-			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
-				active_ctxt->context_gmem_shadow.gmem_save, 3);
-
-			/* Restore TP0_CHICKEN */
-			kgsl_ringbuffer_issuecmds(device, 0,
-				active_ctxt->chicken_restore, 3);
-
-			active_ctxt->flags |= CTXT_FLAGS_GMEM_RESTORE;
-		}
-	}
-
-	yamato_device->drawctxt_active = drawctxt;
-
-	/* restore new context */
-	if (drawctxt != NULL) {
-
-		KGSL_CTXT_INFO(device,
-			"drawctxt flags %08x\n", drawctxt->flags);
-		cmds[0] = pm4_nop_packet(1);
-		cmds[1] = KGSL_CONTEXT_TO_MEM_IDENTIFIER;
-		cmds[2] = pm4_type3_packet(PM4_MEM_WRITE, 2);
-		cmds[3] = device->memstore.gpuaddr +
-				KGSL_DEVICE_MEMSTORE_OFFSET(current_context);
-		cmds[4] = (unsigned int)yamato_device->drawctxt_active;
-		kgsl_ringbuffer_issuecmds(device, 0, cmds, 5);
-		kgsl_mmu_setstate(device, drawctxt->pagetable);
-
-#ifndef CONFIG_MSM_KGSL_CFF_DUMP_NO_CONTEXT_MEM_DUMP
-		kgsl_cffdump_syncmem(NULL, &drawctxt->gpustate,
-			drawctxt->gpustate.gpuaddr, LCC_SHADOW_SIZE +
-			REG_SHADOW_SIZE + CMD_BUFFER_SIZE + TEX_SHADOW_SIZE,
-			false);
-#endif
-
-		/* restore gmem.
-		 *  (note: changes shader. shader must not already be restored.)
-		 */
-		if (drawctxt->flags & CTXT_FLAGS_GMEM_RESTORE) {
-			kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
-				drawctxt->context_gmem_shadow.gmem_restore, 3);
-
-			/* Restore TP0_CHICKEN */
-			kgsl_ringbuffer_issuecmds(device, 0,
-				drawctxt->chicken_restore, 3);
-
-			drawctxt->flags &= ~CTXT_FLAGS_GMEM_RESTORE;
-		}
-
-		/* restore registers and constants. */
-		kgsl_ringbuffer_issuecmds(device, 0,
-					  drawctxt->reg_restore, 3);
-
-		/* restore shader instructions & partitioning. */
-		if (drawctxt->flags & CTXT_FLAGS_SHADER_RESTORE) {
-			kgsl_ringbuffer_issuecmds(device, 0,
-					  drawctxt->shader_restore, 3);
-		}
-
-		cmds[0] = pm4_type3_packet(PM4_SET_BIN_BASE_OFFSET, 1);
-		cmds[1] = drawctxt->bin_base_offset;
-		if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
-			kgsl_ringbuffer_issuecmds(device, 0, cmds, 2);
-
-	} else
-		kgsl_mmu_setstate(device, device->mmu.defaultpagetable);
-}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.h
deleted file mode 100644
index 7b31594..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_drawctxt.h
+++ /dev/null
@@ -1,116 +0,0 @@
-/* Copyright (c) 2002,2007-2010, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef __GSL_DRAWCTXT_H
-#define __GSL_DRAWCTXT_H
-
-/* Flags */
-
-#define CTXT_FLAGS_NOT_IN_USE		0x00000000
-#define CTXT_FLAGS_IN_USE			0x00000001
-
-/* state shadow memory allocated */
-#define CTXT_FLAGS_STATE_SHADOW		0x00000010
-
-/* gmem shadow memory allocated */
-#define CTXT_FLAGS_GMEM_SHADOW		0x00000100
-/* gmem must be copied to shadow */
-#define CTXT_FLAGS_GMEM_SAVE		0x00000200
-/* gmem can be restored from shadow */
-#define CTXT_FLAGS_GMEM_RESTORE		0x00000400
-/* shader must be copied to shadow */
-#define CTXT_FLAGS_SHADER_SAVE		0x00002000
-/* shader can be restored from shadow */
-#define CTXT_FLAGS_SHADER_RESTORE	0x00004000
-/* Context has caused a GPU hang */
-#define CTXT_FLAGS_GPU_HANG		0x00008000
-
-#include <linux/msm_kgsl.h>
-#include "kgsl_sharedmem.h"
-#include "yamato_reg.h"
-
-struct kgsl_device;
-struct kgsl_yamato_device;
-struct kgsl_device_private;
-struct kgsl_context;
-
-/*  types */
-
-/* draw context */
-struct gmem_shadow_t {
-	struct kgsl_memdesc gmemshadow;	/* Shadow buffer address */
-
-	/* 256 KB GMEM surface = 4 bytes-per-pixel x 256 pixels/row x
-	* 256 rows. */
-	/* width & height must be a multiples of 32, in case tiled textures
-	 * are used. */
-	enum COLORFORMATX format;
-	unsigned int size;	/* Size of surface used to store GMEM */
-	unsigned int width;	/* Width of surface used to store GMEM */
-	unsigned int height;	/* Height of surface used to store GMEM */
-	unsigned int pitch;	/* Pitch of surface used to store GMEM */
-	unsigned int gmem_pitch;	/* Pitch value used for GMEM */
-	unsigned int *gmem_save_commands;
-	unsigned int *gmem_restore_commands;
-	unsigned int gmem_save[3];
-	unsigned int gmem_restore[3];
-	struct kgsl_memdesc quad_vertices;
-	struct kgsl_memdesc quad_texcoords;
-};
-
-struct kgsl_yamato_context {
-	uint32_t         flags;
-	struct kgsl_pagetable *pagetable;
-	struct kgsl_memdesc       gpustate;
-	unsigned int        reg_save[3];
-	unsigned int        reg_restore[3];
-	unsigned int        shader_save[3];
-	unsigned int        shader_fixup[3];
-	unsigned int        shader_restore[3];
-	unsigned int		chicken_restore[3];
-	unsigned int 	    bin_base_offset;
-	/* Information of the GMEM shadow that is created in context create */
-	struct gmem_shadow_t context_gmem_shadow;
-};
-
-
-int kgsl_drawctxt_create(struct kgsl_device_private *dev_priv,
-			 uint32_t flags,
-			 struct kgsl_context *context);
-
-int kgsl_drawctxt_destroy(struct kgsl_device *device,
-			  struct kgsl_context *context);
-
-void kgsl_drawctxt_switch(struct kgsl_yamato_device *yamato_device,
-				struct kgsl_yamato_context *drawctxt,
-				unsigned int flags);
-int kgsl_drawctxt_set_bin_base_offset(struct kgsl_device *device,
-				      struct kgsl_context *context,
-					unsigned int offset);
-
-#endif  /* __GSL_DRAWCTXT_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_g12.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_g12.h
deleted file mode 100644
index deb0277..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_g12.h
+++ /dev/null
@@ -1,63 +0,0 @@
-/* Copyright (c) 2008-2011, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef _KGSL_G12_H
-#define _KGSL_G12_H
-
-#define IDX_2D(X) ((X)-KGSL_DEVICE_2D0)
-
-#define DEVICE_2D_NAME "kgsl-2d"
-#define DEVICE_2D0_NAME "kgsl-2d0"
-#define DEVICE_2D1_NAME "kgsl-2d1"
-
-struct kgsl_g12_ringbuffer {
-	unsigned int prevctx;
-	struct kgsl_memdesc      cmdbufdesc;
-};
-
-struct kgsl_g12_device {
-	struct kgsl_device dev;    /* Must be first field in this struct */
-	int current_timestamp;
-	int timestamp;
-	struct kgsl_g12_ringbuffer ringbuffer;
-	spinlock_t cmdwin_lock;
-};
-
-irqreturn_t kgsl_g12_isr(int irq, void *data);
-int kgsl_g12_setstate(struct kgsl_device *device, uint32_t flags);
-int kgsl_g12_idle(struct kgsl_device *device, unsigned int timeout);
-void kgsl_g12_regread(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int *value);
-void kgsl_g12_regwrite(struct kgsl_device *device, unsigned int offsetwords,
-			unsigned int value);
-void kgsl_g12_regread_isr(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int *value);
-void kgsl_g12_regwrite_isr(struct kgsl_device *device, unsigned int offsetwords,
-			unsigned int value);
-
-#endif /* _KGSL_G12_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_log.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_log.h
index 55d44de..3b7982b 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_log.h
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_log.h
@@ -26,8 +26,8 @@
  * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#ifndef _GSL_LOG_H
-#define _GSL_LOG_H
+#ifndef __KGSL_LOG_H
+#define __KGSL_LOG_H
 
 extern unsigned int kgsl_cff_dump_enable;
 
@@ -117,4 +117,4 @@
 
 void kgsl_device_log_init(struct kgsl_device *device);
 
-#endif /* _GSL_LOG_H */
+#endif /* __KGSL_LOG_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_mmu.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_mmu.c
index c869620..3006319 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_mmu.c
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_mmu.c
@@ -16,30 +16,14 @@
  *
  */
 #include <linux/types.h>
-#include <linux/mutex.h>
+#include <linux/device.h>
 #include <linux/spinlock.h>
 #include <linux/genalloc.h>
 #include <linux/slab.h>
-#include <linux/io.h>
-#include <linux/bitmap.h>
-#ifdef CONFIG_MSM_KGSL_MMU
-#include <asm/pgalloc.h>
-#include <asm/pgtable.h>
-#endif
-#include "kgsl_mmu.h"
-#include "kgsl_drawctxt.h"
 #include "kgsl.h"
-#include "kgsl_log.h"
-#include "kgsl_device.h"
-#include "kgsl_ringbuffer.h"
-
-struct kgsl_pte_debug {
-	unsigned int read:1;
-	unsigned int write:1;
-	unsigned int dirty:1;
-	unsigned int reserved:9;
-	unsigned int phyaddr:20;
-};
+#include "kgsl_mmu.h"
+#include "adreno_ringbuffer.h"
+#include "a200_reg.h"
 
 #define KGSL_MMU_ALIGN_SHIFT    13
 #define KGSL_MMU_ALIGN_MASK     (~((1 << KGSL_MMU_ALIGN_SHIFT) - 1))
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pm4types.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pm4types.h
deleted file mode 100644
index ebfca24..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pm4types.h
+++ /dev/null
@@ -1,193 +0,0 @@
-/* Copyright (c) 2002,2007-2009, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef __GSL_PM4TYPES_H
-#define __GSL_PM4TYPES_H
-
-
-#define PM4_PKT_MASK	0xc0000000
-
-#define PM4_TYPE0_PKT	((unsigned int)0 << 30)
-#define PM4_TYPE1_PKT	((unsigned int)1 << 30)
-#define PM4_TYPE2_PKT	((unsigned int)2 << 30)
-#define PM4_TYPE3_PKT	((unsigned int)3 << 30)
-
-
-/* type3 packets */
-/* initialize CP's micro-engine */
-#define PM4_ME_INIT		0x48
-
-/* skip N 32-bit words to get to the next packet */
-#define PM4_NOP			0x10
-
-/* indirect buffer dispatch.  prefetch parser uses this packet type to determine
-*  whether to pre-fetch the IB
-*/
-#define PM4_INDIRECT_BUFFER	0x3f
-
-/* indirect buffer dispatch.  same as IB, but init is pipelined */
-#define PM4_INDIRECT_BUFFER_PFD	0x37
-
-/* wait for the IDLE state of the engine */
-#define PM4_WAIT_FOR_IDLE	0x26
-
-/* wait until a register or memory location is a specific value */
-#define PM4_WAIT_REG_MEM	0x3c
-
-/* wait until a register location is equal to a specific value */
-#define PM4_WAIT_REG_EQ		0x52
-
-/* wait until a register location is >= a specific value */
-#define PM4_WAT_REG_GTE		0x53
-
-/* wait until a read completes */
-#define PM4_WAIT_UNTIL_READ	0x5c
-
-/* wait until all base/size writes from an IB_PFD packet have completed */
-#define PM4_WAIT_IB_PFD_COMPLETE 0x5d
-
-/* register read/modify/write */
-#define PM4_REG_RMW		0x21
-
-/* reads register in chip and writes to memory */
-#define PM4_REG_TO_MEM		0x3e
-
-/* write N 32-bit words to memory */
-#define PM4_MEM_WRITE		0x3d
-
-/* write CP_PROG_COUNTER value to memory */
-#define PM4_MEM_WRITE_CNTR	0x4f
-
-/* conditional execution of a sequence of packets */
-#define PM4_COND_EXEC		0x44
-
-/* conditional write to memory or register */
-#define PM4_COND_WRITE		0x45
-
-/* generate an event that creates a write to memory when completed */
-#define PM4_EVENT_WRITE		0x46
-
-/* generate a VS|PS_done event */
-#define PM4_EVENT_WRITE_SHD	0x58
-
-/* generate a cache flush done event */
-#define PM4_EVENT_WRITE_CFL	0x59
-
-/* generate a z_pass done event */
-#define PM4_EVENT_WRITE_ZPD	0x5b
-
-
-/* initiate fetch of index buffer and draw */
-#define PM4_DRAW_INDX		0x22
-
-/* draw using supplied indices in packet */
-#define PM4_DRAW_INDX_2		0x36
-
-/* initiate fetch of index buffer and binIDs and draw */
-#define PM4_DRAW_INDX_BIN	0x34
-
-/* initiate fetch of bin IDs and draw using supplied indices */
-#define PM4_DRAW_INDX_2_BIN	0x35
-
-
-/* begin/end initiator for viz query extent processing */
-#define PM4_VIZ_QUERY		0x23
-
-/* fetch state sub-blocks and initiate shader code DMAs */
-#define PM4_SET_STATE		0x25
-
-/* load constant into chip and to memory */
-#define PM4_SET_CONSTANT	0x2d
-
-/* load sequencer instruction memory (pointer-based) */
-#define PM4_IM_LOAD		0x27
-
-/* load sequencer instruction memory (code embedded in packet) */
-#define PM4_IM_LOAD_IMMEDIATE	0x2b
-
-/* load constants from a location in memory */
-#define PM4_LOAD_CONSTANT_CONTEXT 0x2e
-
-/* selective invalidation of state pointers */
-#define PM4_INVALIDATE_STATE	0x3b
-
-
-/* dynamically changes shader instruction memory partition */
-#define PM4_SET_SHADER_BASES	0x4A
-
-/* sets the 64-bit BIN_MASK register in the PFP */
-#define PM4_SET_BIN_MASK	0x50
-
-/* sets the 64-bit BIN_SELECT register in the PFP */
-#define PM4_SET_BIN_SELECT	0x51
-
-
-/* updates the current context, if needed */
-#define PM4_CONTEXT_UPDATE	0x5e
-
-/* generate interrupt from the command stream */
-#define PM4_INTERRUPT		0x40
-
-
-/* copy sequencer instruction memory to system memory */
-#define PM4_IM_STORE            0x2c
-
-/* program an offset that will added to the BIN_BASE value of
- * the 3D_DRAW_INDX_BIN packet */
-#define PM4_SET_BIN_BASE_OFFSET     0x4B
-
-#define PM4_SET_PROTECTED_MODE  0x5f /* sets the register protection mode */
-
-
-/* packet header building macros */
-#define pm4_type0_packet(regindx, cnt) \
-	(PM4_TYPE0_PKT | (((cnt)-1) << 16) | ((regindx) & 0x7FFF))
-
-#define pm4_type0_packet_for_sameregister(regindx, cnt) \
-	((PM4_TYPE0_PKT | (((cnt)-1) << 16) | ((1 << 15) | \
-		((regindx) & 0x7FFF)))
-
-#define pm4_type1_packet(reg0, reg1) \
-	 (PM4_TYPE1_PKT | ((reg1) << 12) | (reg0))
-
-#define pm4_type3_packet(opcode, cnt) \
-	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (((opcode) & 0xFF) << 8))
-
-#define pm4_predicated_type3_packet(opcode, cnt) \
-	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (((opcode) & 0xFF) << 8) | 0x1)
-
-#define pm4_nop_packet(cnt) \
-	 (PM4_TYPE3_PKT | (((cnt)-1) << 16) | (PM4_NOP << 8))
-
-
-/* packet headers */
-#define PM4_HDR_ME_INIT	pm4_type3_packet(PM4_ME_INIT, 18)
-#define PM4_HDR_INDIRECT_BUFFER_PFD pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)
-#define PM4_HDR_INDIRECT_BUFFER	pm4_type3_packet(PM4_INDIRECT_BUFFER, 2)
-
-#endif	/* __GSL_PM4TYPES_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.c
deleted file mode 100644
index 0306fc8..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.c
+++ /dev/null
@@ -1,880 +0,0 @@
-/* Copyright (c) 2010-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301, USA.
- *
- */
-
-#include <linux/delay.h>
-#include <linux/relay.h>
-#include <linux/vmalloc.h>
-
-#include "kgsl.h"
-#include "kgsl_device.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_log.h"
-#include "kgsl_postmortem.h"
-#include "kgsl_pm4types.h"
-#include "yamato_reg.h"
-#include "kgsl_yamato.h"
-#include "kgsl_yamato_debugfs.h"
-
-#define INVALID_RB_CMD 0xaaaaaaaa
-
-struct pm_id_name {
-	uint32_t id;
-	char name[9];
-};
-
-static const struct pm_id_name pm0_types[] = {
-	{REG_PA_SC_AA_CONFIG,		"RPASCAAC"},
-	{REG_RBBM_PM_OVERRIDE2,		"RRBBPMO2"},
-	{REG_SCRATCH_REG2,		"RSCRTRG2"},
-	{REG_SQ_GPR_MANAGEMENT,		"RSQGPRMN"},
-	{REG_SQ_INST_STORE_MANAGMENT,	"RSQINSTS"},
-	{REG_TC_CNTL_STATUS,		"RTCCNTLS"},
-	{REG_TP0_CHICKEN,		"RTP0CHCK"},
-	{REG_CP_TIMESTAMP,		"CP_TM_ST"},
-};
-
-static const struct pm_id_name pm3_types[] = {
-	{PM4_COND_EXEC,			"CND_EXEC"},
-	{PM4_CONTEXT_UPDATE,		"CX__UPDT"},
-	{PM4_DRAW_INDX,			"DRW_NDX_"},
-	{PM4_DRAW_INDX_BIN,		"DRW_NDXB"},
-	{PM4_EVENT_WRITE,		"EVENT_WT"},
-	{PM4_IM_LOAD,			"IN__LOAD"},
-	{PM4_IM_LOAD_IMMEDIATE,		"IM_LOADI"},
-	{PM4_IM_STORE,			"IM_STORE"},
-	{PM4_INDIRECT_BUFFER,		"IND_BUF_"},
-	{PM4_INDIRECT_BUFFER_PFD,	"IND_BUFP"},
-	{PM4_INTERRUPT,			"PM4_INTR"},
-	{PM4_INVALIDATE_STATE,		"INV_STAT"},
-	{PM4_LOAD_CONSTANT_CONTEXT,	"LD_CN_CX"},
-	{PM4_ME_INIT,			"ME__INIT"},
-	{PM4_NOP,			"PM4__NOP"},
-	{PM4_REG_RMW,			"REG__RMW"},
-	{PM4_REG_TO_MEM,		"REG2_MEM"},
-	{PM4_SET_BIN_BASE_OFFSET,	"ST_BIN_O"},
-	{PM4_SET_CONSTANT,		"ST_CONST"},
-	{PM4_SET_PROTECTED_MODE,	"ST_PRT_M"},
-	{PM4_SET_SHADER_BASES,		"ST_SHD_B"},
-	{PM4_WAIT_FOR_IDLE,		"WAIT4IDL"},
-};
-
-/* Offset address pairs: start, end of range to dump (inclusive) */
-
-/* GPU < Z470 */
-
-static const int yamato_registers[] = {
-	0x0000, 0x0008, 0x0010, 0x002c, 0x00ec, 0x00f4,
-	0x0100, 0x0110, 0x0118, 0x011c,
-	0x0700, 0x0704, 0x070c, 0x0720, 0x0754, 0x0764,
-	0x0770, 0x0774, 0x07a8, 0x07a8, 0x07b8, 0x07cc,
-	0x07d8, 0x07dc, 0x07f0, 0x07fc, 0x0e44, 0x0e48,
-	0x0e6c, 0x0e78, 0x0ec8, 0x0ed4, 0x0edc, 0x0edc,
-	0x0fe0, 0x0fec, 0x1100, 0x1100,
-
-	0x110c, 0x1110, 0x112c, 0x112c, 0x1134, 0x113c,
-	0x1148, 0x1148, 0x1150, 0x116c, 0x11fc, 0x11fc,
-	0x15e0, 0x161c, 0x1724, 0x1724, 0x1740, 0x1740,
-	0x1804, 0x1810, 0x1818, 0x1824, 0x182c, 0x1838,
-	0x184c, 0x1850, 0x28a4, 0x28ac, 0x28bc, 0x28c4,
-	0x2900, 0x290c, 0x2914, 0x2914, 0x2938, 0x293c,
-	0x30b0, 0x30b0, 0x30c0, 0x30c0, 0x30e0, 0x30f0,
-	0x3100, 0x3100, 0x3110, 0x3110, 0x3200, 0x3218,
-	0x3220, 0x3250, 0x3264, 0x3268, 0x3290, 0x3294,
-	0x3400, 0x340c, 0x3418, 0x3418, 0x3420, 0x342c,
-	0x34d0, 0x34d4, 0x36b8, 0x3704, 0x3720, 0x3750,
-	0x3760, 0x3764, 0x3800, 0x3800, 0x3808, 0x3810,
-	0x385c, 0x3878, 0x3b00, 0x3b24, 0x3b2c, 0x3b30,
-	0x3b40, 0x3b40, 0x3b50, 0x3b5c, 0x3b80, 0x3b88,
-	0x3c04, 0x3c08, 0x3c30, 0x3c30, 0x3c38, 0x3c48,
-	0x3c98, 0x3ca8, 0x3cb0, 0x3cb0,
-
-	0x8000, 0x8008, 0x8018, 0x803c, 0x8200, 0x8208,
-	0x8400, 0x8424, 0x8430, 0x8450, 0x8600, 0x8610,
-	0x87d4, 0x87dc, 0x8800, 0x8820, 0x8a00, 0x8a0c,
-	0x8a4c, 0x8a50, 0x8c00, 0x8c20, 0x8c48, 0x8c48,
-	0x8c58, 0x8c74, 0x8c90, 0x8c98, 0x8e00, 0x8e0c,
-
-	0x9000, 0x9008, 0x9018, 0x903c, 0x9200, 0x9208,
-	0x9400, 0x9424, 0x9430, 0x9450, 0x9600, 0x9610,
-	0x97d4, 0x97dc, 0x9800, 0x9820, 0x9a00, 0x9a0c,
-	0x9a4c, 0x9a50, 0x9c00, 0x9c20, 0x9c48, 0x9c48,
-	0x9c58, 0x9c74, 0x9c90, 0x9c98, 0x9e00, 0x9e0c,
-
-	0x10000, 0x1000c, 0x12000, 0x12014,
-	0x12400, 0x12400, 0x12420, 0x12420
-};
-
-/* GPU = Z470 */
-
-static const int leia_registers[] = {
-	0x0000, 0x0008, 0x0010, 0x002c, 0x00ec, 0x00f4,
-	0x0100, 0x0110, 0x0118, 0x011c,
-	0x0700, 0x0704, 0x070c, 0x0720, 0x0754, 0x0764,
-	0x0770, 0x0774, 0x07a8, 0x07a8, 0x07b8, 0x07cc,
-	0x07d8, 0x07dc, 0x07f0, 0x07fc, 0x0e44, 0x0e48,
-	0x0e6c, 0x0e78, 0x0ec8, 0x0ed4, 0x0edc, 0x0edc,
-	0x0fe0, 0x0fec, 0x1100, 0x1100,
-
-	0x110c, 0x1110, 0x112c, 0x112c, 0x1134, 0x113c,
-	0x1148, 0x1148, 0x1150, 0x116c, 0x11fc, 0x11fc,
-	0x15e0, 0x161c, 0x1724, 0x1724, 0x1740, 0x1740,
-	0x1804, 0x1810, 0x1818, 0x1824, 0x182c, 0x1838,
-	0x184c, 0x1850, 0x28a4, 0x28ac, 0x28bc, 0x28c4,
-	0x2900, 0x2900, 0x2908, 0x290c, 0x2914, 0x2914,
-	0x2938, 0x293c, 0x30c0, 0x30c0, 0x30e0, 0x30e4,
-	0x30f0, 0x30f0, 0x3200, 0x3204, 0x3220, 0x324c,
-	0x3400, 0x340c, 0x3414, 0x3418, 0x3420, 0x342c,
-	0x34d0, 0x34d4, 0x36b8, 0x3704, 0x3720, 0x3750,
-	0x3760, 0x3764, 0x3800, 0x3800, 0x3808, 0x3810,
-	0x385c, 0x3878, 0x3b00, 0x3b24, 0x3b2c, 0x3b30,
-	0x3b40, 0x3b40, 0x3b50, 0x3b5c, 0x3b80, 0x3b88,
-	0x3c04, 0x3c08, 0x8000, 0x8008, 0x8018, 0x803c,
-	0x8200, 0x8208, 0x8400, 0x8408, 0x8410, 0x8424,
-	0x8430, 0x8450, 0x8600, 0x8610, 0x87d4, 0x87dc,
-	0x8800, 0x8808, 0x8810, 0x8810, 0x8820, 0x8820,
-	0x8a00, 0x8a08, 0x8a50, 0x8a50,
-	0x8c00, 0x8c20, 0x8c24, 0x8c28, 0x8c48, 0x8c48,
-	0x8c58, 0x8c58, 0x8c60, 0x8c74, 0x8c90, 0x8c98,
-	0x8e00, 0x8e0c, 0x9000, 0x9008, 0x9018, 0x903c,
-	0x9200, 0x9208, 0x9400, 0x9408, 0x9410, 0x9424,
-	0x9430, 0x9450, 0x9600, 0x9610, 0x97d4, 0x97dc,
-	0x9800, 0x9808, 0x9810, 0x9818, 0x9820, 0x9820,
-	0x9a00, 0x9a08, 0x9a50, 0x9a50, 0x9c00, 0x9c20,
-	0x9c48, 0x9c48, 0x9c58, 0x9c58, 0x9c60, 0x9c74,
-	0x9c90, 0x9c98, 0x9e00, 0x9e0c,
-
-	0x10000, 0x1000c, 0x12000, 0x12014,
-	0x12400, 0x12400, 0x12420, 0x12420
-};
-
-static struct {
-	int id;
-	const int *registers;
-	int len;
-} kgsl_registers[] = {
-	{ KGSL_CHIPID_LEIA_REV470, leia_registers,
-	  ARRAY_SIZE(leia_registers) / 2 },
-	{ KGSL_CHIPID_LEIA_REV470_TEMP, leia_registers,
-	  ARRAY_SIZE(leia_registers) / 2 },
-	{ KGSL_CHIPID_YAMATODX_REV21, yamato_registers,
-	  ARRAY_SIZE(yamato_registers) / 2 },
-	{ KGSL_CHIPID_YAMATODX_REV211, yamato_registers,
-	  ARRAY_SIZE(yamato_registers) / 2 },
-	{ 0x0, NULL, 0},
-};
-
-static uint32_t kgsl_is_pm4_len(uint32_t word)
-{
-	if (word == INVALID_RB_CMD)
-		return 0;
-
-	return (word >> 16) & 0x3FFF;
-}
-
-static bool kgsl_is_pm4_type(uint32_t word)
-{
-	int i;
-
-	if (word == INVALID_RB_CMD)
-		return 1;
-
-	if (kgsl_is_pm4_len(word) > 16)
-		return 0;
-
-	if ((word & (3<<30)) == PM4_TYPE0_PKT) {
-		for (i = 0; i < ARRAY_SIZE(pm0_types); ++i) {
-			if ((word & 0x7FFF) == pm0_types[i].id)
-				return 1;
-		}
-		return 0;
-	}
-	if ((word & (3<<30)) == PM4_TYPE3_PKT) {
-		for (i = 0; i < ARRAY_SIZE(pm3_types); ++i) {
-			if ((word & 0xFFFF) == (pm3_types[i].id << 8))
-				return 1;
-		}
-		return 0;
-	}
-	return 0;
-}
-
-static const char *kgsl_pm4_name(uint32_t word)
-{
-	int i;
-
-	if (word == INVALID_RB_CMD)
-		return "--------";
-
-	if ((word & (3<<30)) == PM4_TYPE0_PKT) {
-		for (i = 0; i < ARRAY_SIZE(pm0_types); ++i) {
-			if ((word & 0x7FFF) == pm0_types[i].id)
-				return pm0_types[i].name;
-		}
-		return "????????";
-	}
-	if ((word & (3<<30)) == PM4_TYPE3_PKT) {
-		for (i = 0; i < ARRAY_SIZE(pm3_types); ++i) {
-			if ((word & 0xFFFF) == (pm3_types[i].id << 8))
-				return pm3_types[i].name;
-		}
-		return "????????";
-	}
-	return "????????";
-}
-
-static void kgsl_dump_regs(struct kgsl_device *device,
-			   const int *registers, int size)
-{
-	int range = 0, offset = 0;
-
-	for (range = 0; range < size; range++) {
-		/* start and end are in dword offsets */
-		int start = registers[range * 2] / 4;
-		int end = registers[range * 2 + 1] / 4;
-
-		unsigned char linebuf[32 * 3 + 2 + 32 + 1];
-		int linelen, i;
-
-		for (offset = start; offset <= end; offset += linelen) {
-			unsigned int regvals[32/4];
-			linelen = min(end+1-offset, 32/4);
-
-			for (i = 0; i < linelen; ++i)
-				kgsl_regread(device, offset+i, regvals+i);
-
-			hex_dump_to_buffer(regvals, linelen*4, 32, 4,
-				linebuf, sizeof(linebuf), 0);
-			KGSL_LOG_DUMP(device,
-				"REG: %5.5X: %s\n", offset<<2, linebuf);
-		}
-	}
-}
-
-static void dump_ib(struct kgsl_device *device, char* buffId, uint32_t pt_base,
-	uint32_t base_offset, uint32_t ib_base, uint32_t ib_size, bool dump)
-{
-	unsigned int memsize;
-	uint8_t *base_addr = kgsl_sharedmem_convertaddr(device, pt_base,
-		ib_base, &memsize);
-
-	if (base_addr && dump)
-		print_hex_dump(KERN_ERR, buffId, DUMP_PREFIX_OFFSET,
-				 32, 4, base_addr, ib_size*4, 0);
-	else
-		KGSL_LOG_DUMP(device, "%s base:%8.8X  ib_size:%d  "
-			"offset:%5.5X%s\n",
-			buffId, ib_base, ib_size*4, base_offset,
-			base_addr ? "" : " [Invalid]");
-}
-
-#define IB_LIST_SIZE	64
-struct ib_list {
-	int count;
-	uint32_t bases[IB_LIST_SIZE];
-	uint32_t sizes[IB_LIST_SIZE];
-	uint32_t offsets[IB_LIST_SIZE];
-};
-
-static void dump_ib1(struct kgsl_device *device, uint32_t pt_base,
-			uint32_t base_offset,
-			uint32_t ib1_base, uint32_t ib1_size,
-			struct ib_list *ib_list, bool dump)
-{
-	int i, j;
-	uint32_t value;
-	uint32_t *ib1_addr;
-	unsigned int memsize;
-
-	dump_ib(device, "IB1:", pt_base, base_offset, ib1_base,
-		ib1_size, dump);
-
-	/* fetch virtual address for given IB base */
-	ib1_addr = (uint32_t *)kgsl_sharedmem_convertaddr(device, pt_base,
-		ib1_base, &memsize);
-	if (!ib1_addr)
-		return;
-
-	for (i = 0; i+3 < ib1_size; ) {
-		value = ib1_addr[i++];
-		if (value == pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)) {
-			uint32_t ib2_base = ib1_addr[i++];
-			uint32_t ib2_size = ib1_addr[i++];
-
-			/* find previous match */
-			for (j = 0; j < ib_list->count; ++j)
-				if (ib_list->sizes[j] == ib2_size
-					&& ib_list->bases[j] == ib2_base)
-					break;
-
-			if (j < ib_list->count || ib_list->count
-				>= IB_LIST_SIZE)
-				continue;
-
-			/* store match */
-			ib_list->sizes[ib_list->count] = ib2_size;
-			ib_list->bases[ib_list->count] = ib2_base;
-			ib_list->offsets[ib_list->count] = i<<2;
-			++ib_list->count;
-		}
-	}
-}
-
-static void kgsl_dump_rb_buffer(const void *buf, size_t len,
-		char *linebuf, size_t linebuflen, int *argp)
-{
-	const u32 *ptr4 = buf;
-	const int ngroups = len;
-	int lx = 0, j;
-	bool nxsp = 1;
-
-	for (j = 0; j < ngroups; j++) {
-		if (*argp < 0) {
-			lx += scnprintf(linebuf + lx, linebuflen - lx, " <");
-			*argp = -*argp;
-		} else if (nxsp)
-			lx += scnprintf(linebuf + lx, linebuflen - lx, "  ");
-		else
-			nxsp = 1;
-		if (!*argp && kgsl_is_pm4_type(ptr4[j])) {
-			lx += scnprintf(linebuf + lx, linebuflen - lx,
-				"%s", kgsl_pm4_name(ptr4[j]));
-			*argp = -(kgsl_is_pm4_len(ptr4[j])+1);
-		} else {
-			lx += scnprintf(linebuf + lx, linebuflen - lx,
-				"%8.8X", ptr4[j]);
-			if (*argp > 1)
-				--*argp;
-			else if (*argp == 1) {
-				*argp = 0;
-				nxsp = 0;
-				lx += scnprintf(linebuf + lx, linebuflen - lx,
-					"> ");
-			}
-		}
-	}
-	linebuf[lx] = '\0';
-}
-
-static bool kgsl_rb_use_hex(void)
-{
-#ifdef CONFIG_MSM_KGSL_PSTMRTMDMP_RB_HEX
-	return 1;
-#else
-	return 0;
-#endif
-}
-
-static void kgsl_dump_rb(struct kgsl_device *device, const void *buf,
-			 size_t len, int start, int size)
-{
-	const uint32_t *ptr = buf;
-	int i, remaining, args = 0;
-	unsigned char linebuf[32 * 3 + 2 + 32 + 1];
-	const int rowsize = 8;
-
-	len >>= 2;
-	remaining = len;
-	for (i = 0; i < len; i += rowsize) {
-		int linelen = min(remaining, rowsize);
-		remaining -= rowsize;
-
-		if (kgsl_rb_use_hex())
-			hex_dump_to_buffer(ptr+i, linelen*4, rowsize*4, 4,
-				linebuf, sizeof(linebuf), 0);
-		else
-			kgsl_dump_rb_buffer(ptr+i, linelen, linebuf,
-				sizeof(linebuf), &args);
-		KGSL_LOG_DUMP(device,
-			"RB: %4.4X:%s\n", (start+i)%size, linebuf);
-	}
-}
-
-static bool kgsl_ib_dump_enabled(void)
-{
-#ifdef CONFIG_MSM_KGSL_PSTMRTMDMP_NO_IB_DUMP
-	return 0;
-#else
-	return 1;
-#endif
-}
-
-struct log_field {
-	bool show;
-	const char *display;
-};
-
-static int kgsl_dump_fields_line(struct kgsl_device *device,
-				 const char *start, char *str, int slen,
-				 const struct log_field **lines,
-				 int num)
-{
-	const struct log_field *l = *lines;
-	int sptr, count  = 0;
-
-	sptr = snprintf(str, slen, "%s", start);
-
-	for (  ; num && sptr < slen; num--, l++) {
-		int ilen = strlen(l->display);
-
-		if (count)
-			ilen += strlen("  | ");
-
-		if (ilen > (slen - sptr))
-			break;
-
-		if (count++)
-			sptr += snprintf(str + sptr, slen - sptr, " | ");
-
-		sptr += snprintf(str + sptr, slen - sptr, "%s", l->display);
-	}
-
-	KGSL_LOG_DUMP(device, "%s\n", str);
-
-	*lines = l;
-	return num;
-}
-
-static void kgsl_dump_fields(struct kgsl_device *device,
-			     const char *start, const struct log_field *lines,
-			     int num)
-{
-	char lb[90];
-	const char *sstr = start;
-
-	lb[sizeof(lb)  - 1] = '\0';
-
-	while (num) {
-		int ret = kgsl_dump_fields_line(device, sstr, lb,
-			sizeof(lb) - 1, &lines, num);
-
-		if (ret == num)
-			break;
-
-		num = ret;
-		sstr = "        ";
-	}
-}
-
-static int kgsl_dump_yamato(struct kgsl_device *device)
-{
-	unsigned int r1, r2, r3, rbbm_status;
-	unsigned int cp_ib1_base, cp_ib1_bufsz, cp_stat;
-	unsigned int cp_ib2_base, cp_ib2_bufsz;
-	unsigned int pt_base;
-	unsigned int cp_rb_base, rb_count;
-	unsigned int cp_rb_wptr, cp_rb_rptr;
-	unsigned int i;
-	int result = 0;
-	uint32_t *rb_copy;
-	const uint32_t *rb_vaddr;
-	int num_item = 0;
-	int read_idx, write_idx;
-	unsigned int ts_processed, rb_memsize;
-
-	static struct ib_list ib_list;
-
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-
-	struct kgsl_pwrctrl *pwr = &device->pwrctrl;
-
-	mb();
-
-	KGSL_LOG_DUMP(device, "POWER: FLAGS = %08X | ACTIVE POWERLEVEL = %08X",
-			pwr->power_flags, pwr->active_pwrlevel);
-
-	KGSL_LOG_DUMP(device, "POWER: INTERVAL TIMEOUT = %08X ",
-		pwr->interval_timeout);
-
-	KGSL_LOG_DUMP(device, "GRP_CLK = %lu ",
-				  kgsl_get_clkrate(pwr->grp_clks[0]));
-
-	KGSL_LOG_DUMP(device, "BUS CLK = %lu ",
-		kgsl_get_clkrate(pwr->ebi1_clk));
-
-
-	kgsl_regread(device, REG_RBBM_STATUS, &rbbm_status);
-	kgsl_regread(device, REG_RBBM_PM_OVERRIDE1, &r2);
-	kgsl_regread(device, REG_RBBM_PM_OVERRIDE2, &r3);
-	KGSL_LOG_DUMP(device, "RBBM:   STATUS   = %08X | PM_OVERRIDE1 = %08X | "
-		"PM_OVERRIDE2 = %08X\n", rbbm_status, r2, r3);
-
-	kgsl_regread(device, REG_RBBM_INT_CNTL, &r1);
-	kgsl_regread(device, REG_RBBM_INT_STATUS, &r2);
-	kgsl_regread(device, REG_RBBM_READ_ERROR, &r3);
-	KGSL_LOG_DUMP(device, "        INT_CNTL = %08X | INT_STATUS   = %08X | "
-		"READ_ERROR   = %08X\n", r1, r2, r3);
-
-	{
-		char cmdFifo[16];
-		struct log_field lines[] = {
-			{rbbm_status &  0x000F, cmdFifo},
-			{rbbm_status &  BIT(5), "TC busy     "},
-			{rbbm_status &  BIT(8), "HIRQ pending"},
-			{rbbm_status &  BIT(9), "CPRQ pending"},
-			{rbbm_status & BIT(10), "CFRQ pending"},
-			{rbbm_status & BIT(11), "PFRQ pending"},
-			{rbbm_status & BIT(12), "VGT 0DMA bsy"},
-			{rbbm_status & BIT(14), "RBBM WU busy"},
-			{rbbm_status & BIT(16), "CP NRT busy "},
-			{rbbm_status & BIT(18), "MH busy     "},
-			{rbbm_status & BIT(19), "MH chncy bsy"},
-			{rbbm_status & BIT(21), "SX busy     "},
-			{rbbm_status & BIT(22), "TPC busy    "},
-			{rbbm_status & BIT(24), "SC CNTX busy"},
-			{rbbm_status & BIT(25), "PA busy     "},
-			{rbbm_status & BIT(26), "VGT busy    "},
-			{rbbm_status & BIT(27), "SQ cntx1 bsy"},
-			{rbbm_status & BIT(28), "SQ cntx0 bsy"},
-			{rbbm_status & BIT(30), "RB busy     "},
-			{rbbm_status & BIT(31), "Grphs pp bsy"},
-		};
-		snprintf(cmdFifo, sizeof(cmdFifo), "CMD FIFO=%01X  ",
-			rbbm_status & 0xf);
-		kgsl_dump_fields(device, " STATUS=", lines, ARRAY_SIZE(lines));
-	}
-
-	kgsl_regread(device, REG_CP_RB_BASE, &cp_rb_base);
-	kgsl_regread(device, REG_CP_RB_CNTL, &r2);
-	rb_count = 2 << (r2 & (BIT(6)-1));
-	kgsl_regread(device, REG_CP_RB_RPTR_ADDR, &r3);
-	KGSL_LOG_DUMP(device,
-		"CP_RB:  BASE = %08X | CNTL   = %08X | RPTR_ADDR = %08X"
-		"\n", cp_rb_base, r2, r3);
-
-	kgsl_regread(device, REG_CP_RB_RPTR, &cp_rb_rptr);
-	kgsl_regread(device, REG_CP_RB_WPTR, &cp_rb_wptr);
-	kgsl_regread(device, REG_CP_RB_RPTR_WR, &r3);
-	KGSL_LOG_DUMP(device,
-		"        RPTR = %08X | WPTR   = %08X | RPTR_WR   = %08X"
-		"\n", cp_rb_rptr, cp_rb_wptr, r3);
-
-	kgsl_regread(device, REG_CP_IB1_BASE, &cp_ib1_base);
-	kgsl_regread(device, REG_CP_IB1_BUFSZ, &cp_ib1_bufsz);
-	KGSL_LOG_DUMP(device,
-		"CP_IB1: BASE = %08X | BUFSZ  = %d\n", cp_ib1_base,
-		cp_ib1_bufsz);
-
-	kgsl_regread(device, REG_CP_IB2_BASE, &cp_ib2_base);
-	kgsl_regread(device, REG_CP_IB2_BUFSZ, &cp_ib2_bufsz);
-	KGSL_LOG_DUMP(device,
-		"CP_IB2: BASE = %08X | BUFSZ  = %d\n", cp_ib2_base,
-		cp_ib2_bufsz);
-
-	kgsl_regread(device, REG_CP_INT_CNTL, &r1);
-	kgsl_regread(device, REG_CP_INT_STATUS, &r2);
-	KGSL_LOG_DUMP(device, "CP_INT: CNTL = %08X | STATUS = %08X\n", r1, r2);
-
-	kgsl_regread(device, REG_CP_ME_CNTL, &r1);
-	kgsl_regread(device, REG_CP_ME_STATUS, &r2);
-	kgsl_regread(device, REG_MASTER_INT_SIGNAL, &r3);
-	KGSL_LOG_DUMP(device,
-		"CP_ME:  CNTL = %08X | STATUS = %08X | MSTR_INT_SGNL = "
-		"%08X\n", r1, r2, r3);
-
-	kgsl_regread(device, REG_CP_STAT, &cp_stat);
-	KGSL_LOG_DUMP(device, "CP_STAT      = %08X\n", cp_stat);
-#ifndef CONFIG_MSM_KGSL_PSTMRTMDMP_CP_STAT_NO_DETAIL
-	{
-		struct log_field lns[] = {
-			{cp_stat &  BIT(0), "WR_BSY     0"},
-			{cp_stat &  BIT(1), "RD_RQ_BSY  1"},
-			{cp_stat &  BIT(2), "RD_RTN_BSY 2"},
-		};
-		kgsl_dump_fields(device, "    MIU=", lns, ARRAY_SIZE(lns));
-	}
-	{
-		struct log_field lns[] = {
-			{cp_stat &  BIT(5), "RING_BUSY  5"},
-			{cp_stat &  BIT(6), "NDRCTS_BSY 6"},
-			{cp_stat &  BIT(7), "NDRCT2_BSY 7"},
-			{cp_stat &  BIT(9), "ST_BUSY    9"},
-			{cp_stat & BIT(10), "BUSY      10"},
-		};
-		kgsl_dump_fields(device, "    CSF=", lns, ARRAY_SIZE(lns));
-	}
-	{
-		struct log_field lns[] = {
-			{cp_stat & BIT(11), "RNG_Q_BSY 11"},
-			{cp_stat & BIT(12), "NDRCTS_Q_B12"},
-			{cp_stat & BIT(13), "NDRCT2_Q_B13"},
-			{cp_stat & BIT(16), "ST_QUEUE_B16"},
-			{cp_stat & BIT(17), "PFP_BUSY  17"},
-		};
-		kgsl_dump_fields(device, "   RING=", lns, ARRAY_SIZE(lns));
-	}
-	{
-		struct log_field lns[] = {
-			{cp_stat &  BIT(3), "RBIU_BUSY  3"},
-			{cp_stat &  BIT(4), "RCIU_BUSY  4"},
-			{cp_stat & BIT(18), "MQ_RG_BSY 18"},
-			{cp_stat & BIT(19), "MQ_NDRS_BS19"},
-			{cp_stat & BIT(20), "MQ_NDR2_BS20"},
-			{cp_stat & BIT(21), "MIU_WC_STL21"},
-			{cp_stat & BIT(22), "CP_NRT_BSY22"},
-			{cp_stat & BIT(23), "3D_BUSY   23"},
-			{cp_stat & BIT(26), "ME_BUSY   26"},
-			{cp_stat & BIT(29), "ME_WC_BSY 29"},
-			{cp_stat & BIT(30), "MIU_FF EM 30"},
-			{cp_stat & BIT(31), "CP_BUSY   31"},
-		};
-		kgsl_dump_fields(device, " CP_STT=", lns, ARRAY_SIZE(lns));
-	}
-#endif
-
-	kgsl_regread(device, REG_SCRATCH_REG0, &r1);
-	KGSL_LOG_DUMP(device, "SCRATCH_REG0       = %08X\n", r1);
-
-	kgsl_regread(device, REG_COHER_SIZE_PM4, &r1);
-	kgsl_regread(device, REG_COHER_BASE_PM4, &r2);
-	kgsl_regread(device, REG_COHER_STATUS_PM4, &r3);
-	KGSL_LOG_DUMP(device,
-		"COHER:  SIZE_PM4   = %08X | BASE_PM4 = %08X | STATUS_PM4"
-		" = %08X\n", r1, r2, r3);
-
-	kgsl_regread(device, REG_MH_AXI_ERROR, &r1);
-	KGSL_LOG_DUMP(device, "MH:     AXI_ERROR  = %08X\n", r1);
-
-	kgsl_regread(device, REG_MH_MMU_PAGE_FAULT, &r1);
-	kgsl_regread(device, REG_MH_MMU_CONFIG, &r2);
-	kgsl_regread(device, REG_MH_MMU_MPU_BASE, &r3);
-	KGSL_LOG_DUMP(device,
-		"MH_MMU: PAGE_FAULT = %08X | CONFIG   = %08X | MPU_BASE ="
-		" %08X\n", r1, r2, r3);
-
-	kgsl_regread(device, REG_MH_MMU_MPU_END, &r1);
-	kgsl_regread(device, REG_MH_MMU_VA_RANGE, &r2);
-	kgsl_regread(device, REG_MH_MMU_PT_BASE, &pt_base);
-	KGSL_LOG_DUMP(device,
-		"        MPU_END    = %08X | VA_RANGE = %08X | PT_BASE  ="
-		" %08X\n", r1, r2, pt_base);
-
-	KGSL_LOG_DUMP(device, "PAGETABLE SIZE: %08X ", KGSL_PAGETABLE_SIZE);
-
-	kgsl_regread(device, REG_MH_MMU_TRAN_ERROR, &r1);
-	KGSL_LOG_DUMP(device, "        TRAN_ERROR = %08X\n", r1);
-
-	kgsl_regread(device, REG_MH_INTERRUPT_MASK, &r1);
-	kgsl_regread(device, REG_MH_INTERRUPT_STATUS, &r2);
-	KGSL_LOG_DUMP(device,
-		"MH_INTERRUPT: MASK = %08X | STATUS   = %08X\n", r1, r2);
-
-	if (device->ftbl.device_cmdstream_readtimestamp != NULL) {
-		ts_processed = device->ftbl.device_cmdstream_readtimestamp(
-				device, KGSL_TIMESTAMP_RETIRED);
-		KGSL_LOG_DUMP(device, "TIMESTM RTRD: %08X\n", ts_processed);
-	}
-
-	num_item = kgsl_ringbuffer_count(&yamato_device->ringbuffer,
-						cp_rb_rptr);
-	if (num_item <= 0)
-		KGSL_LOG_POSTMORTEM_WRITE(device, "Ringbuffer is Empty.\n");
-
-	rb_copy = vmalloc(rb_count<<2);
-	if (!rb_copy) {
-		KGSL_LOG_POSTMORTEM_WRITE(device,
-			"vmalloc(%d) failed\n", rb_count << 2);
-		result = -ENOMEM;
-		goto end;
-	}
-
-	KGSL_LOG_DUMP(device, "RB: rd_addr:%8.8x  rb_size:%d  num_item:%d\n",
-		cp_rb_base, rb_count<<2, num_item);
-	rb_vaddr = (const uint32_t *)kgsl_sharedmem_convertaddr(device, pt_base,
-					cp_rb_base, &rb_memsize);
-	if (!rb_vaddr) {
-		KGSL_LOG_POSTMORTEM_WRITE(device,
-			"Can't fetch vaddr for CP_RB_BASE\n");
-		goto error_vfree;
-	}
-
-	read_idx = (int)cp_rb_rptr - 64;
-	if (read_idx < 0)
-		read_idx += rb_count;
-	write_idx = (int)cp_rb_wptr + 16;
-	if (write_idx > rb_count)
-		write_idx -= rb_count;
-	num_item += 64+16;
-	if (num_item > rb_count)
-		num_item = rb_count;
-	if (write_idx >= read_idx)
-		memcpy(rb_copy, rb_vaddr+read_idx, num_item<<2);
-	else {
-		int part1_c = rb_count-read_idx;
-		memcpy(rb_copy, rb_vaddr+read_idx, part1_c<<2);
-		memcpy(rb_copy+part1_c, rb_vaddr, (num_item-part1_c)<<2);
-	}
-
-	/* extract the latest ib commands from the buffer */
-	ib_list.count = 0;
-	i = 0;
-	for (read_idx = 0; read_idx < num_item; ) {
-		uint32_t this_cmd = rb_copy[read_idx++];
-		if (this_cmd == pm4_type3_packet(PM4_INDIRECT_BUFFER_PFD, 2)) {
-			uint32_t ib_addr = rb_copy[read_idx++];
-			uint32_t ib_size = rb_copy[read_idx++];
-			dump_ib1(device, pt_base, (read_idx-3)<<2, ib_addr,
-				ib_size, &ib_list, 0);
-			for (; i < ib_list.count; ++i)
-				dump_ib(device, "IB2:", pt_base,
-					ib_list.offsets[i],
-					ib_list.bases[i],
-					ib_list.sizes[i], 0);
-		}
-	}
-
-	read_idx = (int)cp_rb_rptr - 64;
-	if (read_idx < 0)
-		read_idx += rb_count;
-	KGSL_LOG_DUMP(device,
-		"RB: addr=%8.8x  window:%4.4x-%4.4x, start:%4.4x\n",
-		cp_rb_base, cp_rb_rptr, cp_rb_wptr, read_idx);
-	kgsl_dump_rb(device, rb_copy, num_item<<2, read_idx, rb_count);
-
-	if (kgsl_ib_dump_enabled()) {
-		for (read_idx = 64; read_idx >= 0; --read_idx) {
-			uint32_t this_cmd = rb_copy[read_idx];
-			if (this_cmd == pm4_type3_packet(
-				PM4_INDIRECT_BUFFER_PFD, 2)) {
-				uint32_t ib_addr = rb_copy[read_idx+1];
-				uint32_t ib_size = rb_copy[read_idx+2];
-				if (cp_ib1_bufsz && cp_ib1_base == ib_addr) {
-					KGSL_LOG_DUMP(device,
-						"IB1: base:%8.8X  "
-						"count:%d\n", ib_addr, ib_size);
-					dump_ib(device, "IB1: ", pt_base,
-						read_idx<<2, ib_addr, ib_size,
-						1);
-				}
-			}
-		}
-		for (i = 0; i < ib_list.count; ++i) {
-			if (cp_ib2_bufsz && cp_ib2_base == ib_list.bases[i]) {
-				uint32_t ib_size = ib_list.sizes[i];
-				uint32_t ib_offset = ib_list.offsets[i];
-				KGSL_LOG_DUMP(device,
-					"IB2: base:%8.8X  count:%d\n",
-					cp_ib2_base, ib_size);
-				dump_ib(device, "IB2: ", pt_base, ib_offset,
-					ib_list.bases[i], ib_size, 1);
-			}
-		}
-	}
-
-	/* Dump the registers if the user asked for it */
-
-	for (i = 0; kgsl_pmregs_enabled() && kgsl_registers[i].id; i++) {
-		if (kgsl_registers[i].id == device->chip_id) {
-			kgsl_dump_regs(device, kgsl_registers[i].registers,
-				       kgsl_registers[i].len);
-			break;
-		}
-	}
-
-error_vfree:
-	vfree(rb_copy);
-end:
-	return result;
-}
-
-/**
- * kgsl_postmortem_dump - Dump the current GPU state
- * @device - A pointer to the KGSL device to dump
- * @manual - A flag that indicates if this was a manually triggered
- *           dump (from debugfs).  If zero, then this is assumed to be a
- *           dump automaticlaly triggered from a hang
-*/
-
-int kgsl_postmortem_dump(struct kgsl_device *device, int manual)
-{
-	bool saved_nap;
-
-	BUG_ON(device == NULL);
-
-	if (device->id == KGSL_DEVICE_YAMATO) {
-
-		/* For a manual dump, make sure that the system is idle */
-
-		if (manual) {
-			if (device->active_cnt != 0) {
-				mutex_unlock(&device->mutex);
-				wait_for_completion(&device->suspend_gate);
-				mutex_lock(&device->mutex);
-			}
-
-			if (device->state == KGSL_STATE_ACTIVE)
-				kgsl_idle(device,  KGSL_TIMEOUT_DEFAULT);
-
-		}
-		/* Disable the idle timer so we don't get interrupted */
-		del_timer(&device->idle_timer);
-
-		/* Turn off napping to make sure we have the clocks full
-		   attention through the following process */
-		saved_nap = device->pwrctrl.nap_allowed;
-		device->pwrctrl.nap_allowed = false;
-
-		/* Force on the clocks */
-		kgsl_pwrctrl_wake(device);
-
-		/* Disable the irq */
-		kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
-
-		/* If this is not a manual trigger, then set up the
-		   state to try to recover */
-
-		if (!manual) {
-			device->state = KGSL_STATE_DUMP_AND_RECOVER;
-			KGSL_PWR_WARN(device,
-				"state -> DUMP_AND_RECOVER, device %d\n",
-				device->id);
-		}
-
-		KGSL_DRV_ERR(device,
-			"wait for work in workqueue to complete\n");
-		mutex_unlock(&device->mutex);
-		flush_workqueue(device->work_queue);
-		mutex_lock(&device->mutex);
-		kgsl_dump_yamato(device);
-
-		/* Restore nap mode */
-		device->pwrctrl.nap_allowed = saved_nap;
-
-		/* On a manual trigger, turn on the interrupts and put
-		   the clocks to sleep.  They will recover themselves
-		   on the next event.  For a hang, leave things as they
-		   are until recovery kicks in. */
-
-		if (manual) {
-			kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_ON);
-
-			/* try to go into a sleep mode until the next event */
-			device->requested_state = KGSL_STATE_SLEEP;
-			kgsl_pwrctrl_sleep(device);
-		}
-	}
-	else
-		KGSL_DRV_CRIT(device, "Unknown device id - 0x%x\n", device->id);
-
-	KGSL_DRV_ERR(device, "Dump Finished\n");
-
-	KGSL_DRV_ERR(device, "Should not happen, reboot by kgsl\n");
-	hr_msleep(5000);
-	BUG_ON(true);
-
-	return 0;
-}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.h
deleted file mode 100644
index 9030120..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_postmortem.h
+++ /dev/null
@@ -1,37 +0,0 @@
-/* Copyright (c) 2010, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-
-#ifndef KGSL_POSTMORTEM_H
-#define KGSL_POSTMORTEM_H
-
-struct kgsl_device;
-
-int kgsl_postmortem_dump(struct kgsl_device *device, int manual);
-
-#endif /* KGSL_POSTMORTEM_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.c
index e68e180..23853b7 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.c
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.c
@@ -16,15 +16,9 @@
  *
  */
 #include <linux/interrupt.h>
-#include <linux/err.h>
-#include <linux/kernel.h>
-#include <mach/clk.h>
-#include <mach/dal_axi.h>
-#include <mach/msm_bus.h>
 #include <mach/msm_iomap.h>
 
 #include "kgsl.h"
-#include "kgsl_log.h"
 
 #define SWITCH_OFF		200
 #define TZ_UPDATE_ID		0x01404000
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.h
index 5766ccc..09f77a1 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.h
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_pwrctrl.h
@@ -26,16 +26,10 @@
  * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#ifndef _GSL_PWRCTRL_H
-#define _GSL_PWRCTRL_H
+#ifndef __KGSL_PWRCTRL_H
+#define __KGSL_PWRCTRL_H
 
-#include <linux/types.h>
-#include <linux/wait.h>
-#include <linux/clk.h>
-#include <linux/mutex.h>
-#include <mach/clk.h>
 #include <mach/internal_power_rail.h>
-#include <linux/pm_qos_params.h>
 
 /*****************************************************************************
 ** power flags
@@ -96,4 +90,4 @@ struct kgsl_pwrctrl {
 int kgsl_pwrctrl_init_sysfs(struct kgsl_device *device);
 void kgsl_pwrctrl_uninit_sysfs(struct kgsl_device *device);
 
-#endif /* _GSL_PWRCTRL_H */
+#endif /* __KGSL_PWRCTRL_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.c
deleted file mode 100644
index ca744cb..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.c
+++ /dev/null
@@ -1,945 +0,0 @@
-/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301, USA.
- *
- */
-#include <linux/firmware.h>
-#include <linux/io.h>
-#include <linux/sched.h>
-#include <linux/wait.h>
-#include <linux/slab.h>
-
-#include "kgsl.h"
-#include "kgsl_device.h"
-#include "kgsl_yamato.h"
-#include "kgsl_log.h"
-#include "kgsl_pm4types.h"
-#include "kgsl_ringbuffer.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_cffdump.h"
-
-#include "yamato_reg.h"
-
-#define VALID_STATUS_COUNT_MAX	10
-#define GSL_RB_NOP_SIZEDWORDS				2
-/* protected mode error checking below register address 0x800
-*  note: if CP_INTERRUPT packet is used then checking needs
-*  to change to below register address 0x7C8
-*/
-#define GSL_RB_PROTECTED_MODE_CONTROL		0x200001F2
-
-#define GSL_CP_INT_MASK \
-	(CP_INT_CNTL__SW_INT_MASK | \
-	CP_INT_CNTL__T0_PACKET_IN_IB_MASK | \
-	CP_INT_CNTL__OPCODE_ERROR_MASK | \
-	CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK | \
-	CP_INT_CNTL__RESERVED_BIT_ERROR_MASK | \
-	CP_INT_CNTL__IB_ERROR_MASK | \
-	CP_INT_CNTL__IB2_INT_MASK | \
-	CP_INT_CNTL__IB1_INT_MASK | \
-	CP_INT_CNTL__RB_INT_MASK)
-
-#define YAMATO_PFP_FW "yamato_pfp.fw"
-#define YAMATO_PM4_FW "yamato_pm4.fw"
-#define LEIA_PFP_470_FW "leia_pfp_470.fw"
-#define LEIA_PM4_470_FW "leia_pm4_470.fw"
-
-/*  ringbuffer size log2 quadwords equivalent */
-inline unsigned int kgsl_ringbuffer_sizelog2quadwords(unsigned int sizedwords)
-{
-	unsigned int sizelog2quadwords = 0;
-	int i = sizedwords >> 1;
-
-	while (i >>= 1)
-		sizelog2quadwords++;
-
-	return sizelog2quadwords;
-}
-
-
-/* functions */
-void kgsl_cp_intrcallback(struct kgsl_device *device)
-{
-	unsigned int status = 0, num_reads = 0, master_status = 0;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-
-	kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL, &master_status);
-	while (!status && (num_reads < VALID_STATUS_COUNT_MAX) &&
-		(master_status & MASTER_INT_SIGNAL__CP_INT_STAT)) {
-		kgsl_yamato_regread_isr(device, REG_CP_INT_STATUS, &status);
-		kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL,
-					&master_status);
-		num_reads++;
-	}
-	if (num_reads > 1)
-		KGSL_DRV_WARN(device,
-			"Looped %d times to read REG_CP_INT_STATUS\n",
-			num_reads);
-	if (!status) {
-		if (master_status & MASTER_INT_SIGNAL__CP_INT_STAT) {
-			/* This indicates that we could not read CP_INT_STAT.
-			 * As a precaution just wake up processes so
-			 * they can check their timestamps. Since, we
-			 * did not ack any interrupts this interrupt will
-			 * be generated again */
-			KGSL_DRV_WARN(device, "Unable to read CP_INT_STATUS\n");
-			wake_up_interruptible_all(&device->wait_queue);
-		} else
-			KGSL_DRV_WARN(device, "Spurious interrput detected\n");
-		return;
-	}
-
-	if (status & CP_INT_CNTL__RB_INT_MASK) {
-		/* signal intr completion event */
-		unsigned int enableflag = 0;
-		kgsl_sharedmem_writel(&rb->device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
-			enableflag);
-		wmb();
-		KGSL_CMD_WARN(rb->device, "ringbuffer rb interrupt\n");
-	}
-
-	if (status & CP_INT_CNTL__T0_PACKET_IN_IB_MASK) {
-		KGSL_CMD_CRIT(rb->device,
-			"ringbuffer TO packet in IB interrupt\n");
-		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
-	}
-	if (status & CP_INT_CNTL__OPCODE_ERROR_MASK) {
-		KGSL_CMD_CRIT(rb->device,
-			"ringbuffer opcode error interrupt\n");
-		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
-	}
-	if (status & CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK) {
-		KGSL_CMD_CRIT(rb->device,
-			"ringbuffer protected mode error interrupt\n");
-		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
-	}
-	if (status & CP_INT_CNTL__RESERVED_BIT_ERROR_MASK) {
-		KGSL_CMD_CRIT(rb->device,
-			"ringbuffer reserved bit error interrupt\n");
-		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
-	}
-	if (status & CP_INT_CNTL__IB_ERROR_MASK) {
-		KGSL_CMD_CRIT(rb->device,
-			"ringbuffer IB error interrupt\n");
-		kgsl_yamato_regwrite_isr(rb->device, REG_CP_INT_CNTL, 0);
-	}
-	if (status & CP_INT_CNTL__SW_INT_MASK)
-		KGSL_CMD_INFO(rb->device, "ringbuffer software interrupt\n");
-
-	if (status & CP_INT_CNTL__IB2_INT_MASK)
-		KGSL_CMD_INFO(rb->device, "ringbuffer ib2 interrupt\n");
-
-	if (status & (~GSL_CP_INT_MASK))
-		KGSL_CMD_WARN(rb->device,
-			"bad bits in REG_CP_INT_STATUS %08x\n", status);
-
-	/* only ack bits we understand */
-	status &= GSL_CP_INT_MASK;
-	kgsl_yamato_regwrite_isr(device, REG_CP_INT_ACK, status);
-
-	if (status & (CP_INT_CNTL__IB1_INT_MASK | CP_INT_CNTL__RB_INT_MASK)) {
-		KGSL_CMD_WARN(rb->device, "ringbuffer ib1/rb interrupt\n");
-		wake_up_interruptible_all(&device->wait_queue);
-		atomic_notifier_call_chain(&(device->ts_notifier_list),
-					   KGSL_DEVICE_YAMATO,
-					   NULL);
-	}
-}
-
-static void kgsl_ringbuffer_submit(struct kgsl_ringbuffer *rb)
-{
-	BUG_ON(rb->wptr == 0);
-
-	GSL_RB_UPDATE_WPTR_POLLING(rb);
-	/* Drain write buffer and data memory barrier */
-	dsb();
-	wmb();
-
-	/* Memory fence to ensure all data has posted.  On some systems,
-	* like 7x27, the register block is not allocated as strongly ordered
-	* memory.  Adding a memory fence ensures ordering during ringbuffer
-	* submits.*/
-	mb();
-	outer_sync();
-
-	kgsl_yamato_regwrite(rb->device, REG_CP_RB_WPTR, rb->wptr);
-
-	rb->flags |= KGSL_FLAGS_ACTIVE;
-}
-
-static int
-kgsl_ringbuffer_waitspace(struct kgsl_ringbuffer *rb, unsigned int numcmds,
-			  int wptr_ahead)
-{
-	int nopcount;
-	unsigned int freecmds;
-	unsigned int *cmds;
-	uint cmds_gpu;
-
-	/* if wptr ahead, fill the remaining with NOPs */
-	if (wptr_ahead) {
-		/* -1 for header */
-		nopcount = rb->sizedwords - rb->wptr - 1;
-
-		cmds = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
-		cmds_gpu = rb->buffer_desc.gpuaddr + sizeof(uint)*rb->wptr;
-
-		GSL_RB_WRITE(cmds, cmds_gpu, pm4_nop_packet(nopcount));
-
-		/* Make sure that rptr is not 0 before submitting
-		 * commands at the end of ringbuffer. We do not
-		 * want the rptr and wptr to become equal when
-		 * the ringbuffer is not empty */
-		do {
-			GSL_RB_GET_READPTR(rb, &rb->rptr);
-		} while (!rb->rptr);
-
-		rb->wptr++;
-
-		kgsl_ringbuffer_submit(rb);
-
-		rb->wptr = 0;
-	}
-
-	/* wait for space in ringbuffer */
-	do {
-		GSL_RB_GET_READPTR(rb, &rb->rptr);
-
-		freecmds = rb->rptr - rb->wptr;
-
-	} while ((freecmds != 0) && (freecmds <= numcmds));
-
-	return 0;
-}
-
-
-static unsigned int *kgsl_ringbuffer_allocspace(struct kgsl_ringbuffer *rb,
-					     unsigned int numcmds)
-{
-	unsigned int	*ptr = NULL;
-	int				status = 0;
-
-	BUG_ON(numcmds >= rb->sizedwords);
-
-	GSL_RB_GET_READPTR(rb, &rb->rptr);
-	/* check for available space */
-	if (rb->wptr >= rb->rptr) {
-		/* wptr ahead or equal to rptr */
-		/* reserve dwords for nop packet */
-		if ((rb->wptr + numcmds) > (rb->sizedwords -
-				GSL_RB_NOP_SIZEDWORDS))
-			status = kgsl_ringbuffer_waitspace(rb, numcmds, 1);
-	} else {
-		/* wptr behind rptr */
-		if ((rb->wptr + numcmds) >= rb->rptr)
-			status  = kgsl_ringbuffer_waitspace(rb, numcmds, 0);
-		/* check for remaining space */
-		/* reserve dwords for nop packet */
-		if ((rb->wptr + numcmds) > (rb->sizedwords -
-				GSL_RB_NOP_SIZEDWORDS))
-			status = kgsl_ringbuffer_waitspace(rb, numcmds, 1);
-	}
-
-	if (status == 0) {
-		ptr = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
-		rb->wptr += numcmds;
-	}
-
-	return ptr;
-}
-
-static int _load_firmware(struct kgsl_device *device, const char *fwfile,
-			  void **data, int *len)
-{
-	const struct firmware *fw = NULL;
-	int ret;
-
-	ret = request_firmware(&fw, fwfile, device->dev);
-
-	if (ret) {
-		KGSL_DRV_ERR(device, "request_firmware(%s) failed: %d\n",
-			     fwfile, ret);
-		return ret;
-	}
-
-	*data = kmalloc(fw->size, GFP_KERNEL);
-
-	if (*data) {
-		memcpy(*data, fw->data, fw->size);
-		*len = fw->size;
-	} else
-		KGSL_MEM_ERR(device, "kmalloc(%d) failed\n", fw->size);
-
-	release_firmware(fw);
-	return (*data != NULL) ? 0 : -ENOMEM;
-}
-
-static int kgsl_ringbuffer_load_pm4_ucode(struct kgsl_device *device)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	const char *fwfile;
-	int i, ret = 0;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		fwfile =  LEIA_PM4_470_FW;
-	else
-		fwfile =  YAMATO_PM4_FW;
-
-	if (yamato_device->pm4_fw == NULL) {
-		int len;
-		unsigned int *ptr;
-
-		ret = _load_firmware(device, fwfile, (void *) &ptr, &len);
-		if (ret)
-			goto err;
-
-		/* PM4 size is 3 dword aligned plus 1 dword of version */
-		if (len % ((sizeof(uint32_t) * 3)) != sizeof(uint32_t)) {
-			KGSL_DRV_ERR(device, "Bad firmware size: %d\n", len);
-			ret = -EINVAL;
-			goto err;
-		}
-
-		yamato_device->pm4_fw_size = len / sizeof(uint32_t);
-		yamato_device->pm4_fw = ptr;
-	}
-
-	KGSL_DRV_INFO(device, "loading pm4 ucode version: %d\n",
-		yamato_device->pm4_fw[0]);
-
-	kgsl_yamato_regwrite(device, REG_CP_DEBUG, 0x02000000);
-	kgsl_yamato_regwrite(device, REG_CP_ME_RAM_WADDR, 0);
-	for (i = 1; i < yamato_device->pm4_fw_size; i++)
-		kgsl_yamato_regwrite(device, REG_CP_ME_RAM_DATA,
-				     yamato_device->pm4_fw[i]);
-err:
-	return ret;
-}
-
-static int kgsl_ringbuffer_load_pfp_ucode(struct kgsl_device *device)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	const char *fwfile;
-	int i, ret = 0;
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		fwfile =  LEIA_PFP_470_FW;
-	else
-		fwfile = YAMATO_PFP_FW;
-
-	if (yamato_device->pfp_fw == NULL) {
-		int len;
-		unsigned int *ptr;
-
-		ret = _load_firmware(device, fwfile, (void *) &ptr, &len);
-		if (ret)
-			goto err;
-
-		/* PFP size shold be dword aligned */
-		if (len % sizeof(uint32_t) != 0) {
-			KGSL_DRV_ERR(device, "Bad firmware size: %d\n", len);
-			ret = -EINVAL;
-			goto err;
-		}
-
-		yamato_device->pfp_fw_size = len / sizeof(uint32_t);
-		yamato_device->pfp_fw = ptr;
-	}
-
-	KGSL_DRV_INFO(device, "loading pfp ucode version: %d\n",
-		yamato_device->pfp_fw[0]);
-
-	kgsl_yamato_regwrite(device, REG_CP_PFP_UCODE_ADDR, 0);
-	for (i = 1; i < yamato_device->pfp_fw_size; i++)
-		kgsl_yamato_regwrite(device, REG_CP_PFP_UCODE_DATA,
-				     yamato_device->pfp_fw[i]);
-err:
-	return ret;
-}
-
-int kgsl_ringbuffer_start(struct kgsl_ringbuffer *rb, unsigned int init_ram)
-{
-	int status;
-	/*cp_rb_cntl_u cp_rb_cntl; */
-	union reg_cp_rb_cntl cp_rb_cntl;
-	unsigned int *cmds, rb_cntl;
-	struct kgsl_device *device = rb->device;
-	uint cmds_gpu;
-
-	if (rb->flags & KGSL_FLAGS_STARTED)
-		return 0;
-
-	if (init_ram) {
-		rb->timestamp = 0;
-		GSL_RB_INIT_TIMESTAMP(rb);
-	}
-
-	kgsl_sharedmem_set(&rb->memptrs_desc, 0, 0,
-			   sizeof(struct kgsl_rbmemptrs));
-
-	kgsl_sharedmem_set(&rb->buffer_desc, 0, 0xAA,
-			   (rb->sizedwords << 2));
-
-	kgsl_yamato_regwrite(device, REG_CP_RB_WPTR_BASE,
-			     (rb->memptrs_desc.gpuaddr
-			      + GSL_RB_MEMPTRS_WPTRPOLL_OFFSET));
-
-	/* setup WPTR delay */
-	kgsl_yamato_regwrite(device, REG_CP_RB_WPTR_DELAY, 0 /*0x70000010 */);
-
-	/*setup REG_CP_RB_CNTL */
-	kgsl_yamato_regread(device, REG_CP_RB_CNTL, &rb_cntl);
-	cp_rb_cntl.val = rb_cntl;
-	/* size of ringbuffer */
-	cp_rb_cntl.f.rb_bufsz =
-		kgsl_ringbuffer_sizelog2quadwords(rb->sizedwords);
-	/* quadwords to read before updating mem RPTR */
-	cp_rb_cntl.f.rb_blksz = rb->blksizequadwords;
-	cp_rb_cntl.f.rb_poll_en = GSL_RB_CNTL_POLL_EN; /* WPTR polling */
-	/* mem RPTR writebacks */
-	cp_rb_cntl.f.rb_no_update =  GSL_RB_CNTL_NO_UPDATE;
-
-	kgsl_yamato_regwrite(device, REG_CP_RB_CNTL, cp_rb_cntl.val);
-
-	kgsl_yamato_regwrite(device, REG_CP_RB_BASE, rb->buffer_desc.gpuaddr);
-
-	kgsl_yamato_regwrite(device, REG_CP_RB_RPTR_ADDR,
-			     rb->memptrs_desc.gpuaddr +
-			     GSL_RB_MEMPTRS_RPTR_OFFSET);
-
-	/* explicitly clear all cp interrupts */
-	kgsl_yamato_regwrite(device, REG_CP_INT_ACK, 0xFFFFFFFF);
-
-	/* setup scratch/timestamp */
-	kgsl_yamato_regwrite(device, REG_SCRATCH_ADDR,
-			     device->memstore.gpuaddr +
-			     KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp));
-
-	kgsl_yamato_regwrite(device, REG_SCRATCH_UMSK,
-			     GSL_RB_MEMPTRS_SCRATCH_MASK);
-
-	/* load the CP ucode */
-
-	status = kgsl_ringbuffer_load_pm4_ucode(device);
-	if (status != 0)
-		return status;
-
-	/* load the prefetch parser ucode */
-	status = kgsl_ringbuffer_load_pfp_ucode(device);
-	if (status != 0)
-		return status;
-
-	kgsl_yamato_regwrite(device, REG_CP_QUEUE_THRESHOLDS, 0x000C0804);
-
-	rb->rptr = 0;
-	rb->wptr = 0;
-
-	/* clear ME_HALT to start micro engine */
-	kgsl_yamato_regwrite(device, REG_CP_ME_CNTL, 0);
-
-	/* ME_INIT */
-	cmds = kgsl_ringbuffer_allocspace(rb, 19);
-	cmds_gpu = rb->buffer_desc.gpuaddr + sizeof(uint)*(rb->wptr-19);
-
-	GSL_RB_WRITE(cmds, cmds_gpu, PM4_HDR_ME_INIT);
-	/* All fields present (bits 9:0) */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x000003ff);
-	/* Disable/Enable Real-Time Stream processing (present but ignored) */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-	/* Enable (2D <-> 3D) implicit synchronization (present but ignored) */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_RB_SURFACE_INFO));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SC_WINDOW_OFFSET));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_VGT_MAX_VTX_INDX));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_SQ_PROGRAM_CNTL));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_RB_DEPTHCONTROL));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SU_POINT_SIZE));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SC_LINE_CNTL));
-	GSL_RB_WRITE(cmds, cmds_gpu,
-		GSL_HAL_SUBBLOCK_OFFSET(REG_PA_SU_POLY_OFFSET_FRONT_SCALE));
-
-	/* Vertex and Pixel Shader Start Addresses in instructions
-	* (3 DWORDS per instruction) */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x80000180);
-	/* Maximum Contexts */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000001);
-	/* Write Confirm Interval and The CP will wait the
-	* wait_interval * 16 clocks between polling  */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-
-	/* NQ and External Memory Swap */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-	/* Protected mode error checking */
-	GSL_RB_WRITE(cmds, cmds_gpu, GSL_RB_PROTECTED_MODE_CONTROL);
-	/* Disable header dumping and Header dump address */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-	/* Header dump size */
-	GSL_RB_WRITE(cmds, cmds_gpu, 0x00000000);
-
-	kgsl_ringbuffer_submit(rb);
-
-	/* idle device to validate ME INIT */
-	status = kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-
-	kgsl_yamato_regwrite(rb->device, REG_CP_INT_CNTL, GSL_CP_INT_MASK);
-	if (status == 0)
-		rb->flags |= KGSL_FLAGS_STARTED;
-
-	return status;
-}
-
-int kgsl_ringbuffer_stop(struct kgsl_ringbuffer *rb)
-{
-	if (rb->flags & KGSL_FLAGS_STARTED) {
-		kgsl_yamato_regwrite(rb->device, REG_CP_INT_CNTL, 0);
-
-		/* ME_HALT */
-		kgsl_yamato_regwrite(rb->device, REG_CP_ME_CNTL, 0x10000000);
-
-		rb->flags &= ~KGSL_FLAGS_STARTED;
-	}
-
-	return 0;
-}
-
-int kgsl_ringbuffer_init(struct kgsl_device *device)
-{
-	int status;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-
-	rb->device = device;
-	rb->sizedwords = (2 << kgsl_cfg_rb_sizelog2quadwords);
-	rb->blksizequadwords = kgsl_cfg_rb_blksizequadwords;
-
-	/* allocate memory for ringbuffer */
-	status = kgsl_allocate_contig(&rb->buffer_desc, (rb->sizedwords << 2));
-	if (status != 0) {
-		kgsl_ringbuffer_close(rb);
-		return status;
-	}
-
-	/* allocate memory for polling and timestamps */
-	/* This really can be at 4 byte alignment boundry but for using MMU
-	 * we need to make it at page boundary */
-	status = kgsl_allocate_contig(&rb->memptrs_desc,
-	       sizeof(struct kgsl_rbmemptrs));
-	if (status != 0) {
-		kgsl_ringbuffer_close(rb);
-		return status;
-	}
-
-	/* overlay structure on memptrs memory */
-	rb->memptrs = (struct kgsl_rbmemptrs *) rb->memptrs_desc.hostptr;
-
-	return 0;
-}
-
-int kgsl_ringbuffer_close(struct kgsl_ringbuffer *rb)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(
-							rb->device);
-	if (rb->buffer_desc.hostptr)
-		kgsl_sharedmem_free(&rb->buffer_desc);
-
-	if (rb->memptrs_desc.hostptr)
-		kgsl_sharedmem_free(&rb->memptrs_desc);
-
-	if (yamato_device->pfp_fw != NULL)
-		kfree(yamato_device->pfp_fw);
-	if (yamato_device->pm4_fw != NULL)
-		kfree(yamato_device->pm4_fw);
-	yamato_device->pfp_fw = NULL;
-	yamato_device->pm4_fw = NULL;
-
-	memset(rb, 0, sizeof(struct kgsl_ringbuffer));
-
-	return 0;
-}
-
-static uint32_t
-kgsl_ringbuffer_addcmds(struct kgsl_ringbuffer *rb,
-				unsigned int flags, unsigned int *cmds,
-				int sizedwords)
-{
-	unsigned int *ringcmds;
-	unsigned int timestamp;
-	unsigned int total_sizedwords = sizedwords + 6;
-	unsigned int i;
-	unsigned int rcmd_gpu;
-
-	/* reserve space to temporarily turn off protected mode
-	*  error checking if needed
-	*/
-	total_sizedwords += flags & KGSL_CMD_FLAGS_PMODE ? 4 : 0;
-	total_sizedwords += !(flags & KGSL_CMD_FLAGS_NO_TS_CMP) ? 7 : 0;
-	total_sizedwords += !(flags & KGSL_CMD_FLAGS_NOT_KERNEL_CMD) ? 2 : 0;
-
-	ringcmds = kgsl_ringbuffer_allocspace(rb, total_sizedwords);
-	rcmd_gpu = rb->buffer_desc.gpuaddr
-		+ sizeof(uint)*(rb->wptr-total_sizedwords);
-
-	if (!(flags & KGSL_CMD_FLAGS_NOT_KERNEL_CMD)) {
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_nop_packet(1));
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, KGSL_CMD_IDENTIFIER);
-	}
-	if (flags & KGSL_CMD_FLAGS_PMODE) {
-		/* disable protected mode error checking */
-		GSL_RB_WRITE(ringcmds, rcmd_gpu,
-			pm4_type3_packet(PM4_SET_PROTECTED_MODE, 1));
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, 0);
-	}
-
-	for (i = 0; i < sizedwords; i++) {
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, *cmds);
-		cmds++;
-	}
-
-	if (flags & KGSL_CMD_FLAGS_PMODE) {
-		/* re-enable protected mode error checking */
-		GSL_RB_WRITE(ringcmds, rcmd_gpu,
-			pm4_type3_packet(PM4_SET_PROTECTED_MODE, 1));
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, 1);
-	}
-
-	rb->timestamp++;
-	timestamp = rb->timestamp;
-
-	/* start-of-pipeline and end-of-pipeline timestamps */
-	GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_type0_packet(REG_CP_TIMESTAMP, 1));
-	GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
-	GSL_RB_WRITE(ringcmds, rcmd_gpu, pm4_type3_packet(PM4_EVENT_WRITE, 3));
-	GSL_RB_WRITE(ringcmds, rcmd_gpu, CACHE_FLUSH_TS);
-	GSL_RB_WRITE(ringcmds, rcmd_gpu,
-		     (rb->device->memstore.gpuaddr +
-		      KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp)));
-	GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
-
-	if (!(flags & KGSL_CMD_FLAGS_NO_TS_CMP)) {
-		/* Conditional execution based on memory values */
-		GSL_RB_WRITE(ringcmds, rcmd_gpu,
-			pm4_type3_packet(PM4_COND_EXEC, 4));
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, (rb->device->memstore.gpuaddr +
-			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable)) >> 2);
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, (rb->device->memstore.gpuaddr +
-			KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts)) >> 2);
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, rb->timestamp);
-		/* # of conditional command DWORDs */
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, 2);
-		GSL_RB_WRITE(ringcmds, rcmd_gpu,
-			pm4_type3_packet(PM4_INTERRUPT, 1));
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, CP_INT_CNTL__RB_INT_MASK);
-	}
-
-	kgsl_ringbuffer_submit(rb);
-
-	/* return timestamp of issued coREG_ands */
-	return timestamp;
-}
-
-void
-kgsl_ringbuffer_issuecmds(struct kgsl_device *device,
-						unsigned int flags,
-						unsigned int *cmds,
-						int sizedwords)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-
-	if (device->state & KGSL_STATE_HUNG)
-		return;
-	kgsl_ringbuffer_addcmds(rb, flags, cmds, sizedwords);
-}
-
-int
-kgsl_ringbuffer_issueibcmds(struct kgsl_device_private *dev_priv,
-				struct kgsl_context *context,
-				struct kgsl_ibdesc *ibdesc,
-				unsigned int numibs,
-				uint32_t *timestamp,
-				unsigned int flags)
-{
-	struct kgsl_device *device = dev_priv->device;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	unsigned int *link;
-	unsigned int *cmds;
-	unsigned int i;
-	struct kgsl_yamato_context *drawctxt = context->devctxt;
-
-	if (device->state & KGSL_STATE_HUNG)
-		return -EBUSY;
-	if (!(yamato_device->ringbuffer.flags & KGSL_FLAGS_STARTED) ||
-	      context == NULL)
-		return -EINVAL;
-
-	BUG_ON(ibdesc == 0);
-	BUG_ON(numibs == 0);
-
-	if (drawctxt->flags & CTXT_FLAGS_GPU_HANG) {
-		KGSL_CTXT_WARN(device, "Context %p caused a gpu hang.."
-			" will not accept commands for this context\n",
-			drawctxt);
-		return -EDEADLK;
-	}
-	link = kzalloc(sizeof(unsigned int) * numibs * 3, GFP_KERNEL);
-	cmds = link;
-	if (!link) {
-		KGSL_MEM_ERR(device, "Failed to allocate memory for for command"
-			" submission, size %x\n", numibs * 3);
-		return -ENOMEM;
-	}
-	for (i = 0; i < numibs; i++) {
-		(void)kgsl_cffdump_parse_ibs(dev_priv, NULL,
-			ibdesc[i].gpuaddr, ibdesc[i].sizedwords, false);
-
-		*cmds++ = PM4_HDR_INDIRECT_BUFFER_PFD;
-		*cmds++ = ibdesc[i].gpuaddr;
-		*cmds++ = ibdesc[i].sizedwords;
-	}
-
-	kgsl_setstate(device,
-		      kgsl_pt_get_flags(device->mmu.hwpagetable,
-					device->id));
-
-	kgsl_drawctxt_switch(yamato_device, drawctxt, flags);
-
-	*timestamp = kgsl_ringbuffer_addcmds(&yamato_device->ringbuffer,
-					KGSL_CMD_FLAGS_NOT_KERNEL_CMD,
-					&link[0], (cmds - link));
-
-	KGSL_CMD_INFO(device, "ctxt %d g %08x numibs %d ts %d\n",
-		context->id, (unsigned int)ibdesc, numibs, *timestamp);
-
-	kfree(link);
-
-#ifdef CONFIG_MSM_KGSL_CFF_DUMP
-	/*
-	 * insert wait for idle after every IB1
-	 * this is conservative but works reliably and is ok
-	 * even for performance simulations
-	 */
-	kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-#endif
-
-	return 0;
-}
-
-int kgsl_ringbuffer_extract(struct kgsl_ringbuffer *rb,
-				unsigned int *temp_rb_buffer,
-				int *rb_size)
-{
-	struct kgsl_device *device = rb->device;
-	unsigned int rb_rptr;
-	unsigned int retired_timestamp;
-	unsigned int temp_idx = 0;
-	unsigned int value;
-	unsigned int val1;
-	unsigned int val2;
-	unsigned int val3;
-	unsigned int copy_rb_contents = 0;
-	unsigned int cur_context;
-	unsigned int j;
-
-	GSL_RB_GET_READPTR(rb, &rb->rptr);
-
-	retired_timestamp = device->ftbl.device_cmdstream_readtimestamp(
-				device, KGSL_TIMESTAMP_RETIRED);
-	rmb();
-	KGSL_DRV_ERR(device, "GPU successfully executed till ts: %x\n",
-			retired_timestamp);
-	/*
-	 * We need to go back in history by 4 dwords from the current location
-	 * of read pointer as 4 dwords are read to match the end of a command.
-	 * Also, take care of wrap around when moving back
-	 */
-	if (rb->rptr >= 4)
-		rb_rptr = (rb->rptr - 4) * sizeof(unsigned int);
-	else
-		rb_rptr = rb->buffer_desc.size -
-			((4 - rb->rptr) * sizeof(unsigned int));
-	/* Read the rb contents going backwards to locate end of last
-	 * sucessfully executed command */
-	while ((rb_rptr / sizeof(unsigned int)) != rb->wptr) {
-		kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
-		rmb();
-		if (value == retired_timestamp) {
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			kgsl_sharedmem_readl(&rb->buffer_desc, &val2, rb_rptr);
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			kgsl_sharedmem_readl(&rb->buffer_desc, &val3, rb_rptr);
-			rmb();
-			/* match the pattern found at the end of a command */
-			if ((val1 == 2 &&
-				val2 == pm4_type3_packet(PM4_INTERRUPT, 1)
-				&& val3 == CP_INT_CNTL__RB_INT_MASK) ||
-				(val1 == pm4_type3_packet(PM4_EVENT_WRITE, 3)
-				&& val2 == CACHE_FLUSH_TS &&
-				val3 == (rb->device->memstore.gpuaddr +
-				KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp)))) {
-				rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-				KGSL_DRV_ERR(device,
-					"Found end of last executed "
-					"command at offset: %x\n",
-					rb_rptr / sizeof(unsigned int));
-				break;
-			} else {
-				if (rb_rptr < (3 * sizeof(unsigned int)))
-					rb_rptr = rb->buffer_desc.size -
-						(3 * sizeof(unsigned int))
-							+ rb_rptr;
-				else
-					rb_rptr -= (3 * sizeof(unsigned int));
-			}
-		}
-
-		if (rb_rptr == 0)
-			rb_rptr = rb->buffer_desc.size - sizeof(unsigned int);
-		else
-			rb_rptr -= sizeof(unsigned int);
-	}
-
-	if ((rb_rptr / sizeof(unsigned int)) == rb->wptr) {
-		KGSL_DRV_ERR(device,
-			"GPU recovery from hang not possible because last"
-			" successful timestamp is overwritten\n");
-		return -EINVAL;
-	}
-	/* rb_rptr is now pointing to the first dword of the command following
-	 * the last sucessfully executed command sequence. Assumption is that
-	 * GPU is hung in the command sequence pointed by rb_rptr */
-	/* make sure the GPU is not hung in a command submitted by kgsl
-	 * itself */
-	kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
-	kgsl_sharedmem_readl(&rb->buffer_desc, &val2,
-				adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size));
-	rmb();
-	if (val1 == pm4_nop_packet(1) && val2 == KGSL_CMD_IDENTIFIER) {
-		KGSL_DRV_ERR(device,
-			"GPU recovery from hang not possible because "
-			"of hang in kgsl command\n");
-		return -EINVAL;
-	}
-
-	/* current_context is the context that is presently active in the
-	 * GPU, i.e the context in which the hang is caused */
-	kgsl_sharedmem_readl(&device->memstore, &cur_context,
-		KGSL_DEVICE_MEMSTORE_OFFSET(current_context));
-	while ((rb_rptr / sizeof(unsigned int)) != rb->wptr) {
-		kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
-		rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-						rb->buffer_desc.size);
-		rmb();
-		/* check for context switch indicator */
-		if (value == KGSL_CONTEXT_TO_MEM_IDENTIFIER) {
-			kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			rmb();
-			BUG_ON(value != pm4_type3_packet(PM4_MEM_WRITE, 2));
-			kgsl_sharedmem_readl(&rb->buffer_desc, &val1, rb_rptr);
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			rmb();
-			BUG_ON(val1 != (device->memstore.gpuaddr +
-				KGSL_DEVICE_MEMSTORE_OFFSET(current_context)));
-			kgsl_sharedmem_readl(&rb->buffer_desc, &value, rb_rptr);
-			rb_rptr = adreno_ringbuffer_inc_wrapped(rb_rptr,
-							rb->buffer_desc.size);
-			rmb();
-			BUG_ON((copy_rb_contents == 0) &&
-				(value == cur_context));
-			/* if context switches to a context that did not cause
-			 * hang then start saving the rb contents as those
-			 * commands can be executed */
-			if (value != cur_context) {
-				copy_rb_contents = 1;
-				temp_rb_buffer[temp_idx++] = pm4_nop_packet(1);
-				temp_rb_buffer[temp_idx++] =
-						KGSL_CMD_IDENTIFIER;
-				temp_rb_buffer[temp_idx++] = pm4_nop_packet(1);
-				temp_rb_buffer[temp_idx++] =
-						KGSL_CONTEXT_TO_MEM_IDENTIFIER;
-				temp_rb_buffer[temp_idx++] =
-					pm4_type3_packet(PM4_MEM_WRITE, 2);
-				temp_rb_buffer[temp_idx++] = val1;
-				temp_rb_buffer[temp_idx++] = value;
-			} else {
-				/* if temp_idx is not 0 then we do not need to
-				 * copy extra dwords indicating a kernel cmd */
-				if (temp_idx)
-					temp_idx -= 3;
-				copy_rb_contents = 0;
-			}
-		} else if (copy_rb_contents)
-			temp_rb_buffer[temp_idx++] = value;
-	}
-
-	*rb_size = temp_idx;
-	KGSL_DRV_ERR(device, "Extracted rb contents, size: %x\n", *rb_size);
-	for (temp_idx = 0; temp_idx < *rb_size;) {
-		char str[80];
-		int idx = 0;
-		if ((temp_idx + 8) <= *rb_size)
-			j = 8;
-		else
-			j = *rb_size - temp_idx;
-		for (; j != 0; j--)
-			idx += scnprintf(str + idx, 80 - idx,
-				"%8.8X ", temp_rb_buffer[temp_idx++]);
-		printk(KERN_ALERT "%s", str);
-	}
-	return 0;
-}
-
-void
-kgsl_ringbuffer_restore(struct kgsl_ringbuffer *rb, unsigned int *rb_buff,
-			int num_rb_contents)
-{
-	int i;
-	unsigned int *ringcmds;
-	unsigned int rcmd_gpu;
-
-	if (!num_rb_contents)
-		return;
-
-	if (num_rb_contents > (rb->buffer_desc.size - rb->wptr)) {
-		kgsl_yamato_regwrite(rb->device, REG_CP_RB_RPTR, 0);
-		rb->rptr = 0;
-		BUG_ON(num_rb_contents > rb->buffer_desc.size);
-	}
-	ringcmds = (unsigned int *)rb->buffer_desc.hostptr + rb->wptr;
-	rcmd_gpu = rb->buffer_desc.gpuaddr + sizeof(unsigned int) * rb->wptr;
-	for (i = 0; i < num_rb_contents; i++)
-		GSL_RB_WRITE(ringcmds, rcmd_gpu, rb_buff[i]);
-	rb->wptr += num_rb_contents;
-	kgsl_ringbuffer_submit(rb);
-}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.h
deleted file mode 100644
index 71db0f7..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_ringbuffer.h
+++ /dev/null
@@ -1,211 +0,0 @@
-/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef __GSL_RINGBUFFER_H
-#define __GSL_RINGBUFFER_H
-#include <linux/msm_kgsl.h>
-#include <linux/mutex.h>
-#include "yamato_reg.h"
-
-#define GSL_RB_USE_MEM_RPTR
-#define GSL_RB_USE_MEM_TIMESTAMP
-#define GSL_DEVICE_SHADOW_MEMSTORE_TO_USER
-
-/* ringbuffer sizes log2quadword */
-#define GSL_RB_SIZE_8	 	0
-#define GSL_RB_SIZE_16		1
-#define GSL_RB_SIZE_32		2
-#define GSL_RB_SIZE_64		3
-#define GSL_RB_SIZE_128		4
-#define GSL_RB_SIZE_256		5
-#define GSL_RB_SIZE_512		6
-#define GSL_RB_SIZE_1K  	7
-#define GSL_RB_SIZE_2K  	8
-#define GSL_RB_SIZE_4K  	9
-#define GSL_RB_SIZE_8K  	10
-#define GSL_RB_SIZE_16K 	11
-#define GSL_RB_SIZE_32K 	12
-#define GSL_RB_SIZE_64K 	13
-#define GSL_RB_SIZE_128K	14
-#define GSL_RB_SIZE_256K	15
-#define GSL_RB_SIZE_512K	16
-#define GSL_RB_SIZE_1M		17
-#define GSL_RB_SIZE_2M		18
-#define GSL_RB_SIZE_4M		19
-
-/* Yamato ringbuffer config*/
-static const unsigned int kgsl_cfg_rb_sizelog2quadwords = GSL_RB_SIZE_32K;
-static const unsigned int kgsl_cfg_rb_blksizequadwords  = GSL_RB_SIZE_16;
-
-/* CP timestamp register */
-#define	REG_CP_TIMESTAMP		 REG_SCRATCH_REG0
-
-
-struct kgsl_device;
-struct kgsl_device_private;
-
-#define GSL_RB_MEMPTRS_SCRATCH_COUNT	 8
-struct kgsl_rbmemptrs {
-	int  rptr;
-	int  wptr_poll;
-};
-
-#define GSL_RB_MEMPTRS_RPTR_OFFSET \
-	(offsetof(struct kgsl_rbmemptrs, rptr))
-
-#define GSL_RB_MEMPTRS_WPTRPOLL_OFFSET \
-	(offsetof(struct kgsl_rbmemptrs, wptr_poll))
-
-struct kgsl_ringbuffer {
-	struct kgsl_device *device;
-	uint32_t flags;
-
-	struct kgsl_memdesc buffer_desc;
-
-	struct kgsl_memdesc memptrs_desc;
-	struct kgsl_rbmemptrs *memptrs;
-
-	/*ringbuffer size */
-	unsigned int sizedwords;
-	unsigned int blksizequadwords;
-
-	unsigned int wptr; /* write pointer offset in dwords from baseaddr */
-	unsigned int rptr; /* read pointer offset in dwords from baseaddr */
-	uint32_t timestamp;
-};
-
-/* dword base address of the GFX decode space */
-#define GSL_HAL_SUBBLOCK_OFFSET(reg) ((unsigned int)((reg) - (0x2000)))
-
-#define GSL_RB_WRITE(ring, gpuaddr, data) \
-	do { \
-		writel(data, ring); \
-		kgsl_cffdump_setmem(gpuaddr, data, 4); \
-		ring++; \
-		gpuaddr += sizeof(uint); \
-		wmb(); \
-	} while (0)
-
-/* timestamp */
-#ifdef GSL_DEVICE_SHADOW_MEMSTORE_TO_USER
-#define GSL_RB_USE_MEM_TIMESTAMP
-#endif /* GSL_DEVICE_SHADOW_MEMSTORE_TO_USER */
-
-#ifdef GSL_RB_USE_MEM_TIMESTAMP
-/* enable timestamp (...scratch0) memory shadowing */
-#define GSL_RB_MEMPTRS_SCRATCH_MASK 0x1
-#define GSL_RB_INIT_TIMESTAMP(rb)
-
-#else
-#define GSL_RB_MEMPTRS_SCRATCH_MASK 0x0
-#define GSL_RB_INIT_TIMESTAMP(rb) \
-		kgsl_yamato_regwrite((rb)->device->id, REG_CP_TIMESTAMP, 0)
-
-#endif /* GSL_RB_USE_MEMTIMESTAMP */
-
-/* mem rptr */
-#ifdef GSL_RB_USE_MEM_RPTR
-#define GSL_RB_CNTL_NO_UPDATE 0x0 /* enable */
-#define GSL_RB_GET_READPTR(rb, data) \
-	do { \
-		*(data) = readl(&(rb)->memptrs->rptr); \
-		rmb(); \
-	} while (0)
-#else
-#define GSL_RB_CNTL_NO_UPDATE 0x1 /* disable */
-#define GSL_RB_GET_READPTR(rb, data) \
-	do { \
-		kgsl_yamato_regread((rb)->device->id, REG_CP_RB_RPTR, (data)); \
-	} while (0)
-#endif /* GSL_RB_USE_MEMRPTR */
-
-/* wptr polling */
-#ifdef GSL_RB_USE_WPTR_POLLING
-#define GSL_RB_CNTL_POLL_EN 0x1 /* enable */
-#define GSL_RB_UPDATE_WPTR_POLLING(rb) \
-	do { writel((rb)->wptr, &((rb)->memptrs->wptr_poll)); } while (0)
-#else
-#define GSL_RB_CNTL_POLL_EN 0x0 /* disable */
-#define GSL_RB_UPDATE_WPTR_POLLING(rb)
-#endif	/* GSL_RB_USE_WPTR_POLLING */
-
-int kgsl_ringbuffer_issueibcmds(struct kgsl_device_private *dev_priv,
-				struct kgsl_context *context,
-				struct kgsl_ibdesc *ibdesc, unsigned int numibs,
-				uint32_t *timestamp,
-				unsigned int flags);
-
-int kgsl_ringbuffer_init(struct kgsl_device *device);
-
-int kgsl_ringbuffer_start(struct kgsl_ringbuffer *rb, unsigned int init_ram);
-
-int kgsl_ringbuffer_stop(struct kgsl_ringbuffer *rb);
-
-int kgsl_ringbuffer_close(struct kgsl_ringbuffer *rb);
-
-void kgsl_ringbuffer_issuecmds(struct kgsl_device *device,
-					unsigned int flags,
-					unsigned int *cmdaddr,
-					int sizedwords);
-
-int kgsl_ringbuffer_gettimestampshadow(struct kgsl_device *device,
-					unsigned int *sopaddr,
-					unsigned int *eopaddr);
-
-void kgsl_cp_intrcallback(struct kgsl_device *device);
-
-int kgsl_ringbuffer_extract(struct kgsl_ringbuffer *rb,
-				unsigned int *temp_rb_buffer,
-				int *rb_size);
-
-void
-kgsl_ringbuffer_restore(struct kgsl_ringbuffer *rb, unsigned int *rb_buff,
-			int num_rb_contents);
-
-static inline int kgsl_ringbuffer_count(struct kgsl_ringbuffer *rb,
-	unsigned int rptr)
-{
-	if (rb->wptr >= rptr)
-		return rb->wptr - rptr;
-	return rb->wptr + rb->sizedwords - rptr;
-}
-
-/* Increment a value by 4 bytes with wrap-around based on size */
-static inline unsigned int adreno_ringbuffer_inc_wrapped(unsigned int val,
-							unsigned int size)
-{
-	return (val + sizeof(unsigned int)) % size;
-}
-
-static inline int
-kgsl_allocate_contig(struct kgsl_memdesc *memdesc, size_t size)
-{
-	return kgsl_sharedmem_alloc_coherent(memdesc, size);
-}
-
-#endif  /* __GSL_RINGBUFFER_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.c
index 55d9d53..0d4a0e7 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.c
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.c
@@ -15,18 +15,11 @@
  * 02110-1301, USA.
  *
  */
-#include <linux/io.h>
-#include <linux/spinlock.h>
-#include <linux/genalloc.h>
-#include <linux/dma-mapping.h>
-#include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <asm/cacheflush.h>
 
-#include "kgsl_sharedmem.h"
-#include "kgsl_device.h"
 #include "kgsl.h"
-#include "kgsl_log.h"
+#include "kgsl_sharedmem.h"
 #include "kgsl_cffdump.h"
 
 static struct kgsl_process_private *
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.h
index 45a7c21..fcc91cd 100644
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.h
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_sharedmem.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2002,2007-2010, Code Aurora Forum. All rights reserved.
+/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -26,8 +26,8 @@
  * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#ifndef __GSL_SHAREDMEM_H
-#define __GSL_SHAREDMEM_H
+#ifndef __KGSL_SHAREDMEM_H
+#define __KGSL_SHAREDMEM_H
 
 #include <linux/dma-mapping.h>
 
@@ -39,8 +39,6 @@
 #define KGSL_CACHE_OP_FLUSH     0x02
 #define KGSL_CACHE_OP_CLEAN     0x03
 
-/** memdesc->priv flags */
-
 /** Set if the memdesc describes cached memory */
 #define KGSL_MEMFLAGS_CACHED    0x00000001
 
@@ -58,7 +56,7 @@ struct kgsl_memdesc_ops {
 /* shared memory allocation */
 struct kgsl_memdesc {
 	struct kgsl_pagetable *pagetable;
-	void  *hostptr;
+	void *hostptr;
 	unsigned int gpuaddr;
 	unsigned int physaddr;
 	unsigned int size;
@@ -108,4 +106,4 @@ int kgsl_sharedmem_set(const struct kgsl_memdesc *memdesc,
 {
 	return kgsl_sharedmem_vmalloc_user(memdesc, pagetable, size, flags);
 }
-#endif /* __GSL_SHAREDMEM_H */
+#endif /* __KGSL_SHAREDMEM_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.c
deleted file mode 100644
index 0cc6691..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.c
+++ /dev/null
@@ -1,1326 +0,0 @@
-/* Copyright (c) 2002,2007-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301, USA.
- *
- */
-#include <linux/delay.h>
-#include <linux/uaccess.h>
-#include <linux/fs.h>
-#include <linux/io.h>
-#include <linux/sched.h>
-#include <linux/timer.h>
-#include <linux/workqueue.h>
-#include <linux/notifier.h>
-#include <linux/pm_runtime.h>
-
-#include <mach/msm_bus.h>
-#include <linux/vmalloc.h>
-
-#include "kgsl.h"
-#include "kgsl_yamato.h"
-#include "kgsl_log.h"
-#include "kgsl_pm4types.h"
-#include "kgsl_cmdstream.h"
-#include "kgsl_postmortem.h"
-#include "kgsl_cffdump.h"
-#include "kgsl_drawctxt.h"
-#include "kgsl_yamato_debugfs.h"
-
-#include "yamato_reg.h"
-
-#define DRIVER_VERSION_MAJOR   3
-#define DRIVER_VERSION_MINOR   1
-
-#define GSL_RBBM_INT_MASK \
-	 (RBBM_INT_CNTL__RDERR_INT_MASK |  \
-	  RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK)
-
-#define GSL_SQ_INT_MASK \
-	(SQ_INT_CNTL__PS_WATCHDOG_MASK | \
-	 SQ_INT_CNTL__VS_WATCHDOG_MASK)
-
-/* Yamato MH arbiter config*/
-#define KGSL_CFG_YAMATO_MHARB \
-	(0x10 \
-		| (0 << MH_ARBITER_CONFIG__SAME_PAGE_GRANULARITY__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__L1_ARB_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__L1_ARB_HOLD_ENABLE__SHIFT) \
-		| (0 << MH_ARBITER_CONFIG__L2_ARB_CONTROL__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__PAGE_SIZE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__TC_REORDER_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__TC_ARB_HOLD_ENABLE__SHIFT) \
-		| (0 << MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT_ENABLE__SHIFT) \
-		| (0x8 << MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__CP_CLNT_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__VGT_CLNT_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__TC_CLNT_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__RB_CLNT_ENABLE__SHIFT) \
-		| (1 << MH_ARBITER_CONFIG__PA_CLNT_ENABLE__SHIFT))
-
-#define YAMATO_MMU_CONFIG						\
-	(0x01								\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__RB_W_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_W_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R0_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R1_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R2_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R3_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__CP_R4_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__VGT_R0_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__VGT_R1_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__TC_R_CLNT_BEHAVIOR__SHIFT)	\
-	 | (MMU_CONFIG << MH_MMU_CONFIG__PA_W_CLNT_BEHAVIOR__SHIFT))
-
-static struct kgsl_yamato_device yamato_device = {
-	.dev = {
-		.name = DEVICE_3D0_NAME,
-		.id = KGSL_DEVICE_YAMATO,
-		.ver_major = DRIVER_VERSION_MAJOR,
-		.ver_minor = DRIVER_VERSION_MINOR,
-		.mmu = {
-			.config = YAMATO_MMU_CONFIG,
-			/* turn off memory protection unit by setting
-			   acceptable physical address range to include
-			   all pages. */
-			.mpu_base = 0x00000000,
-			.mpu_range =  0xFFFFF000,
-			.reg = {
-				.config = REG_MH_MMU_CONFIG,
-				.mpu_base = REG_MH_MMU_MPU_BASE,
-				.mpu_end = REG_MH_MMU_MPU_END,
-				.va_range = REG_MH_MMU_VA_RANGE,
-				.pt_page = REG_MH_MMU_PT_BASE,
-				.page_fault = REG_MH_MMU_PAGE_FAULT,
-				.tran_error = REG_MH_MMU_TRAN_ERROR,
-				.invalidate = REG_MH_MMU_INVALIDATE,
-				.interrupt_mask = REG_MH_INTERRUPT_MASK,
-				.interrupt_status = REG_MH_INTERRUPT_STATUS,
-				.interrupt_clear = REG_MH_INTERRUPT_CLEAR,
-				.axi_error = REG_MH_AXI_ERROR,
-			},
-		},
-		.pwrctrl = {
-			.pwr_rail = PWR_RAIL_GRP_CLK,
-			.regulator_name = "fs_gfx3d",
-			.irq_name = KGSL_3D0_IRQ,
-			.src_clk_name = "grp_src_clk",
-		},
-		.mutex = __MUTEX_INITIALIZER(yamato_device.dev.mutex),
-		.state = KGSL_STATE_INIT,
-		.active_cnt = 0,
-		.iomemname = KGSL_3D0_REG_MEMORY,
-	},
-	.gmemspace = {
-		.gpu_base = 0,
-		.sizebytes = SZ_256K,
-	},
-	.pfp_fw = NULL,
-	.pm4_fw = NULL,
-};
-
-/* max msecs to wait for gpu to finish its operation(s) */
-#define MAX_WAITGPU_SECS (10*(HZ + HZ/2))
-
-
-static int kgsl_yamato_start(struct kgsl_device *device,
-						unsigned int init_ram);
-static int kgsl_yamato_stop(struct kgsl_device *device);
-
-static int kgsl_yamato_gmeminit(struct kgsl_yamato_device *yamato_device)
-{
-	struct kgsl_device *device = &yamato_device->dev;
-	union reg_rb_edram_info rb_edram_info;
-	unsigned int gmem_size;
-	unsigned int edram_value = 0;
-
-	/* make sure edram range is aligned to size */
-	BUG_ON(yamato_device->gmemspace.gpu_base &
-				(yamato_device->gmemspace.sizebytes - 1));
-
-	/* get edram_size value equivalent */
-	gmem_size = (yamato_device->gmemspace.sizebytes >> 14);
-	while (gmem_size >>= 1)
-		edram_value++;
-
-	rb_edram_info.val = 0;
-
-	rb_edram_info.f.edram_size = edram_value;
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
-		rb_edram_info.f.edram_mapping_mode = 0; /* EDRAM_MAP_UPPER */
-
-	/* must be aligned to size */
-	rb_edram_info.f.edram_range = (yamato_device->gmemspace.gpu_base >> 14);
-
-	kgsl_yamato_regwrite(device, REG_RB_EDRAM_INFO, rb_edram_info.val);
-
-	return 0;
-}
-
-static int kgsl_yamato_gmemclose(struct kgsl_device *device)
-{
-	kgsl_yamato_regwrite(device, REG_RB_EDRAM_INFO, 0x00000000);
-
-	return 0;
-}
-
-static void kgsl_yamato_rbbm_intrcallback(struct kgsl_device *device)
-{
-	unsigned int status = 0;
-	unsigned int rderr = 0;
-
-	kgsl_yamato_regread_isr(device, REG_RBBM_INT_STATUS, &status);
-
-	if (status & RBBM_INT_CNTL__RDERR_INT_MASK) {
-		union rbbm_read_error_u rerr;
-		kgsl_yamato_regread_isr(device, REG_RBBM_READ_ERROR, &rderr);
-		rerr.val = rderr;
-		if (rerr.f.read_address == REG_CP_INT_STATUS &&
-			rerr.f.read_error &&
-			rerr.f.read_requester)
-			KGSL_DRV_WARN(device,
-				"rbbm read error interrupt: %08x\n", rderr);
-		else
-			KGSL_DRV_CRIT(device,
-				"rbbm read error interrupt: %08x\n", rderr);
-	} else if (status & RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK) {
-		KGSL_DRV_INFO(device, "rbbm display update interrupt\n");
-	} else if (status & RBBM_INT_CNTL__GUI_IDLE_INT_MASK) {
-		KGSL_DRV_INFO(device, "rbbm gui idle interrupt\n");
-	} else {
-		KGSL_CMD_WARN(device,
-			"bad bits in REG_CP_INT_STATUS %08x\n", status);
-	}
-
-	status &= GSL_RBBM_INT_MASK;
-	kgsl_yamato_regwrite_isr(device, REG_RBBM_INT_ACK, status);
-}
-
-static void kgsl_yamato_sq_intrcallback(struct kgsl_device *device)
-{
-	unsigned int status = 0;
-
-	kgsl_yamato_regread_isr(device, REG_SQ_INT_STATUS, &status);
-
-	if (status & SQ_INT_CNTL__PS_WATCHDOG_MASK)
-		KGSL_DRV_INFO(device, "sq ps watchdog interrupt\n");
-	else if (status & SQ_INT_CNTL__VS_WATCHDOG_MASK)
-		KGSL_DRV_INFO(device, "sq vs watchdog interrupt\n");
-	else
-		KGSL_DRV_WARN(device,
-			"bad bits in REG_SQ_INT_STATUS %08x\n", status);
-
-
-	status &= GSL_SQ_INT_MASK;
-	kgsl_yamato_regwrite_isr(device, REG_SQ_INT_ACK, status);
-}
-
-irqreturn_t kgsl_yamato_isr(int irq, void *data)
-{
-	irqreturn_t result = IRQ_NONE;
-	struct kgsl_device *device;
-	unsigned int status;
-
-	device = (struct kgsl_device *) data;
-
-	BUG_ON(device == NULL);
-	BUG_ON(device->regspace.sizebytes == 0);
-	BUG_ON(device->regspace.mmio_virt_base == 0);
-
-	kgsl_yamato_regread_isr(device, REG_MASTER_INT_SIGNAL, &status);
-
-	if (status & MASTER_INT_SIGNAL__MH_INT_STAT) {
-		kgsl_mh_intrcallback(device);
-		result = IRQ_HANDLED;
-	}
-
-	if (status & MASTER_INT_SIGNAL__CP_INT_STAT) {
-		kgsl_cp_intrcallback(device);
-		result = IRQ_HANDLED;
-	}
-
-	if (status & MASTER_INT_SIGNAL__RBBM_INT_STAT) {
-		kgsl_yamato_rbbm_intrcallback(device);
-		result = IRQ_HANDLED;
-	}
-
-	if (status & MASTER_INT_SIGNAL__SQ_INT_STAT) {
-		kgsl_yamato_sq_intrcallback(device);
-		result = IRQ_HANDLED;
-	}
-
-	if (device->requested_state == KGSL_STATE_NONE) {
-		if (device->pwrctrl.nap_allowed == true) {
-			device->requested_state = KGSL_STATE_NAP;
-			queue_work(device->work_queue, &device->idle_check_ws);
-		} else if (device->pwrctrl.idle_pass == true) {
-			queue_work(device->work_queue, &device->idle_check_ws);
-		}
-	}
-
-	/* Reset the time-out in our idle timer */
-	mod_timer(&device->idle_timer,
-		jiffies + device->pwrctrl.interval_timeout);
-	return result;
-}
-
-static int kgsl_yamato_cleanup_pt(struct kgsl_device *device,
-			struct kgsl_pagetable *pagetable)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-
-	kgsl_mmu_unmap(pagetable, &rb->buffer_desc);
-
-	kgsl_mmu_unmap(pagetable, &rb->memptrs_desc);
-
-	kgsl_mmu_unmap(pagetable, &device->memstore);
-
-	kgsl_mmu_unmap(pagetable, &device->mmu.dummyspace);
-
-	return 0;
-}
-
-static int kgsl_yamato_setup_pt(struct kgsl_device *device,
-			struct kgsl_pagetable *pagetable)
-{
-	int result = 0;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-
-	BUG_ON(rb->buffer_desc.physaddr == 0);
-	BUG_ON(rb->memptrs_desc.physaddr == 0);
-	BUG_ON(device->memstore.physaddr == 0);
-#ifdef CONFIG_MSM_KGSL_MMU
-	BUG_ON(device->mmu.dummyspace.physaddr == 0);
-#endif
-	result = kgsl_mmu_map_global(pagetable, &rb->buffer_desc,
-				     GSL_PT_PAGE_RV);
-	if (result)
-		goto error;
-
-	result = kgsl_mmu_map_global(pagetable, &rb->memptrs_desc,
-				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
-	if (result)
-		goto unmap_buffer_desc;
-
-	result = kgsl_mmu_map_global(pagetable, &device->memstore,
-				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
-	if (result)
-		goto unmap_memptrs_desc;
-
-	result = kgsl_mmu_map_global(pagetable, &device->mmu.dummyspace,
-				     GSL_PT_PAGE_RV | GSL_PT_PAGE_WV);
-	if (result)
-		goto unmap_memstore_desc;
-
-	return result;
-
-unmap_memstore_desc:
-	kgsl_mmu_unmap(pagetable, &device->memstore);
-
-unmap_memptrs_desc:
-	kgsl_mmu_unmap(pagetable, &rb->memptrs_desc);
-
-unmap_buffer_desc:
-	kgsl_mmu_unmap(pagetable, &rb->buffer_desc);
-
-error:
-	return result;
-}
-
-static int kgsl_yamato_setstate(struct kgsl_device *device, uint32_t flags)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	unsigned int link[32];
-	unsigned int *cmds = &link[0];
-	int sizedwords = 0;
-	unsigned int mh_mmu_invalidate = 0x00000003; /*invalidate all and tc */
-
-#ifndef CONFIG_MSM_KGSL_MMU
-	return 0;
-#endif
-	/* if possible, set via command stream,
-	* otherwise set via direct register writes
-	*/
-	if (yamato_device->drawctxt_active) {
-		if (flags & KGSL_MMUFLAGS_PTUPDATE) {
-			/* wait for graphics pipe to be idle */
-			*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-			*cmds++ = 0x00000000;
-
-			/* set page table base */
-			*cmds++ = pm4_type0_packet(REG_MH_MMU_PT_BASE, 1);
-			*cmds++ = device->mmu.hwpagetable->base.gpuaddr;
-			sizedwords += 4;
-		}
-
-		if (flags & KGSL_MMUFLAGS_TLBFLUSH) {
-			if (!(flags & KGSL_MMUFLAGS_PTUPDATE)) {
-				*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE,
-								1);
-				*cmds++ = 0x00000000;
-				sizedwords += 2;
-			}
-			*cmds++ = pm4_type0_packet(REG_MH_MMU_INVALIDATE, 1);
-			*cmds++ = mh_mmu_invalidate;
-			sizedwords += 2;
-		}
-
-		if (flags & KGSL_MMUFLAGS_PTUPDATE &&
-			device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-			/* HW workaround: to resolve MMU page fault interrupts
-			* caused by the VGT.It prevents the CP PFP from filling
-			* the VGT DMA request fifo too early,thereby ensuring
-			* that the VGT will not fetch vertex/bin data until
-			* after the page table base register has been updated.
-			*
-			* Two null DRAW_INDX_BIN packets are inserted right
-			* after the page table base update, followed by a
-			* wait for idle. The null packets will fill up the
-			* VGT DMA request fifo and prevent any further
-			* vertex/bin updates from occurring until the wait
-			* has finished. */
-			*cmds++ = pm4_type3_packet(PM4_SET_CONSTANT, 2);
-			*cmds++ = (0x4 << 16) |
-				(REG_PA_SU_SC_MODE_CNTL - 0x2000);
-			*cmds++ = 0;	  /* disable faceness generation */
-			*cmds++ = pm4_type3_packet(PM4_SET_BIN_BASE_OFFSET, 1);
-			*cmds++ = device->mmu.dummyspace.gpuaddr;
-			*cmds++ = pm4_type3_packet(PM4_DRAW_INDX_BIN, 6);
-			*cmds++ = 0;	  /* viz query info */
-			*cmds++ = 0x0003C004; /* draw indicator */
-			*cmds++ = 0;	  /* bin base */
-			*cmds++ = 3;	  /* bin size */
-			*cmds++ = device->mmu.dummyspace.gpuaddr; /* dma base */
-			*cmds++ = 6;	  /* dma size */
-			*cmds++ = pm4_type3_packet(PM4_DRAW_INDX_BIN, 6);
-			*cmds++ = 0;	  /* viz query info */
-			*cmds++ = 0x0003C004; /* draw indicator */
-			*cmds++ = 0;	  /* bin base */
-			*cmds++ = 3;	  /* bin size */
-			/* dma base */
-			*cmds++ = device->mmu.dummyspace.gpuaddr;
-			*cmds++ = 6;	  /* dma size */
-			*cmds++ = pm4_type3_packet(PM4_WAIT_FOR_IDLE, 1);
-			*cmds++ = 0x00000000;
-			sizedwords += 21;
-		}
-
-		if (flags & (KGSL_MMUFLAGS_PTUPDATE | KGSL_MMUFLAGS_TLBFLUSH)) {
-			*cmds++ = pm4_type3_packet(PM4_INVALIDATE_STATE, 1);
-			*cmds++ = 0x7fff; /* invalidate all base pointers */
-			sizedwords += 2;
-		}
-
-		kgsl_ringbuffer_issuecmds(device, KGSL_CMD_FLAGS_PMODE,
-					&link[0], sizedwords);
-	} else {
-		if (flags & KGSL_MMUFLAGS_PTUPDATE) {
-			kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-			kgsl_yamato_regwrite(device, REG_MH_MMU_PT_BASE,
-				     device->mmu.hwpagetable->base.gpuaddr);
-		}
-
-		if (flags & KGSL_MMUFLAGS_TLBFLUSH) {
-			kgsl_yamato_regwrite(device, REG_MH_MMU_INVALIDATE,
-					   mh_mmu_invalidate);
-		}
-	}
-
-	return 0;
-}
-
-static unsigned int
-kgsl_yamato_getchipid(struct kgsl_device *device)
-{
-	unsigned int chipid;
-	unsigned int coreid, majorid, minorid, patchid, revid;
-
-	/* YDX */
-	kgsl_yamato_regread(device, REG_RBBM_PERIPHID1, &coreid);
-	coreid &= 0xF;
-
-	kgsl_yamato_regread(device, REG_RBBM_PERIPHID2, &majorid);
-	majorid = (majorid >> 4) & 0xF;
-
-	kgsl_yamato_regread(device, REG_RBBM_PATCH_RELEASE, &revid);
-	/* this is a 16bit field, but extremely unlikely it would ever get
-	* this high
-	*/
-	minorid = ((revid >> 0)  & 0xFF);
-
-
-	patchid = ((revid >> 16) & 0xFF);
-
-	chipid  = ((coreid << 24) | (majorid << 16) |
-			(minorid << 8) | (patchid << 0));
-
-	/* Hardware revision 211 (8650) returns the wrong chip ID */
-	if (chipid == KGSL_CHIPID_YAMATODX_REV21)
-		chipid = KGSL_CHIPID_YAMATODX_REV211;
-
-	/* Workaround Hardware revision issue of Z470 */
-	if (chipid == KGSL_CHIPID_LEIA_REV470_TEMP)
-		chipid = KGSL_CHIPID_LEIA_REV470;
-
-
-	return chipid;
-}
-
-static void __devinit kgsl_yamato_getfunctable(struct kgsl_functable *ftbl);
-
-static int __devinit
-kgsl_3d_probe(struct platform_device *pdev)
-{
-	struct kgsl_device *device;
-	int status = -EINVAL;
-
-	device = (struct kgsl_device *)pdev->id_entry->driver_data;
-	device->pdev = pdev;
-
-	init_completion(&device->recovery_gate);
-
-	kgsl_yamato_getfunctable(&device->ftbl);
-
-	status = kgsl_ringbuffer_init(device);
-	if (status != 0)
-		goto error;
-
-	status = kgsl_device_platform_probe(device, kgsl_yamato_isr);
-	if (status)
-		goto error_close_rb;
-
-	kgsl_yamato_debugfs_init(device);
-
-	device->flags &= ~KGSL_FLAGS_SOFT_RESET;
-	return 0;
-
-error_close_rb:
-	kgsl_ringbuffer_close(&yamato_device.ringbuffer);
-error:
-	device->pdev = NULL;
-	return status;
-}
-
-static int __devexit kgsl_3d_remove(struct platform_device *pdev)
-{
-	struct kgsl_device *device = NULL;
-	struct kgsl_yamato_device *device_3d = NULL;
-
-	device = (struct kgsl_device *)pdev->id_entry->driver_data;
-	device_3d = KGSL_YAMATO_DEVICE(device);
-
-	kgsl_device_platform_remove(device);
-
-	kgsl_ringbuffer_close(&device_3d->ringbuffer);
-
-	return 0;
-}
-
-static int kgsl_yamato_start(struct kgsl_device *device, unsigned int init_ram)
-{
-	int status = -EINVAL;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	int init_reftimestamp = 0x7fffffff;
-
-	device->state = KGSL_STATE_INIT;
-	device->requested_state = KGSL_STATE_NONE;
-	/* Order pwrrail/clk sequence based upon platform. */
-	if (device->pwrctrl.pwrrail_first)
-		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_ON);
-	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_ON);
-	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_ON);
-	if (!device->pwrctrl.pwrrail_first)
-		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_ON);
-
-	if (kgsl_mmu_start(device))
-		goto error_clk_off;
-
-	/*We need to make sure all blocks are powered up and clocked before
-	*issuing a soft reset.  The overrides will then be turned off (set to 0)
-	*/
-	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE1, 0xfffffffe);
-	device->chip_id = kgsl_yamato_getchipid(device);
-
-	if (device->chip_id == CHIP_REV_251)
-		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0x000000ff);
-	else
-		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0xffffffff);
-
-	/* Only reset CP block if all blocks have previously been reset */
-	if (!(device->flags & KGSL_FLAGS_SOFT_RESET) ||
-		(device->chip_id != KGSL_CHIPID_LEIA_REV470)) {
-		kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0xFFFFFFFF);
-		device->flags |= KGSL_FLAGS_SOFT_RESET;
-	} else
-		kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0x00000001);
-
-	/* The core is in an indeterminate state until the reset completes
-	 * after 30ms.
-	 */
-	msleep(30);
-
-	kgsl_yamato_regwrite(device, REG_RBBM_SOFT_RESET, 0x00000000);
-
-	kgsl_yamato_regwrite(device, REG_RBBM_CNTL, 0x00004442);
-
-	kgsl_yamato_regwrite(device, REG_MH_ARBITER_CONFIG,
-				KGSL_CFG_YAMATO_MHARB);
-
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470) {
-		kgsl_yamato_regwrite(device,
-			 REG_MH_CLNT_INTF_CTRL_CONFIG1, 0x00030f27);
-		kgsl_yamato_regwrite(device,
-			 REG_MH_CLNT_INTF_CTRL_CONFIG2, 0x00472747);
-	}
-
-	/* Remove 1k boundary check in z470 to avoid GPU hang.
-	   Notice that, this solution won't work if both EBI and SMI are used */
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470) {
-		kgsl_yamato_regwrite(device, REG_MH_CLNT_INTF_CTRL_CONFIG1,
-				 0x00032f07);
-	}
-
-	kgsl_yamato_regwrite(device, REG_SQ_VS_PROGRAM, 0x00000000);
-	kgsl_yamato_regwrite(device, REG_SQ_PS_PROGRAM, 0x00000000);
-
-	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE1, 0);
-	if (device->chip_id != KGSL_CHIPID_LEIA_REV470)
-		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0);
-	else
-		kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0x80);
-
-	kgsl_sharedmem_writel(&device->memstore,
-			      KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
-			      init_reftimestamp);
-
-	kgsl_yamato_regwrite(device, REG_RBBM_DEBUG, 0x00080000);
-
-	kgsl_yamato_regwrite(device, REG_RBBM_INT_CNTL, GSL_RBBM_INT_MASK);
-
-	/* make sure SQ interrupts are disabled */
-	kgsl_yamato_regwrite(device, REG_SQ_INT_CNTL, 0);
-
-	if (device->chip_id == KGSL_CHIPID_LEIA_REV470)
-		yamato_device->gmemspace.sizebytes = SZ_512K;
-	else
-		yamato_device->gmemspace.sizebytes = SZ_256K;
-	kgsl_yamato_gmeminit(yamato_device);
-
-	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_ON);
-
-	status = kgsl_ringbuffer_start(&yamato_device->ringbuffer, init_ram);
-	if (status != 0)
-		goto error_irq_off;
-
-	mod_timer(&device->idle_timer, jiffies + FIRST_TIMEOUT);
-#ifdef CONFIG_KGSL_PER_PROCESS_PAGE_TABLE
-	pr_info("kgsl: initialized dev=%d mmu=%s "
-		"per_process_pagetable=on\n",
-		device->id, kgsl_mmu_isenabled(&device->mmu) ? "on" : "off");
-#else
-	pr_info("kgsl: initialized dev=%d mmu=%s "
-		"per_process_pagetable=off\n",
-		device->id, kgsl_mmu_isenabled(&device->mmu) ? "on" : "off");
-#endif
-	return status;
-
-error_irq_off:
-	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
-error_clk_off:
-	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_OFF);
-	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_OFF);
-
-	kgsl_mmu_stop(device);
-	return status;
-}
-
-static int kgsl_yamato_stop(struct kgsl_device *device)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	del_timer(&device->idle_timer);
-	kgsl_yamato_regwrite(device, REG_RBBM_INT_CNTL, 0);
-
-	kgsl_yamato_regwrite(device, REG_SQ_INT_CNTL, 0);
-
-	yamato_device->drawctxt_active = NULL;
-
-	kgsl_ringbuffer_stop(&yamato_device->ringbuffer);
-
-	kgsl_yamato_gmemclose(device);
-
-	kgsl_mmu_stop(device);
-
-	kgsl_pwrctrl_irq(device, KGSL_PWRFLAGS_IRQ_OFF);
-	if (!device->pwrctrl.pwrrail_first)
-		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_OFF);
-	kgsl_pwrctrl_axi(device, KGSL_PWRFLAGS_AXI_OFF);
-	kgsl_pwrctrl_clk(device, KGSL_PWRFLAGS_CLK_OFF);
-	if (device->pwrctrl.pwrrail_first)
-		kgsl_pwrctrl_pwrrail(device, KGSL_PWRFLAGS_POWER_OFF);
-
-	return 0;
-}
-
-static int
-kgsl_yamato_recover_hang(struct kgsl_device *device)
-{
-	int ret;
-	unsigned int *rb_buffer;
-	struct kgsl_yamato_device *yamato_device =
-			(struct kgsl_yamato_device *)device;
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-	unsigned int timestamp;
-	unsigned int num_rb_contents;
-	unsigned int bad_context;
-	unsigned int reftimestamp;
-	unsigned int enable_ts;
-	unsigned int soptimestamp;
-	unsigned int eoptimestamp;
-	struct kgsl_yamato_context *drawctxt;
-
-	KGSL_DRV_ERR(device, "Starting recovery from 3D GPU hang....\n");
-	rb_buffer = vmalloc(rb->buffer_desc.size);
-	if (!rb_buffer) {
-		KGSL_MEM_ERR(device,
-			"Failed to allocate memory for recovery: %x\n",
-			rb->buffer_desc.size);
-		return -ENOMEM;
-	}
-	/* Extract valid contents from rb which can stil be executed after
-	 * hang */
-	ret = kgsl_ringbuffer_extract(rb, rb_buffer, &num_rb_contents);
-	if (ret)
-		goto done;
-	timestamp = rb->timestamp;
-	KGSL_DRV_ERR(device, "Last issued timestamp: %x\n", timestamp);
-	kgsl_sharedmem_readl(&device->memstore, &bad_context,
-				KGSL_DEVICE_MEMSTORE_OFFSET(current_context));
-	kgsl_sharedmem_readl(&device->memstore, &reftimestamp,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts));
-	kgsl_sharedmem_readl(&device->memstore, &enable_ts,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable));
-	kgsl_sharedmem_readl(&device->memstore, &soptimestamp,
-				KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp));
-	kgsl_sharedmem_readl(&device->memstore, &eoptimestamp,
-				KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp));
-	rmb();
-	KGSL_CTXT_ERR(device,
-		"Context that caused a GPU hang: %x\n", bad_context);
-	/* restart device */
-	ret = kgsl_yamato_stop(device);
-	if (ret)
-		goto done;
-	ret = kgsl_yamato_start(device, true);
-	if (ret)
-		goto done;
-	KGSL_DRV_ERR(device, "Device has been restarted after hang\n");
-	/* Restore timestamp states */
-	kgsl_sharedmem_writel(&device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp),
-			soptimestamp);
-	kgsl_sharedmem_writel(&device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(eoptimestamp),
-			eoptimestamp);
-	kgsl_sharedmem_writel(&device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(soptimestamp),
-			soptimestamp);
-	if (num_rb_contents) {
-		kgsl_sharedmem_writel(&device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
-			reftimestamp);
-		kgsl_sharedmem_writel(&device->memstore,
-			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
-			enable_ts);
-	}
-	wmb();
-	/* Mark the invalid context so no more commands are accepted from
-	 * that context */
-
-	drawctxt = (struct kgsl_yamato_context *) bad_context;
-
-	KGSL_CTXT_ERR(device,
-		"Context that caused a GPU hang: %x\n", bad_context);
-
-	drawctxt->flags |= CTXT_FLAGS_GPU_HANG;
-
-	/* Restore valid commands in ringbuffer */
-	kgsl_ringbuffer_restore(rb, rb_buffer, num_rb_contents);
-	rb->timestamp = timestamp;
-done:
-	vfree(rb_buffer);
-	return ret;
-}
-
-static int
-kgsl_yamato_dump_and_recover(struct kgsl_device *device)
-{
-	static int recovery;
-	int result = -ETIMEDOUT;
-
-	if (device->state == KGSL_STATE_HUNG)
-		goto done;
-	if (device->state == KGSL_STATE_DUMP_AND_RECOVER && !recovery) {
-		mutex_unlock(&device->mutex);
-		wait_for_completion(&device->recovery_gate);
-		mutex_lock(&device->mutex);
-		if (!(device->state & KGSL_STATE_HUNG))
-			/* recovery success */
-			result = 0;
-	} else {
-		INIT_COMPLETION(device->recovery_gate);
-		/* Detected a hang - trigger an automatic dump */
-		kgsl_postmortem_dump(device, 0);
-		if (!recovery) {
-			recovery = 1;
-			result = kgsl_yamato_recover_hang(device);
-			if (result)
-				device->state = KGSL_STATE_HUNG;
-			recovery = 0;
-			complete_all(&device->recovery_gate);
-		} else
-			KGSL_DRV_ERR(device,
-				"Cannot recover from another hang while "
-				"recovering from a hang\n");
-	}
-done:
-	return result;
-}
-
-struct kgsl_device *kgsl_get_yamato_generic_device(void)
-{
-	return &yamato_device.dev;
-}
-
-static int kgsl_yamato_getproperty(struct kgsl_device *device,
-				enum kgsl_property_type type,
-				void *value,
-				unsigned int sizebytes)
-{
-	int status = -EINVAL;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-
-	switch (type) {
-	case KGSL_PROP_DEVICE_INFO:
-		{
-			struct kgsl_devinfo devinfo;
-
-			if (sizebytes != sizeof(devinfo)) {
-				status = -EINVAL;
-				break;
-			}
-
-			memset(&devinfo, 0, sizeof(devinfo));
-			devinfo.device_id = device->id+1;
-			devinfo.chip_id = device->chip_id;
-			devinfo.mmu_enabled = kgsl_mmu_isenabled(&device->mmu);
-//			devinfo.gpu_id = adreno_get_rev(adreno_dev);
-			devinfo.gpu_id = 205;
-			devinfo.gmem_gpubaseaddr = yamato_device->gmemspace.
-					gpu_base;
-			devinfo.gmem_sizebytes = yamato_device->gmemspace.
-					sizebytes;
-
-			if (copy_to_user(value, &devinfo, sizeof(devinfo)) !=
-					0) {
-				status = -EFAULT;
-				break;
-			}
-			status = 0;
-		}
-		break;
-	case KGSL_PROP_DEVICE_SHADOW:
-		{
-			struct kgsl_shadowprop shadowprop;
-
-			if (sizebytes != sizeof(shadowprop)) {
-				status = -EINVAL;
-				break;
-			}
-			memset(&shadowprop, 0, sizeof(shadowprop));
-			if (device->memstore.hostptr) {
-				/*NOTE: with mmu enabled, gpuaddr doesn't mean
-				 * anything to mmap().
-				 */
-				shadowprop.gpuaddr = device->memstore.physaddr;
-				shadowprop.size = device->memstore.size;
-				/* GSL needs this to be set, even if it
-				   appears to be meaningless */
-				shadowprop.flags = KGSL_FLAGS_INITIALIZED;
-			}
-			if (copy_to_user(value, &shadowprop,
-				sizeof(shadowprop))) {
-				status = -EFAULT;
-				break;
-			}
-			status = 0;
-		}
-		break;
-	case KGSL_PROP_MMU_ENABLE:
-		{
-#ifdef CONFIG_MSM_KGSL_MMU
-			int mmuProp = 1;
-#else
-			int mmuProp = 0;
-#endif
-			if (sizebytes != sizeof(int)) {
-				status = -EINVAL;
-				break;
-			}
-			if (copy_to_user(value, &mmuProp, sizeof(mmuProp))) {
-				status = -EFAULT;
-				break;
-			}
-			status = 0;
-		}
-		break;
-	case KGSL_PROP_INTERRUPT_WAITS:
-		{
-			int int_waits = 1;
-			if (sizebytes != sizeof(int)) {
-				status = -EINVAL;
-				break;
-			}
-			if (copy_to_user(value, &int_waits, sizeof(int))) {
-				status = -EFAULT;
-				break;
-			}
-			status = 0;
-		}
-		break;
-	default:
-		status = -EINVAL;
-	}
-
-	return status;
-}
-
-/* Caller must hold the device mutex. */
-int kgsl_yamato_idle(struct kgsl_device *device, unsigned int timeout)
-{
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-	unsigned int rbbm_status;
-	unsigned long wait_time = jiffies + MAX_WAITGPU_SECS;
-
-	kgsl_cffdump_regpoll(device->id, REG_RBBM_STATUS << 2,
-		0x00000000, 0x80000000);
-	/* first, wait until the CP has consumed all the commands in
-	 * the ring buffer
-	 */
-retry:
-	if (rb->flags & KGSL_FLAGS_STARTED) {
-		do {
-			GSL_RB_GET_READPTR(rb, &rb->rptr);
-			if (time_after(jiffies, wait_time)) {
-				KGSL_DRV_ERR(device, "rptr: %x, wptr: %x\n",
-					rb->rptr, rb->wptr);
-				goto err;
-			}
-		} while (rb->rptr != rb->wptr);
-	}
-
-	/* now, wait for the GPU to finish its operations */
-	wait_time = jiffies + MAX_WAITGPU_SECS;
-	while (time_before(jiffies, wait_time)) {
-		kgsl_yamato_regread(device, REG_RBBM_STATUS, &rbbm_status);
-		if (rbbm_status == 0x110)
-			return 0;
-	}
-
-err:
-	KGSL_DRV_ERR(device, "spun too long waiting for RB to idle\n");
-	if (!kgsl_yamato_dump_and_recover(device)) {
-		wait_time = jiffies + MAX_WAITGPU_SECS;
-		goto retry;
-	}
-	return -ETIMEDOUT;
-}
-
-static unsigned int kgsl_yamato_isidle(struct kgsl_device *device)
-{
-	int status = false;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-	struct kgsl_ringbuffer *rb = &yamato_device->ringbuffer;
-	unsigned int rbbm_status;
-
-	if (rb->flags & KGSL_FLAGS_STARTED) {
-		/* Is the ring buffer is empty? */
-		GSL_RB_GET_READPTR(rb, &rb->rptr);
-		if (!device->active_cnt && (rb->rptr == rb->wptr)) {
-			/* Is the core idle? */
-			kgsl_yamato_regread(device, REG_RBBM_STATUS,
-					    &rbbm_status);
-			if (rbbm_status == 0x110)
-				status = true;
-		}
-	} else {
-		KGSL_DRV_ERR(device, "ringbuffer not started\n");
-		BUG();
-	}
-	return status;
-}
-
-
-/******************************************************************/
-/* Caller must hold the driver mutex. */
-static int kgsl_yamato_resume_context(struct kgsl_device *device)
-{
-	int status = 0;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-
-	if (device->pwrctrl.suspended_ctxt != NULL) {
-		kgsl_drawctxt_switch(yamato_device,
-				     device->pwrctrl.suspended_ctxt, 0);
-		status = kgsl_yamato_idle(device, 0);
-
-	}
-
-	return status;
-}
-
-/******************************************************************/
-/* Caller must hold the device mutex. */
-static int kgsl_yamato_suspend_context(struct kgsl_device *device)
-{
-	int status = 0;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-
-	/* save ctxt ptr and switch to NULL ctxt */
-	device->pwrctrl.suspended_ctxt = yamato_device->drawctxt_active;
-	if (device->pwrctrl.suspended_ctxt != NULL) {
-		kgsl_drawctxt_switch(yamato_device, NULL, 0);
-		status = kgsl_yamato_idle(device, KGSL_TIMEOUT_DEFAULT);
-	}
-
-	return status;
-}
-static void _yamato_regread(struct kgsl_device *device,
-			    unsigned int offsetwords,
-			    unsigned int *value)
-{
-	unsigned int *reg;
-	BUG_ON(offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes);
-	reg = (unsigned int *)(device->regspace.mmio_virt_base
-				+ (offsetwords << 2));
-	*value = readl(reg);
-}
-
-void kgsl_yamato_regread(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int *value)
-{
-	kgsl_pre_hwaccess(device);
-	_yamato_regread(device, offsetwords, value);
-}
-
-void kgsl_yamato_regread_isr(struct kgsl_device *device,
-			     unsigned int offsetwords,
-			     unsigned int *value)
-{
-	_yamato_regread(device, offsetwords, value);
-}
-
-static void _yamato_regwrite(struct kgsl_device *device,
-			     unsigned int offsetwords,
-			     unsigned int value)
-{
-	unsigned int *reg;
-
-	BUG_ON(offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes);
-
-	kgsl_cffdump_regwrite(device->id, offsetwords << 2, value);
-	reg = (unsigned int *)(device->regspace.mmio_virt_base
-				+ (offsetwords << 2));
-
-	writel(value, reg);
-
-}
-
-void kgsl_yamato_regwrite(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int value)
-{
-	kgsl_pre_hwaccess(device);
-	_yamato_regwrite(device, offsetwords, value);
-}
-
-void kgsl_yamato_regwrite_isr(struct kgsl_device *device,
-			      unsigned int offsetwords,
-			      unsigned int value)
-{
-	_yamato_regwrite(device, offsetwords, value);
-}
-
-static int kgsl_check_interrupt_timestamp(struct kgsl_device *device,
-					unsigned int timestamp)
-{
-	int status;
-	unsigned int ref_ts, enableflag;
-
-	status = kgsl_check_timestamp(device, timestamp);
-	if (!status) {
-		mutex_lock(&device->mutex);
-		kgsl_sharedmem_readl(&device->memstore, &enableflag,
-			KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable));
-		rmb();
-
-		if (enableflag) {
-			kgsl_sharedmem_readl(&device->memstore, &ref_ts,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts));
-			rmb();
-			if (timestamp_cmp(ref_ts, timestamp)) {
-				kgsl_sharedmem_writel(&device->memstore,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
-				timestamp);
-				wmb();
-			}
-		} else {
-			unsigned int cmds[2];
-			kgsl_sharedmem_writel(&device->memstore,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ref_wait_ts),
-				timestamp);
-			enableflag = 1;
-			kgsl_sharedmem_writel(&device->memstore,
-				KGSL_DEVICE_MEMSTORE_OFFSET(ts_cmp_enable),
-				enableflag);
-			wmb();
-			/* submit a dummy packet so that even if all
-			* commands upto timestamp get executed we will still
-			* get an interrupt */
-			cmds[0] = pm4_type3_packet(PM4_NOP, 1);
-			cmds[1] = 0;
-			kgsl_ringbuffer_issuecmds(device, 0, &cmds[0], 2);
-		}
-		mutex_unlock(&device->mutex);
-	}
-
-	return status;
-}
-
-/*
- wait_io_event_interruptible_timeout checks for the exit condition before
- placing a process in wait q. For conditional interrupts we expect the
- process to already be in its wait q when its exit condition checking
- function is called.
-*/
-#define kgsl_wait_io_event_interruptible_timeout(wq, condition, timeout)\
-({									\
-	long __ret = timeout;						\
-	__wait_io_event_interruptible_timeout(wq, condition, __ret);	\
-	__ret;								\
-})
-
-/* MUST be called with the device mutex held */
-static int kgsl_yamato_waittimestamp(struct kgsl_device *device,
-				unsigned int timestamp,
-				unsigned int msecs)
-{
-	long status = 0;
-	struct kgsl_yamato_device *yamato_device = KGSL_YAMATO_DEVICE(device);
-
-	if (timestamp != yamato_device->ringbuffer.timestamp &&
-		timestamp_cmp(timestamp,
-		yamato_device->ringbuffer.timestamp)) {
-		KGSL_DRV_ERR(device, "Cannot wait for invalid ts: %x, "
-			"rb->timestamp: %x\n",
-			timestamp, yamato_device->ringbuffer.timestamp);
-		status = -EINVAL;
-		goto done;
-	}
-	if (!kgsl_check_timestamp(device, timestamp)) {
-		mutex_unlock(&device->mutex);
-		/* We need to make sure that the process is placed in wait-q
-		 * before its condition is called */
-		status = kgsl_wait_io_event_interruptible_timeout(
-				device->wait_queue,
-				kgsl_check_interrupt_timestamp(device,
-					timestamp), msecs_to_jiffies(msecs));
-		mutex_lock(&device->mutex);
-
-		if (status > 0)
-			status = 0;
-		else if (status == 0) {
-			if (!kgsl_check_timestamp(device, timestamp)) {
-				status = -ETIMEDOUT;
-				KGSL_DRV_ERR(device,
-					"Device hang detected while waiting "
-					"for timestamp: %x, last "
-					"submitted(rb->timestamp): %x, wptr: "
-					"%x\n", timestamp,
-					yamato_device->ringbuffer.timestamp,
-					yamato_device->ringbuffer.wptr);
-				if (!kgsl_yamato_dump_and_recover(device)) {
-					/* wait for idle after recovery as the
-					 * timestamp that this process wanted
-					 * to wait on may be invalid */
-					if (!kgsl_yamato_idle(device,
-						KGSL_TIMEOUT_DEFAULT))
-						status = 0;
-				}
-			}
-		}
-	}
-
-done:
-	return (int)status;
-}
-
-static long kgsl_yamato_ioctl(struct kgsl_device_private *dev_priv,
-			      unsigned int cmd, void *data)
-{
-	int result = 0;
-	struct kgsl_drawctxt_set_bin_base_offset *binbase;
-	struct kgsl_context *context;
-
-	switch (cmd) {
-	case IOCTL_KGSL_DRAWCTXT_SET_BIN_BASE_OFFSET:
-		binbase = data;
-
-		context = kgsl_find_context(dev_priv, binbase->drawctxt_id);
-		if (context) {
-			result = kgsl_drawctxt_set_bin_base_offset(
-					dev_priv->device,
-					context,
-					binbase->offset);
-		} else {
-			result = -EINVAL;
-			KGSL_DRV_ERR(dev_priv->device,
-				"invalid drawctxt drawctxt_id %d "
-				"device_id=%d\n",
-				binbase->drawctxt_id, dev_priv->device->id);
-		}
-		break;
-
-	default:
-		KGSL_DRV_INFO(dev_priv->device,
-			"invalid ioctl code %08x\n", cmd);
-		result = -EINVAL;
-		break;
-	}
-	return result;
-
-}
-
-static inline s64 kgsl_yamato_ticks_to_us(u32 ticks, u32 gpu_freq)
-{
-	gpu_freq /= 1000000;
-	return ticks / gpu_freq;
-}
-
-static void kgsl_yamato_power_stats(struct kgsl_device *device,
-				struct kgsl_power_stats *stats)
-{
-	unsigned int reg;
-	struct kgsl_pwrctrl *pwr = &device->pwrctrl;
-
-	/* In order to calculate idle you have to have run the algorithm *
-	 * at least once to get a start time. */
-	if (pwr->time != 0) {
-		s64 tmp;
-		/* Stop the performance moniter and read the current *
-		 * busy cycles. */
-		kgsl_yamato_regwrite(device,
-					REG_CP_PERFMON_CNTL,
-					REG_PERF_MODE_CNT |
-					REG_PERF_STATE_FREEZE);
-		kgsl_yamato_regread(device, REG_RBBM_PERFCOUNTER1_LO, &reg);
-		tmp = ktime_to_us(ktime_get());
-		stats->total_time = tmp - pwr->time;
-		pwr->time = tmp;
-		stats->busy_time  = kgsl_yamato_ticks_to_us(reg,
-				device->pwrctrl.
-				pwrlevels[device->pwrctrl.active_pwrlevel].
-				gpu_freq);
-		kgsl_yamato_regwrite(device,
-					REG_CP_PERFMON_CNTL,
-					REG_PERF_MODE_CNT |
-					REG_PERF_STATE_RESET);
-	} else {
-		stats->total_time = 0;
-		stats->busy_time = 0;
-		pwr->time = ktime_to_us(ktime_get());
-	}
-
-	/* re-enable the performance moniters */
-	kgsl_yamato_regread(device, REG_RBBM_PM_OVERRIDE2, &reg);
-	kgsl_yamato_regwrite(device, REG_RBBM_PM_OVERRIDE2, (reg | 0x40));
-	kgsl_yamato_regwrite(device, REG_RBBM_PERFCOUNTER1_SELECT, 0x1);
-	kgsl_yamato_regwrite(device,
-				REG_CP_PERFMON_CNTL,
-				REG_PERF_MODE_CNT | REG_PERF_STATE_ENABLE);
-}
-
-static void __devinit kgsl_yamato_getfunctable(struct kgsl_functable *ftbl)
-{
-	if (ftbl == NULL)
-		return;
-	ftbl->device_regread = kgsl_yamato_regread;
-	ftbl->device_regwrite = kgsl_yamato_regwrite;
-	ftbl->device_regread_isr = kgsl_yamato_regread_isr;
-	ftbl->device_regwrite_isr = kgsl_yamato_regwrite_isr;
-	ftbl->device_setstate = kgsl_yamato_setstate;
-	ftbl->device_idle = kgsl_yamato_idle;
-	ftbl->device_isidle = kgsl_yamato_isidle;
-	ftbl->device_suspend_context = kgsl_yamato_suspend_context;
-	ftbl->device_resume_context = kgsl_yamato_resume_context;
-	ftbl->device_start = kgsl_yamato_start;
-	ftbl->device_stop = kgsl_yamato_stop;
-	ftbl->device_getproperty = kgsl_yamato_getproperty;
-	ftbl->device_waittimestamp = kgsl_yamato_waittimestamp;
-	ftbl->device_cmdstream_readtimestamp = kgsl_cmdstream_readtimestamp;
-	ftbl->device_issueibcmds = kgsl_ringbuffer_issueibcmds;
-	ftbl->device_drawctxt_create = kgsl_drawctxt_create;
-	ftbl->device_drawctxt_destroy = kgsl_drawctxt_destroy;
-	ftbl->device_ioctl = kgsl_yamato_ioctl;
-	ftbl->device_setup_pt = kgsl_yamato_setup_pt;
-	ftbl->device_cleanup_pt = kgsl_yamato_cleanup_pt;
-	ftbl->device_power_stats = kgsl_yamato_power_stats;
-}
-
-static struct platform_device_id kgsl_3d_id_table[] = {
-	{ DEVICE_3D0_NAME, (kernel_ulong_t)&yamato_device.dev, },
-	{ },
-};
-MODULE_DEVICE_TABLE(platform, kgsl_3d_id_table);
-
-static struct platform_driver kgsl_3d_platform_driver = {
-	.probe = kgsl_3d_probe,
-	.remove = __devexit_p(kgsl_3d_remove),
-	.suspend = kgsl_suspend_driver,
-	.resume = kgsl_resume_driver,
-	.id_table = kgsl_3d_id_table,
-	.driver = {
-		.owner = THIS_MODULE,
-		.name = DEVICE_3D_NAME,
-		.pm = &kgsl_pm_ops,
-	}
-};
-
-static int __init kgsl_3d_init(void)
-{
-	return platform_driver_register(&kgsl_3d_platform_driver);
-}
-
-static void __exit kgsl_3d_exit(void)
-{
-	platform_driver_unregister(&kgsl_3d_platform_driver);
-}
-
-module_init(kgsl_3d_init);
-module_exit(kgsl_3d_exit);
-
-MODULE_DESCRIPTION("3D Graphics driver");
-MODULE_VERSION("1.2");
-MODULE_LICENSE("GPL v2");
-MODULE_ALIAS("platform:kgsl_3d");
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.h
deleted file mode 100644
index 5c986e2..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato.h
+++ /dev/null
@@ -1,65 +0,0 @@
-/* Copyright (c) 2008-2011, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef _KGSL_YAMATO_H
-#define _KGSL_YAMATO_H
-
-#include "kgsl_drawctxt.h"
-#include "kgsl_ringbuffer.h"
-
-#define DEVICE_3D_NAME "kgsl-3d"
-#define DEVICE_3D0_NAME "kgsl-3d0"
-
-struct kgsl_yamato_device {
-	struct kgsl_device dev;    /* Must be first field in this struct */
-	struct kgsl_memregion gmemspace;
-	struct kgsl_yamato_context *drawctxt_active;
-	wait_queue_head_t ib1_wq;
-	unsigned int *pfp_fw;
-	size_t pfp_fw_size;
-	unsigned int *pm4_fw;
-	size_t pm4_fw_size;
-	struct kgsl_ringbuffer ringbuffer;
-};
-
-
-irqreturn_t kgsl_yamato_isr(int irq, void *data);
-
-int kgsl_yamato_idle(struct kgsl_device *device, unsigned int timeout);
-void kgsl_yamato_regread(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int *value);
-void kgsl_yamato_regwrite(struct kgsl_device *device, unsigned int offsetwords,
-				unsigned int value);
-void kgsl_yamato_regread_isr(struct kgsl_device *device,
-			     unsigned int offsetwords,
-			     unsigned int *value);
-void kgsl_yamato_regwrite_isr(struct kgsl_device *device,
-			      unsigned int offsetwords,
-			      unsigned int value);
-
-#endif /*_KGSL_YAMATO_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.c b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.c
deleted file mode 100644
index 722c894..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.c
+++ /dev/null
@@ -1,452 +0,0 @@
-/* Copyright (c) 2002,2008-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- */
-
-#include <linux/delay.h>
-#include <linux/debugfs.h>
-#include <linux/uaccess.h>
-#include <linux/io.h>
-
-#include "kgsl.h"
-#include "kgsl_log.h"
-#include "kgsl_device.h"
-#include "kgsl_postmortem.h"
-#include "kgsl_yamato.h"
-
-unsigned int kgsl_cff_dump_enable;
-int kgsl_pm_regs_enabled;
-
-static uint32_t kgsl_ib_base;
-static uint32_t kgsl_ib_size;
-
-static struct dentry *pm_d_debugfs;
-
-
-static int pm_dump_set(void *data, u64 val)
-{
-	struct kgsl_device *device = data;
-
-	if (val) {
-		mutex_lock(&device->mutex);
-		kgsl_postmortem_dump(device, 1);
-		mutex_unlock(&device->mutex);
-	}
-
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(pm_dump_fops,
-			NULL,
-			pm_dump_set, "%llu\n");
-
-static int pm_regs_enabled_set(void *data, u64 val)
-{
-	kgsl_pm_regs_enabled = val ? 1 : 0;
-	return 0;
-}
-
-static int pm_regs_enabled_get(void *data, u64 *val)
-{
-	*val = kgsl_pm_regs_enabled;
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(pm_regs_enabled_fops,
-			pm_regs_enabled_get,
-			pm_regs_enabled_set, "%llu\n");
-
-
-static int kgsl_cff_dump_enable_set(void *data, u64 val)
-{
-#ifdef CONFIG_MSM_KGSL_CFF_DUMP
-	kgsl_cff_dump_enable = (val != 0);
-	return 0;
-#else
-	return -EINVAL;
-#endif
-}
-
-static int kgsl_cff_dump_enable_get(void *data, u64 *val)
-{
-	*val = kgsl_cff_dump_enable;
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(kgsl_cff_dump_enable_fops, kgsl_cff_dump_enable_get,
-			kgsl_cff_dump_enable_set, "%llu\n");
-
-static int kgsl_dbgfs_open(struct inode *inode, struct file *file)
-{
-	file->f_mode &= ~(FMODE_PREAD | FMODE_PWRITE);
-	file->private_data = inode->i_private;
-	return 0;
-}
-
-static int kgsl_dbgfs_release(struct inode *inode, struct file *file)
-{
-	return 0;
-}
-
-static int kgsl_hex_dump(const char *prefix, int c, uint8_t *data,
-	int rowc, int linec, char __user *buff)
-{
-	int ss;
-	/* Prefix of 20 chars max, 32 bytes per row, in groups of four - that's
-	 * 8 groups at 8 chars per group plus a space, plus new-line, plus
-	 * ending character */
-	char linebuf[20 + 64 + 1 + 1];
-
-	ss = snprintf(linebuf, sizeof(linebuf), prefix, c);
-	hex_dump_to_buffer(data, linec, rowc, 4, linebuf+ss,
-		sizeof(linebuf)-ss, 0);
-	strncat(linebuf, "\n", sizeof(linebuf));
-	linebuf[sizeof(linebuf)-1] = 0;
-	ss = strlen(linebuf);
-	if (copy_to_user(buff, linebuf, ss+1))
-		return -EFAULT;
-	return ss;
-}
-
-static ssize_t kgsl_ib_dump_read(
-	struct file *file,
-	char __user *buff,
-	size_t buff_count,
-	loff_t *ppos)
-{
-	int i, count = kgsl_ib_size, remaining, pos = 0, tot = 0, ss;
-	struct kgsl_device *device = file->private_data;
-	const int rowc = 32;
-	unsigned int pt_base, ib_memsize;
-	uint8_t *base_addr;
-	char linebuf[80];
-
-	if (!ppos || !device || !kgsl_ib_base)
-		return 0;
-
-	kgsl_regread(device, REG_MH_MMU_PT_BASE, &pt_base);
-	base_addr = kgsl_sharedmem_convertaddr(device, pt_base, kgsl_ib_base,
-		&ib_memsize);
-
-	if (!base_addr)
-		return 0;
-
-	pr_info("%s ppos=%ld, buff_count=%d, count=%d\n", __func__, (long)*ppos,
-		buff_count, count);
-	ss = snprintf(linebuf, sizeof(linebuf), "IB: base=%08x(%08x"
-		"), size=%d, memsize=%d\n", kgsl_ib_base,
-		(uint32_t)base_addr, kgsl_ib_size, ib_memsize);
-	if (*ppos == 0) {
-		if (copy_to_user(buff, linebuf, ss+1))
-			return -EFAULT;
-		tot += ss;
-		buff += ss;
-		*ppos += ss;
-	}
-	pos += ss;
-	remaining = count;
-	for (i = 0; i < count; i += rowc) {
-		int linec = min(remaining, rowc);
-
-		remaining -= rowc;
-		ss = kgsl_hex_dump("IB: %05x: ", i, base_addr, rowc, linec,
-			buff);
-		if (ss < 0)
-			return ss;
-
-		if (pos >= *ppos) {
-			if (tot+ss >= buff_count) {
-				ss = copy_to_user(buff, "", 1);
-				return tot;
-			}
-			tot += ss;
-			buff += ss;
-			*ppos += ss;
-		}
-		pos += ss;
-		base_addr += linec;
-	}
-
-	return tot;
-}
-
-static ssize_t kgsl_ib_dump_write(
-	struct file *file,
-	const char __user *buff,
-	size_t count,
-	loff_t *ppos)
-{
-	char local_buff[64];
-
-	if (count >= sizeof(local_buff))
-		return -EFAULT;
-
-	if (copy_from_user(local_buff, buff, count))
-		return -EFAULT;
-
-	local_buff[count] = 0;	/* end of string */
-	sscanf(local_buff, "%x %d", &kgsl_ib_base, &kgsl_ib_size);
-
-	pr_info("%s: base=%08X size=%d\n", __func__, kgsl_ib_base,
-		kgsl_ib_size);
-
-	return count;
-}
-
-static const struct file_operations kgsl_ib_dump_fops = {
-	.open = kgsl_dbgfs_open,
-	.release = kgsl_dbgfs_release,
-	.read = kgsl_ib_dump_read,
-	.write = kgsl_ib_dump_write,
-};
-
-static int kgsl_regread_nolock(struct kgsl_device *device,
-	unsigned int offsetwords, unsigned int *value)
-{
-	unsigned int *reg;
-
-	if (offsetwords*sizeof(uint32_t) >= device->regspace.sizebytes) {
-		KGSL_DRV_ERR(device, "invalid offset %d\n", offsetwords);
-		return -ERANGE;
-	}
-
-	reg = (unsigned int *)(device->regspace.mmio_virt_base
-				+ (offsetwords << 2));
-	*value = readl(reg);
-	return 0;
-}
-
-#define KGSL_ISTORE_START 0x5000
-#define KGSL_ISTORE_LENGTH 0x600
-static ssize_t kgsl_istore_read(
-	struct file *file,
-	char __user *buff,
-	size_t buff_count,
-	loff_t *ppos)
-{
-	int i, count = KGSL_ISTORE_LENGTH, remaining, pos = 0, tot = 0;
-	struct kgsl_device *device = file->private_data;
-	const int rowc = 8;
-
-	if (!ppos || !device)
-		return 0;
-
-	remaining = count;
-	for (i = 0; i < count; i += rowc) {
-		unsigned int vals[rowc];
-		int j, ss;
-		int linec = min(remaining, rowc);
-		remaining -= rowc;
-
-		if (pos >= *ppos) {
-			for (j = 0; j < linec; ++j)
-				kgsl_regread_nolock(device,
-					KGSL_ISTORE_START+i+j, vals+j);
-		} else
-			memset(vals, 0, sizeof(vals));
-
-		ss = kgsl_hex_dump("IS: %04x: ", i, (uint8_t *)vals, rowc*4,
-			linec*4, buff);
-		if (ss < 0)
-			return ss;
-
-		if (pos >= *ppos) {
-			if (tot+ss >= buff_count)
-				return tot;
-			tot += ss;
-			buff += ss;
-			*ppos += ss;
-		}
-		pos += ss;
-	}
-
-	return tot;
-}
-
-static const struct file_operations kgsl_istore_fops = {
-	.open = kgsl_dbgfs_open,
-	.release = kgsl_dbgfs_release,
-	.read = kgsl_istore_read,
-	.llseek = default_llseek,
-};
-
-typedef void (*reg_read_init_t)(struct kgsl_device *device);
-typedef void (*reg_read_fill_t)(struct kgsl_device *device, int i,
-	unsigned int *vals, int linec);
-static ssize_t kgsl_reg_read(struct kgsl_device *device, int count,
-	reg_read_init_t reg_read_init,
-	reg_read_fill_t reg_read_fill, const char *prefix, char __user *buff,
-	loff_t *ppos)
-{
-	int i, remaining;
-	const int rowc = 8;
-
-	if (!ppos || *ppos || !device)
-		return 0;
-
-	mutex_lock(&device->mutex);
-	reg_read_init(device);
-	remaining = count;
-	for (i = 0; i < count; i += rowc) {
-		unsigned int vals[rowc];
-		int ss;
-		int linec = min(remaining, rowc);
-		remaining -= rowc;
-
-		reg_read_fill(device, i, vals, linec);
-		ss = kgsl_hex_dump(prefix, i, (uint8_t *)vals, rowc*4, linec*4,
-			buff);
-		if (ss < 0) {
-			mutex_unlock(&device->mutex);
-			return ss;
-		}
-		buff += ss;
-		*ppos += ss;
-	}
-	mutex_unlock(&device->mutex);
-
-	return *ppos;
-}
-
-
-static void kgsl_sx_reg_read_init(struct kgsl_device *device)
-{
-	kgsl_regwrite(device, REG_RBBM_PM_OVERRIDE2, 0xFF);
-	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
-}
-
-static void kgsl_sx_reg_read_fill(struct kgsl_device *device, int i,
-	unsigned int *vals, int linec)
-{
-	int j;
-
-	for (j = 0; j < linec; ++j) {
-		kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0x1B00 | i);
-		kgsl_regread(device, REG_RBBM_DEBUG_OUT, vals+j);
-	}
-}
-
-static ssize_t kgsl_sx_debug_read(
-	struct file *file,
-	char __user *buff,
-	size_t buff_count,
-	loff_t *ppos)
-{
-	struct kgsl_device *device = file->private_data;
-	return kgsl_reg_read(device, 0x1B, kgsl_sx_reg_read_init,
-			     kgsl_sx_reg_read_fill, "SX: %02x: ", buff, ppos);
-}
-
-static const struct file_operations kgsl_sx_debug_fops = {
-	.open = kgsl_dbgfs_open,
-	.release = kgsl_dbgfs_release,
-	.read = kgsl_sx_debug_read,
-};
-
-static void kgsl_cp_reg_read_init(struct kgsl_device *device)
-{
-	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
-}
-
-static void kgsl_cp_reg_read_fill(struct kgsl_device *device, int i,
-	unsigned int *vals, int linec)
-{
-	int j;
-
-	for (j = 0; j < linec; ++j) {
-		kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0x1628);
-		kgsl_regread(device, REG_RBBM_DEBUG_OUT, vals+j);
-		msleep(100);
-	}
-}
-
-static ssize_t kgsl_cp_debug_read(
-	struct file *file,
-	char __user *buff,
-	size_t buff_count,
-	loff_t *ppos)
-{
-	struct kgsl_device *device = file->private_data;
-	return kgsl_reg_read(device, 20, kgsl_cp_reg_read_init,
-		kgsl_cp_reg_read_fill,
-		"CP: %02x: ", buff, ppos);
-}
-
-static const struct file_operations kgsl_cp_debug_fops = {
-	.open = kgsl_dbgfs_open,
-	.release = kgsl_dbgfs_release,
-	.read = kgsl_cp_debug_read,
-};
-
-static void kgsl_mh_reg_read_init(struct kgsl_device *device)
-{
-	kgsl_regwrite(device, REG_RBBM_DEBUG_CNTL, 0);
-}
-
-static void kgsl_mh_reg_read_fill(struct kgsl_device *device, int i,
-	unsigned int *vals, int linec)
-{
-	int j;
-
-	for (j = 0; j < linec; ++j) {
-		kgsl_regwrite(device, REG_MH_DEBUG_CTRL, i+j);
-		kgsl_regread(device, REG_MH_DEBUG_DATA, vals+j);
-	}
-}
-
-static ssize_t kgsl_mh_debug_read(
-	struct file *file,
-	char __user *buff,
-	size_t buff_count,
-	loff_t *ppos)
-{
-	struct kgsl_device *device = file->private_data;
-	return kgsl_reg_read(device, 0x40, kgsl_mh_reg_read_init,
-		kgsl_mh_reg_read_fill,
-		"MH: %02x: ", buff, ppos);
-}
-
-static const struct file_operations kgsl_mh_debug_fops = {
-	.open = kgsl_dbgfs_open,
-	.release = kgsl_dbgfs_release,
-	.read = kgsl_mh_debug_read,
-};
-
-void kgsl_yamato_debugfs_init(struct kgsl_device *device)
-{
-	if (!device->d_debugfs || IS_ERR(device->d_debugfs))
-		return;
-
-	debugfs_create_file("ib_dump",  0600, device->d_debugfs, device,
-			    &kgsl_ib_dump_fops);
-	debugfs_create_file("istore",   0400, device->d_debugfs, device,
-			    &kgsl_istore_fops);
-	debugfs_create_file("sx_debug", 0400, device->d_debugfs, device,
-			    &kgsl_sx_debug_fops);
-	debugfs_create_file("cp_debug", 0400, device->d_debugfs, device,
-			    &kgsl_cp_debug_fops);
-	debugfs_create_file("mh_debug", 0400, device->d_debugfs, device,
-			    &kgsl_mh_debug_fops);
-	debugfs_create_file("cff_dump", 0644, device->d_debugfs, device,
-			    &kgsl_cff_dump_enable_fops);
-
-	/* Create post mortem control files */
-
-	pm_d_debugfs = debugfs_create_dir("postmortem", device->d_debugfs);
-
-	if (IS_ERR(pm_d_debugfs))
-		return;
-
-	debugfs_create_file("dump",  0600, pm_d_debugfs, device,
-			    &pm_dump_fops);
-	debugfs_create_file("regs_enabled", 0644, pm_d_debugfs, device,
-			    &pm_regs_enabled_fops);
-}
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.h
deleted file mode 100644
index ce447e1..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/kgsl_yamato_debugfs.h
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Copyright (c) 2002,2008-2011, Code Aurora Forum. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- */
-
-#ifndef _KGSL_YAMATO_DEBUGFS_H
-#define _KGSL_YAMATO_DEBUGFS_H
-
-#ifdef CONFIG_DEBUG_FS
-
-int kgsl_yamato_debugfs_init(struct kgsl_device *device);
-
-extern int kgsl_pm_regs_enabled;
-
-static inline int kgsl_pmregs_enabled(void)
-{
-	return kgsl_pm_regs_enabled;
-}
-
-#else
-static inline int kgsl_yamato_debugfs_init(struct kgsl_device *device)
-{
-	return 0;
-}
-
-static inline int kgsl_pmregs_enabled(void)
-{
-	/* If debugfs is turned off, then always print registers */
-	return 1;
-}
-#endif
-
-#endif
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/yamato_reg.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/yamato_reg.h
deleted file mode 100644
index ff0807d..0000000
--- a/drivers/video/msm/gpu/kgsl_adreno205_hc/yamato_reg.h
+++ /dev/null
@@ -1,452 +0,0 @@
-/* Copyright (c) 2002,2007-2010, Code Aurora Forum. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above
- *       copyright notice, this list of conditions and the following
- *       disclaimer in the documentation and/or other materials provided
- *       with the distribution.
- *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
- * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-#ifndef _YAMATO_REG_H
-#define _YAMATO_REG_H
-
-enum VGT_EVENT_TYPE {
- VS_DEALLOC = 0,
- PS_DEALLOC = 1,
- VS_DONE_TS = 2,
- PS_DONE_TS = 3,
- CACHE_FLUSH_TS = 4,
- CONTEXT_DONE = 5,
- CACHE_FLUSH = 6,
- VIZQUERY_START = 7,
- VIZQUERY_END = 8,
- SC_WAIT_WC = 9,
- RST_PIX_CNT = 13,
- RST_VTX_CNT = 14,
- TILE_FLUSH = 15,
- CACHE_FLUSH_AND_INV_TS_EVENT = 20,
- ZPASS_DONE = 21,
- CACHE_FLUSH_AND_INV_EVENT = 22,
- PERFCOUNTER_START = 23,
- PERFCOUNTER_STOP = 24,
- VS_FETCH_DONE = 27,
- FACENESS_FLUSH = 28,
-};
-
-enum COLORFORMATX {
- COLORX_4_4_4_4 = 0,
- COLORX_1_5_5_5 = 1,
- COLORX_5_6_5 = 2,
- COLORX_8 = 3,
- COLORX_8_8 = 4,
- COLORX_8_8_8_8 = 5,
- COLORX_S8_8_8_8 = 6,
- COLORX_16_FLOAT = 7,
- COLORX_16_16_FLOAT = 8,
- COLORX_16_16_16_16_FLOAT = 9,
- COLORX_32_FLOAT = 10,
- COLORX_32_32_FLOAT = 11,
- COLORX_32_32_32_32_FLOAT = 12,
- COLORX_2_3_3 = 13,
- COLORX_8_8_8 = 14,
-};
-
-enum SURFACEFORMAT {
- FMT_1_REVERSE                  = 0,
- FMT_1                          = 1,
- FMT_8                          = 2,
- FMT_1_5_5_5                    = 3,
- FMT_5_6_5                      = 4,
- FMT_6_5_5                      = 5,
- FMT_8_8_8_8                    = 6,
- FMT_2_10_10_10                 = 7,
- FMT_8_A                        = 8,
- FMT_8_B                        = 9,
- FMT_8_8                        = 10,
- FMT_Cr_Y1_Cb_Y0                = 11,
- FMT_Y1_Cr_Y0_Cb                = 12,
- FMT_5_5_5_1                    = 13,
- FMT_8_8_8_8_A                  = 14,
- FMT_4_4_4_4                    = 15,
- FMT_10_11_11                   = 16,
- FMT_11_11_10                   = 17,
- FMT_DXT1                       = 18,
- FMT_DXT2_3                     = 19,
- FMT_DXT4_5                     = 20,
- FMT_24_8                       = 22,
- FMT_24_8_FLOAT                 = 23,
- FMT_16                         = 24,
- FMT_16_16                      = 25,
- FMT_16_16_16_16                = 26,
- FMT_16_EXPAND                  = 27,
- FMT_16_16_EXPAND               = 28,
- FMT_16_16_16_16_EXPAND         = 29,
- FMT_16_FLOAT                   = 30,
- FMT_16_16_FLOAT                = 31,
- FMT_16_16_16_16_FLOAT          = 32,
- FMT_32                         = 33,
- FMT_32_32                      = 34,
- FMT_32_32_32_32                = 35,
- FMT_32_FLOAT                   = 36,
- FMT_32_32_FLOAT                = 37,
- FMT_32_32_32_32_FLOAT          = 38,
- FMT_32_AS_8                    = 39,
- FMT_32_AS_8_8                  = 40,
- FMT_16_MPEG                    = 41,
- FMT_16_16_MPEG                 = 42,
- FMT_8_INTERLACED               = 43,
- FMT_32_AS_8_INTERLACED         = 44,
- FMT_32_AS_8_8_INTERLACED       = 45,
- FMT_16_INTERLACED              = 46,
- FMT_16_MPEG_INTERLACED         = 47,
- FMT_16_16_MPEG_INTERLACED      = 48,
- FMT_DXN                        = 49,
- FMT_8_8_8_8_AS_16_16_16_16     = 50,
- FMT_DXT1_AS_16_16_16_16        = 51,
- FMT_DXT2_3_AS_16_16_16_16      = 52,
- FMT_DXT4_5_AS_16_16_16_16      = 53,
- FMT_2_10_10_10_AS_16_16_16_16  = 54,
- FMT_10_11_11_AS_16_16_16_16    = 55,
- FMT_11_11_10_AS_16_16_16_16    = 56,
- FMT_32_32_32_FLOAT             = 57,
- FMT_DXT3A                      = 58,
- FMT_DXT5A                      = 59,
- FMT_CTX1                       = 60,
- FMT_DXT3A_AS_1_1_1_1           = 61
-};
-
-#define REG_PERF_MODE_CNT	0x0
-#define REG_PERF_STATE_RESET	0x0
-#define REG_PERF_STATE_ENABLE	0x1
-#define REG_PERF_STATE_FREEZE	0x2
-
-#define RB_EDRAM_INFO_EDRAM_SIZE_SIZE                      4
-#define RB_EDRAM_INFO_EDRAM_MAPPING_MODE_SIZE              2
-#define RB_EDRAM_INFO_UNUSED0_SIZE                         8
-#define RB_EDRAM_INFO_EDRAM_RANGE_SIZE                     18
-
-struct rb_edram_info_t {
-	unsigned int edram_size:RB_EDRAM_INFO_EDRAM_SIZE_SIZE;
-	unsigned int edram_mapping_mode:RB_EDRAM_INFO_EDRAM_MAPPING_MODE_SIZE;
-	unsigned int unused0:RB_EDRAM_INFO_UNUSED0_SIZE;
-	unsigned int edram_range:RB_EDRAM_INFO_EDRAM_RANGE_SIZE;
-};
-
-union reg_rb_edram_info {
-	unsigned int val;
-	struct rb_edram_info_t f;
-};
-
-#define RBBM_READ_ERROR_UNUSED0_SIZE		2
-#define RBBM_READ_ERROR_READ_ADDRESS_SIZE	15
-#define RBBM_READ_ERROR_UNUSED1_SIZE		13
-#define RBBM_READ_ERROR_READ_REQUESTER_SIZE	1
-#define RBBM_READ_ERROR_READ_ERROR_SIZE		1
-
-struct rbbm_read_error_t {
-	unsigned int unused0:RBBM_READ_ERROR_UNUSED0_SIZE;
-	unsigned int read_address:RBBM_READ_ERROR_READ_ADDRESS_SIZE;
-	unsigned int unused1:RBBM_READ_ERROR_UNUSED1_SIZE;
-	unsigned int read_requester:RBBM_READ_ERROR_READ_REQUESTER_SIZE;
-	unsigned int read_error:RBBM_READ_ERROR_READ_ERROR_SIZE;
-};
-
-union rbbm_read_error_u {
-	unsigned int val:32;
-	struct rbbm_read_error_t f;
-};
-
-#define CP_RB_CNTL_RB_BUFSZ_SIZE                           6
-#define CP_RB_CNTL_UNUSED0_SIZE                            2
-#define CP_RB_CNTL_RB_BLKSZ_SIZE                           6
-#define CP_RB_CNTL_UNUSED1_SIZE                            2
-#define CP_RB_CNTL_BUF_SWAP_SIZE                           2
-#define CP_RB_CNTL_UNUSED2_SIZE                            2
-#define CP_RB_CNTL_RB_POLL_EN_SIZE                         1
-#define CP_RB_CNTL_UNUSED3_SIZE                            6
-#define CP_RB_CNTL_RB_NO_UPDATE_SIZE                       1
-#define CP_RB_CNTL_UNUSED4_SIZE                            3
-#define CP_RB_CNTL_RB_RPTR_WR_ENA_SIZE                     1
-
-struct cp_rb_cntl_t {
-	unsigned int rb_bufsz:CP_RB_CNTL_RB_BUFSZ_SIZE;
-	unsigned int unused0:CP_RB_CNTL_UNUSED0_SIZE;
-	unsigned int rb_blksz:CP_RB_CNTL_RB_BLKSZ_SIZE;
-	unsigned int unused1:CP_RB_CNTL_UNUSED1_SIZE;
-	unsigned int buf_swap:CP_RB_CNTL_BUF_SWAP_SIZE;
-	unsigned int unused2:CP_RB_CNTL_UNUSED2_SIZE;
-	unsigned int rb_poll_en:CP_RB_CNTL_RB_POLL_EN_SIZE;
-	unsigned int unused3:CP_RB_CNTL_UNUSED3_SIZE;
-	unsigned int rb_no_update:CP_RB_CNTL_RB_NO_UPDATE_SIZE;
-	unsigned int unused4:CP_RB_CNTL_UNUSED4_SIZE;
-	unsigned int rb_rptr_wr_ena:CP_RB_CNTL_RB_RPTR_WR_ENA_SIZE;
-};
-
-union reg_cp_rb_cntl {
-	unsigned int val:32;
-	struct cp_rb_cntl_t f;
-};
-
-#define RB_COLOR_INFO__COLOR_FORMAT_MASK                   0x0000000fL
-#define RB_COPY_DEST_INFO__COPY_DEST_FORMAT__SHIFT         0x00000004
-
-
-#define SQ_INT_CNTL__PS_WATCHDOG_MASK                      0x00000001L
-#define SQ_INT_CNTL__VS_WATCHDOG_MASK                      0x00000002L
-
-#define MH_INTERRUPT_MASK__AXI_READ_ERROR                  0x00000001L
-#define MH_INTERRUPT_MASK__AXI_WRITE_ERROR                 0x00000002L
-#define MH_INTERRUPT_MASK__MMU_PAGE_FAULT                  0x00000004L
-
-#define RBBM_INT_CNTL__RDERR_INT_MASK                      0x00000001L
-#define RBBM_INT_CNTL__DISPLAY_UPDATE_INT_MASK             0x00000002L
-#define RBBM_INT_CNTL__GUI_IDLE_INT_MASK                   0x00080000L
-
-#define RBBM_STATUS__CMDFIFO_AVAIL_MASK                    0x0000001fL
-#define RBBM_STATUS__TC_BUSY_MASK                          0x00000020L
-#define RBBM_STATUS__HIRQ_PENDING_MASK                     0x00000100L
-#define RBBM_STATUS__CPRQ_PENDING_MASK                     0x00000200L
-#define RBBM_STATUS__CFRQ_PENDING_MASK                     0x00000400L
-#define RBBM_STATUS__PFRQ_PENDING_MASK                     0x00000800L
-#define RBBM_STATUS__VGT_BUSY_NO_DMA_MASK                  0x00001000L
-#define RBBM_STATUS__RBBM_WU_BUSY_MASK                     0x00004000L
-#define RBBM_STATUS__CP_NRT_BUSY_MASK                      0x00010000L
-#define RBBM_STATUS__MH_BUSY_MASK                          0x00040000L
-#define RBBM_STATUS__MH_COHERENCY_BUSY_MASK                0x00080000L
-#define RBBM_STATUS__SX_BUSY_MASK                          0x00200000L
-#define RBBM_STATUS__TPC_BUSY_MASK                         0x00400000L
-#define RBBM_STATUS__SC_CNTX_BUSY_MASK                     0x01000000L
-#define RBBM_STATUS__PA_BUSY_MASK                          0x02000000L
-#define RBBM_STATUS__VGT_BUSY_MASK                         0x04000000L
-#define RBBM_STATUS__SQ_CNTX17_BUSY_MASK                   0x08000000L
-#define RBBM_STATUS__SQ_CNTX0_BUSY_MASK                    0x10000000L
-#define RBBM_STATUS__RB_CNTX_BUSY_MASK                     0x40000000L
-#define RBBM_STATUS__GUI_ACTIVE_MASK                       0x80000000L
-
-#define CP_INT_CNTL__SW_INT_MASK                           0x00080000L
-#define CP_INT_CNTL__T0_PACKET_IN_IB_MASK                  0x00800000L
-#define CP_INT_CNTL__OPCODE_ERROR_MASK                     0x01000000L
-#define CP_INT_CNTL__PROTECTED_MODE_ERROR_MASK             0x02000000L
-#define CP_INT_CNTL__RESERVED_BIT_ERROR_MASK               0x04000000L
-#define CP_INT_CNTL__IB_ERROR_MASK                         0x08000000L
-#define CP_INT_CNTL__IB2_INT_MASK                          0x20000000L
-#define CP_INT_CNTL__IB1_INT_MASK                          0x40000000L
-#define CP_INT_CNTL__RB_INT_MASK                           0x80000000L
-
-#define MASTER_INT_SIGNAL__MH_INT_STAT                     0x00000020L
-#define MASTER_INT_SIGNAL__SQ_INT_STAT                     0x04000000L
-#define MASTER_INT_SIGNAL__CP_INT_STAT                     0x40000000L
-#define MASTER_INT_SIGNAL__RBBM_INT_STAT                   0x80000000L
-
-#define RB_EDRAM_INFO__EDRAM_SIZE_MASK                     0x0000000fL
-#define RB_EDRAM_INFO__EDRAM_RANGE_MASK                    0xffffc000L
-
-#define	MH_ARBITER_CONFIG__SAME_PAGE_GRANULARITY__SHIFT    0x00000006
-#define	MH_ARBITER_CONFIG__L1_ARB_ENABLE__SHIFT            0x00000007
-#define	MH_ARBITER_CONFIG__L1_ARB_HOLD_ENABLE__SHIFT       0x00000008
-#define	MH_ARBITER_CONFIG__L2_ARB_CONTROL__SHIFT           0x00000009
-#define	MH_ARBITER_CONFIG__PAGE_SIZE__SHIFT                0x0000000a
-#define	MH_ARBITER_CONFIG__TC_REORDER_ENABLE__SHIFT        0x0000000d
-#define	MH_ARBITER_CONFIG__TC_ARB_HOLD_ENABLE__SHIFT       0x0000000e
-#define	MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT_ENABLE__SHIFT   0x0000000f
-#define	MH_ARBITER_CONFIG__IN_FLIGHT_LIMIT__SHIFT          0x00000010
-#define	MH_ARBITER_CONFIG__CP_CLNT_ENABLE__SHIFT           0x00000016
-#define	MH_ARBITER_CONFIG__VGT_CLNT_ENABLE__SHIFT          0x00000017
-#define	MH_ARBITER_CONFIG__TC_CLNT_ENABLE__SHIFT           0x00000018
-#define	MH_ARBITER_CONFIG__RB_CLNT_ENABLE__SHIFT           0x00000019
-#define	MH_ARBITER_CONFIG__PA_CLNT_ENABLE__SHIFT           0x0000001a
-
-#define	MH_MMU_CONFIG__RB_W_CLNT_BEHAVIOR__SHIFT           0x00000004
-#define	MH_MMU_CONFIG__CP_W_CLNT_BEHAVIOR__SHIFT           0x00000006
-#define	MH_MMU_CONFIG__CP_R0_CLNT_BEHAVIOR__SHIFT          0x00000008
-#define	MH_MMU_CONFIG__CP_R1_CLNT_BEHAVIOR__SHIFT          0x0000000a
-#define	MH_MMU_CONFIG__CP_R2_CLNT_BEHAVIOR__SHIFT          0x0000000c
-#define	MH_MMU_CONFIG__CP_R3_CLNT_BEHAVIOR__SHIFT          0x0000000e
-#define	MH_MMU_CONFIG__CP_R4_CLNT_BEHAVIOR__SHIFT          0x00000010
-#define	MH_MMU_CONFIG__VGT_R0_CLNT_BEHAVIOR__SHIFT         0x00000012
-#define	MH_MMU_CONFIG__VGT_R1_CLNT_BEHAVIOR__SHIFT         0x00000014
-#define	MH_MMU_CONFIG__TC_R_CLNT_BEHAVIOR__SHIFT           0x00000016
-#define	MH_MMU_CONFIG__PA_W_CLNT_BEHAVIOR__SHIFT           0x00000018
-
-#define	CP_RB_CNTL__RB_BUFSZ__SHIFT                        0x00000000
-#define	CP_RB_CNTL__RB_BLKSZ__SHIFT                        0x00000008
-#define	CP_RB_CNTL__RB_POLL_EN__SHIFT                      0x00000014
-#define	CP_RB_CNTL__RB_NO_UPDATE__SHIFT                    0x0000001b
-
-#define	RB_COLOR_INFO__COLOR_FORMAT__SHIFT                 0x00000000
-#define	RB_EDRAM_INFO__EDRAM_MAPPING_MODE__SHIFT           0x00000004
-#define	RB_EDRAM_INFO__EDRAM_RANGE__SHIFT                  0x0000000e
-
-#define REG_CP_CSQ_IB1_STAT              0x01FE
-#define REG_CP_CSQ_IB2_STAT              0x01FF
-#define REG_CP_CSQ_RB_STAT               0x01FD
-#define REG_CP_DEBUG                     0x01FC
-#define REG_CP_IB1_BASE                  0x0458
-#define REG_CP_IB1_BUFSZ                 0x0459
-#define REG_CP_IB2_BASE                  0x045A
-#define REG_CP_IB2_BUFSZ                 0x045B
-#define REG_CP_INT_ACK                   0x01F4
-#define REG_CP_INT_CNTL                  0x01F2
-#define REG_CP_INT_STATUS                0x01F3
-#define REG_CP_ME_CNTL                   0x01F6
-#define REG_CP_ME_RAM_DATA               0x01FA
-#define REG_CP_ME_RAM_WADDR              0x01F8
-#define REG_CP_ME_STATUS                 0x01F7
-#define REG_CP_PFP_UCODE_ADDR            0x00C0
-#define REG_CP_PFP_UCODE_DATA            0x00C1
-#define REG_CP_QUEUE_THRESHOLDS          0x01D5
-#define REG_CP_RB_BASE                   0x01C0
-#define REG_CP_RB_CNTL                   0x01C1
-#define REG_CP_RB_RPTR                   0x01C4
-#define REG_CP_RB_RPTR_ADDR              0x01C3
-#define REG_CP_RB_RPTR_WR                0x01C7
-#define REG_CP_RB_WPTR                   0x01C5
-#define REG_CP_RB_WPTR_BASE              0x01C8
-#define REG_CP_RB_WPTR_DELAY             0x01C6
-#define REG_CP_STAT                      0x047F
-#define REG_CP_STATE_DEBUG_DATA          0x01ED
-#define REG_CP_STATE_DEBUG_INDEX         0x01EC
-#define REG_CP_ST_BASE                   0x044D
-#define REG_CP_ST_BUFSZ                  0x044E
-
-#define REG_CP_PERFMON_CNTL              0x0444
-#define REG_CP_PERFCOUNTER_SELECT        0x0445
-#define REG_CP_PERFCOUNTER_LO            0x0446
-#define REG_CP_PERFCOUNTER_HI            0x0447
-
-#define REG_RBBM_PERFCOUNTER1_SELECT     0x0395
-#define REG_RBBM_PERFCOUNTER1_HI         0x0398
-#define REG_RBBM_PERFCOUNTER1_LO         0x0397
-
-#define REG_MASTER_INT_SIGNAL            0x03B7
-
-#define REG_MH_ARBITER_CONFIG            0x0A40
-#define REG_MH_INTERRUPT_CLEAR           0x0A44
-#define REG_MH_INTERRUPT_MASK            0x0A42
-#define REG_MH_INTERRUPT_STATUS          0x0A43
-#define REG_MH_MMU_CONFIG                0x0040
-#define REG_MH_MMU_INVALIDATE            0x0045
-#define REG_MH_MMU_MPU_BASE              0x0046
-#define REG_MH_MMU_MPU_END               0x0047
-#define REG_MH_MMU_PAGE_FAULT            0x0043
-#define REG_MH_MMU_PT_BASE               0x0042
-#define REG_MH_MMU_TRAN_ERROR            0x0044
-#define REG_MH_MMU_VA_RANGE              0x0041
-#define REG_MH_CLNT_INTF_CTRL_CONFIG1    0x0A54
-#define REG_MH_CLNT_INTF_CTRL_CONFIG2    0x0A55
-
-#define REG_PA_CL_VPORT_XSCALE           0x210F
-#define REG_PA_CL_VPORT_ZOFFSET          0x2114
-#define REG_PA_CL_VPORT_ZSCALE           0x2113
-#define REG_PA_CL_CLIP_CNTL              0x2204
-#define REG_PA_CL_VTE_CNTL               0x2206
-#define REG_PA_SC_AA_MASK                0x2312
-#define REG_PA_SC_LINE_CNTL              0x2300
-#define REG_PA_SC_SCREEN_SCISSOR_BR      0x200F
-#define REG_PA_SC_SCREEN_SCISSOR_TL      0x200E
-#define REG_PA_SC_VIZ_QUERY              0x2293
-#define REG_PA_SC_VIZ_QUERY_STATUS       0x0C44
-#define REG_PA_SC_WINDOW_OFFSET          0x2080
-#define REG_PA_SC_WINDOW_SCISSOR_BR      0x2082
-#define REG_PA_SC_WINDOW_SCISSOR_TL      0x2081
-#define REG_PA_SU_FACE_DATA              0x0C86
-#define REG_PA_SU_POINT_SIZE             0x2280
-#define REG_PA_SU_LINE_CNTL              0x2282
-#define REG_PA_SU_POLY_OFFSET_BACK_OFFSET 0x2383
-#define REG_PA_SU_POLY_OFFSET_FRONT_SCALE 0x2380
-#define REG_PA_SU_SC_MODE_CNTL           0x2205
-
-#define REG_PC_INDEX_OFFSET		0x2102
-
-#define REG_RBBM_CNTL                    0x003B
-#define REG_RBBM_INT_ACK                 0x03B6
-#define REG_RBBM_INT_CNTL                0x03B4
-#define REG_RBBM_INT_STATUS              0x03B5
-#define REG_RBBM_PATCH_RELEASE           0x0001
-#define REG_RBBM_PERIPHID1               0x03F9
-#define REG_RBBM_PERIPHID2               0x03FA
-#define REG_RBBM_DEBUG                   0x039B
-#define REG_RBBM_DEBUG_OUT               0x03A0
-#define REG_RBBM_DEBUG_CNTL              0x03A1
-#define REG_RBBM_PM_OVERRIDE1            0x039C
-#define REG_RBBM_PM_OVERRIDE2            0x039D
-#define REG_RBBM_READ_ERROR              0x03B3
-#define REG_RBBM_SOFT_RESET              0x003C
-#define REG_RBBM_STATUS                  0x05D0
-
-#define REG_RB_COLORCONTROL              0x2202
-#define REG_RB_COLOR_DEST_MASK           0x2326
-#define REG_RB_COLOR_MASK                0x2104
-#define REG_RB_COPY_CONTROL              0x2318
-#define REG_RB_DEPTHCONTROL              0x2200
-#define REG_RB_EDRAM_INFO                0x0F02
-#define REG_RB_MODECONTROL               0x2208
-#define REG_RB_SURFACE_INFO              0x2000
-#define REG_RB_SAMPLE_POS		 0x220a
-
-#define REG_SCRATCH_ADDR                 0x01DD
-#define REG_SCRATCH_REG0                 0x0578
-#define REG_SCRATCH_REG2                 0x057A
-#define REG_SCRATCH_UMSK                 0x01DC
-
-#define REG_SQ_CF_BOOLEANS               0x4900
-#define REG_SQ_CF_LOOP                   0x4908
-#define REG_SQ_GPR_MANAGEMENT            0x0D00
-#define REG_SQ_INST_STORE_MANAGMENT      0x0D02
-#define REG_SQ_INT_ACK                   0x0D36
-#define REG_SQ_INT_CNTL                  0x0D34
-#define REG_SQ_INT_STATUS                0x0D35
-#define REG_SQ_PROGRAM_CNTL              0x2180
-#define REG_SQ_PS_PROGRAM                0x21F6
-#define REG_SQ_VS_PROGRAM                0x21F7
-#define REG_SQ_WRAPPING_0                0x2183
-#define REG_SQ_WRAPPING_1                0x2184
-
-#define REG_VGT_ENHANCE                  0x2294
-#define REG_VGT_INDX_OFFSET              0x2102
-#define REG_VGT_MAX_VTX_INDX             0x2100
-#define REG_VGT_MIN_VTX_INDX             0x2101
-
-#define REG_TP0_CHICKEN			 0x0E1E
-#define REG_TC_CNTL_STATUS             	 0x0E00
-#define REG_PA_SC_AA_CONFIG            	 0x2301
-#define REG_VGT_VERTEX_REUSE_BLOCK_CNTL  0x2316
-#define REG_SQ_INTERPOLATOR_CNTL         0x2182
-#define REG_RB_DEPTH_INFO                0x2002
-#define REG_COHER_DEST_BASE_0            0x2006
-#define REG_RB_FOG_COLOR                 0x2109
-#define REG_RB_STENCILREFMASK_BF         0x210C
-#define REG_PA_SC_LINE_STIPPLE           0x2283
-#define REG_SQ_PS_CONST                  0x2308
-#define REG_RB_DEPTH_CLEAR               0x231D
-#define REG_RB_SAMPLE_COUNT_CTL          0x2324
-#define REG_SQ_CONSTANT_0                0x4000
-#define REG_SQ_FETCH_0                   0x4800
-
-#define REG_MH_AXI_ERROR		 0xA45
-#define REG_MH_DEBUG_CTRL		 0xA4E
-#define REG_MH_DEBUG_DATA		 0xA4F
-#define REG_COHER_BASE_PM4		 0xA2A
-#define REG_COHER_STATUS_PM4		 0xA2B
-#define REG_COHER_SIZE_PM4		 0xA29
-
-#endif /* _YAMATO_REG_H */
diff --git a/drivers/video/msm/gpu/kgsl_adreno205_hc/z180.h b/drivers/video/msm/gpu/kgsl_adreno205_hc/z180.h
new file mode 100644
index 0000000..deb0277
--- /dev/null
+++ b/drivers/video/msm/gpu/kgsl_adreno205_hc/z180.h
@@ -0,0 +1,63 @@
+/* Copyright (c) 2008-2011, Code Aurora Forum. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of Code Aurora Forum, Inc. nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+#ifndef _KGSL_G12_H
+#define _KGSL_G12_H
+
+#define IDX_2D(X) ((X)-KGSL_DEVICE_2D0)
+
+#define DEVICE_2D_NAME "kgsl-2d"
+#define DEVICE_2D0_NAME "kgsl-2d0"
+#define DEVICE_2D1_NAME "kgsl-2d1"
+
+struct kgsl_g12_ringbuffer {
+	unsigned int prevctx;
+	struct kgsl_memdesc      cmdbufdesc;
+};
+
+struct kgsl_g12_device {
+	struct kgsl_device dev;    /* Must be first field in this struct */
+	int current_timestamp;
+	int timestamp;
+	struct kgsl_g12_ringbuffer ringbuffer;
+	spinlock_t cmdwin_lock;
+};
+
+irqreturn_t kgsl_g12_isr(int irq, void *data);
+int kgsl_g12_setstate(struct kgsl_device *device, uint32_t flags);
+int kgsl_g12_idle(struct kgsl_device *device, unsigned int timeout);
+void kgsl_g12_regread(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int *value);
+void kgsl_g12_regwrite(struct kgsl_device *device, unsigned int offsetwords,
+			unsigned int value);
+void kgsl_g12_regread_isr(struct kgsl_device *device, unsigned int offsetwords,
+				unsigned int *value);
+void kgsl_g12_regwrite_isr(struct kgsl_device *device, unsigned int offsetwords,
+			unsigned int value);
+
+#endif /* _KGSL_G12_H */
-- 
1.7.5.4

